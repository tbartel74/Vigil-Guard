{
  "name": "Vigil-Guard-v1.4",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.3,
      "position": [
        -5264,
        -1040
      ],
      "id": "ed67ca7e-d0e5-47bc-a5f4-391564819f94",
      "name": "When chat message received",
      "webhookId": "fc047cb1-9f7a-4278-b3da-1fe3d4ddda95"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Build_Sanitized_NDJSON - strict mode for config values\n * UPDATED: Uses output_text from Final Decision as primary source\n */\n\nfunction err(msg){ throw new Error(msg); }\n\nfunction simpleHash(str){\n  let hash = 0;\n  for (let i = 0; i < str.length; i++){\n    const c = str.charCodeAt(i);\n    hash = ((hash << 5) - hash) + c;\n    hash |= 0;\n  }\n  return hash.toString(36);\n}\n\nconst isPlainObject = v => Object.prototype.toString.call(v) === \"[object Object]\";\nfunction firstDefined(...vals){ for (const v of vals) if (v !== undefined && v !== null) return v; return undefined; }\nfunction s(v){ if (v===undefined||v===null) return undefined; const t=String(v); return t.trim()?t:undefined; }\nfunction deepPrune(value,{removeEmptyObjects=false,removeEmptyArrays=false}={}){\n  if (Array.isArray(value)){\n    const arr = value.map(v=>deepPrune(v,{removeEmptyObjects,removeEmptyArrays})).filter(v=>v!==undefined);\n    if (removeEmptyArrays && arr.length===0) return undefined;\n    return arr;\n  }\n  if (isPlainObject(value)){\n    const out = {};\n    for (const [k,v] of Object.entries(value)){\n      const pruned = deepPrune(v,{removeEmptyObjects,removeEmptyArrays});\n      if (pruned !== undefined) out[k]=pruned;\n    }\n    if (removeEmptyObjects && Object.keys(out).length===0) return undefined;\n    return out;\n  }\n  if (value===null || value===undefined || (typeof value===\"number\" && Number.isNaN(value))) return undefined;\n  return value;\n}\nfunction J(x){ try { return JSON.stringify(x ?? {}); } catch { return \"{}\"; } }\n\nconst items = $input.all();\nif (!items.length) err(\"Build_Sanitized_NDJSON: no input items.\");\n\nconst out = [];\n\nfor (const item of items){\n  const j = item.json || {};\n\n  const san = j.__san || {};\n  const snap = j._pipeline_snapshots || san._pipeline_snapshots || {};\n  const norm = j.normalization || san.normalization || {};\n\n  const pgDecision = j.decision || {};\n  const routing = j.routing || {};\n  const metrics = j.metrics || {};\n  const technical = j.technical || {};\n  const audit = j.audit || {};\n  const messages = j.messages || {};\n\n  const sanitizerDecision = j.sanitizer_decision || {};\n\n  const cfg = j.config || {};\n  const rules = j.rules || {};\n  const thr = j.thresholds || {};\n\n  const sessionId = firstDefined(\n    j.sessionId,\n    san.sessionId,\n    j.chat_payload?.sessionId\n  ) || \"unknown\";\n  \n  const action = firstDefined(\n    j.action,\n    san.action,\n    j.chat_payload?.action\n  ) || \"sendMessage\";\n\n  const originalInput = s(firstDefined(\n    snap.beforeSanitization,\n    norm?.original,\n    san.chat_payload?.chatInput,\n    j.audit?.originalPrompt\n  )) || \"N/A\";\n\n  const normalizedInput = s(firstDefined(\n    snap.input_normalized,\n    norm?.canonical,\n    norm?.normalized,\n    originalInput\n  )) || originalInput;\n\n  const sanitizedText = s(firstDefined(\n    snap.afterSanitization,\n    san.chat_payload?.chatInput,\n    j.chat_payload?.chatInput\n  ));\n\n  const redactedText = s(firstDefined(\n    snap.afterPII,\n    sanitizedText\n  ));\n\n  const pgShouldBlock = !!(routing.shouldBlock || j._isBlocked);\n  const pgShouldWarn = !!(routing.shouldWarn || j._requiresSanitization);\n  const pgIsSafe = !!(routing.isSafe || j._shouldContinue);\n  \n  const sanitizerDecisionStr = sanitizerDecision.decision || 'ALLOW';\n  const sanitizerBlocked = (sanitizerDecisionStr === 'BLOCK');\n  \n  let finalStatus;\n  if (pgShouldBlock || sanitizerBlocked) {\n    finalStatus = \"BLOCKED\";\n  } else if (pgShouldWarn) {\n    finalStatus = \"SANITIZED\";\n  } else {\n    finalStatus = \"ALLOWED\";\n  }\n\n  const shouldBlock = (finalStatus === \"BLOCKED\");\n  const shouldWarn = (finalStatus === \"SANITIZED\");\n  const isSafe = (finalStatus === \"ALLOWED\");\n\n  // ✓ UPDATED: Priorytet dla output_text z Final Decision\n  const finalOutput = s(j.output_text) || \n                      (shouldBlock \n                        ? (s(messages?.user) || s(cfg?.enforcement?.block_message) || \"Content blocked by security policy\")\n                        : (redactedText || sanitizedText || s(j.chat_payload?.chatInput) || \"N/A\"));\n\n  const pgHasDecision = !!(pgDecision && (pgDecision.action !== undefined || pgDecision.severity !== undefined || pgDecision.scoreRaw !== undefined));\n  const blockedByPG = shouldBlock && pgHasDecision;\n  const blockedBySan = shouldBlock && !pgHasDecision;\n\n  let source = \"sanitizer_pre_pg\";\n  let actionTaken = firstDefined(pgDecision.action, finalStatus);\n  \n  if (finalStatus === \"BLOCKED\"){\n    if (blockedBySan) { \n      source = \"sanitizer_only\"; \n      actionTaken = \"BLOCK_BY_SANITIZER\"; \n    }\n    if (blockedByPG) { \n      source = \"prompt_guard\"; \n      actionTaken = pgDecision.action || \"BLOCK_BY_PROMPT_GUARD\"; \n    }\n  } else {\n    source = pgHasDecision ? \"prompt_guard\" : \"sanitizer_pre_pg\";\n    if (finalStatus === \"ALLOWED\") actionTaken = \"ALLOW\";\n    if (finalStatus === \"SANITIZED\") actionTaken = actionTaken || \"SANITIZE\";\n  }\n\n  const nd = {\n    sessionId,\n    action,\n    chat_payload: {\n      sessionId,\n      action,\n      chatInput: finalOutput\n    },\n    sanitizer: {\n      decision: sanitizerDecisionStr,\n      removal_pct: san.enforcement?.removalPct ?? j.enforcement?.removalPct ?? 0,\n      mode: san.enforcement?.mode || j.enforcement?.mode,\n      score: j.score || sanitizerDecision.score || 0,\n      breakdown: j.scoreBreakdown || sanitizerDecision.scoreBreakdown || {}\n    },\n    prompt_guard: pgHasDecision ? {\n      score: pgDecision.scoreRaw || metrics.injectionScore,\n      score_percent: pgDecision.scorePercent || metrics.scorePercent,\n      risk_level: pgDecision.riskLevel,\n      severity: pgDecision.severity,\n      action: pgDecision.action,\n      should_block: pgShouldBlock,\n      should_warn: pgShouldWarn,\n      is_safe: pgIsSafe,\n      confidence: metrics.confidence,\n      thresholds_used: technical.thresholdsUsed,\n      policies_used: technical.policiesUsed,\n      timestamp: audit.timestamp\n    } : {},\n    final_decision: {\n      status: finalStatus,\n      blocked: shouldBlock,\n      sanitized: shouldWarn,\n      allowed: isSafe,\n      action_taken: actionTaken,\n      user_message: s(messages?.user) || \"\",\n      internal_note: s(messages?.internal) || \"\",\n      source\n    },\n    pipeline_flow: {\n      input_raw: originalInput,\n      input_normalized: normalizedInput,\n      after_sanitization: sanitizedText || finalOutput,\n      after_pii_redaction: redactedText || finalOutput,\n      output_final: finalOutput,\n      output_status: finalStatus\n    },\n    scoring: {\n      sanitizer_score: Number(j.score ?? sanitizerDecision.score ?? 0),\n      prompt_guard_score: pgDecision.scoreRaw || metrics.injectionScore,\n      prompt_guard_percent: pgDecision.scorePercent || metrics.scorePercent,\n      combined_severity: firstDefined(\n        pgDecision.severity,\n        (j.score ?? 0) >= 76 ? 5 :\n        (j.score ?? 0) >= 56 ? 4 :\n        (j.score ?? 0) >= 30 ? 3 :\n        (j.score ?? 0) >= 10 ? 2 : 1\n      ),\n      score_breakdown: j.scoreBreakdown || sanitizerDecision.scoreBreakdown || {},\n      match_details: j.matchDetails || []\n    },\n    config_metadata: {\n      config_hash: (cfg && rules && thr) ? simpleHash(JSON.stringify({ cfg, rules, thr })) : \"no-config\",\n      config_version: cfg?.version || \"unknown\",\n      has_full_config: !!(cfg && rules && thr),\n      has_prompt_guard: pgHasDecision,\n      config_ref: {\n        normalization_unicode: cfg.normalization?.unicode_form,\n        scoring_ranges: thr?.ranges,\n        prompt_guard_thresholds: technical.thresholdsUsed\n      },\n      loader_info: j._loader\n    },\n    _audit: {\n      processing_timestamp: new Date().toISOString(),\n      pipeline_version: \"v2.2-merged\",\n      total_processing_time: metrics.processingTime,\n      final_action: actionTaken\n    },\n    normalization: norm || {},  // Include full normalization data (encoding, obfuscation, etc.)\n    validation: cfg._validation || j._validation || j.validation || {}  // Include validation results from Input_Validator (Phase 2.4)\n  };\n\n  const ndClean = deepPrune(nd);\n\n  const row = {\n    sessionId: ndClean.sessionId,\n    action: ndClean.action,\n    timestamp: ndClean._audit?.processing_timestamp,\n\n    original_input: ndClean.pipeline_flow?.input_raw,\n    normalized_input: ndClean.pipeline_flow?.input_normalized,\n    after_sanitization: ndClean.pipeline_flow?.after_sanitization,\n    after_pii_redaction: ndClean.pipeline_flow?.after_pii_redaction,\n    chat_input: ndClean.chat_payload?.chatInput,\n    result: ndClean.pipeline_flow?.output_final,\n\n    threat_score: ndClean.scoring?.sanitizer_score ?? ndClean.scoring?.prompt_guard_score ?? 0,\n    threat_severity: ndClean.prompt_guard?.risk_level ?? \"UNDEFINED\",\n    pg_score: ndClean.prompt_guard?.score ?? 0,\n    pg_score_percent: ndClean.prompt_guard?.score_percent ?? 0,\n    final_status: ndClean.final_decision?.status ?? \"UNKNOWN\",\n    final_action: ndClean._audit?.final_action ?? \"\",\n    user_message: ndClean.final_decision?.user_message ?? \"\",\n\n    removal_pct: ndClean.sanitizer?.removal_pct ?? 0,\n    threat_labels: [],\n    threat_matches: [],\n\n    config_version: ndClean.config_metadata?.config_version,\n    config_hash: ndClean.config_metadata?.config_hash,\n    pipeline_version: ndClean._audit?.pipeline_version,\n    processing_time_ms: ndClean._audit?.total_processing_time ?? 0,\n\n    sanitizer_json: J(ndClean.sanitizer),\n    prompt_guard_json: J(ndClean.prompt_guard),\n    scoring_json: J(ndClean.scoring),\n    final_decision_json: J(ndClean.final_decision),\n    pipeline_flow_json: J(ndClean.pipeline_flow),\n    config_metadata_json: J(ndClean.config_metadata),\n    raw_event: J(ndClean)\n  };\n\n  out.push({ json: { ndjson: ndClean, row } });\n}\n\nreturn out;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        -1008
      ],
      "id": "6944c510-e959-4d68-b80d-2102fe4bf884",
      "name": "Build+Sanitize NDJSON"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=http://clickhouse:8123/?date_time_input_format=best_effort&input_format_skip_unknown_fields=1&query=INSERT%20INTO%20n8n_logs.events_processed%20FORMAT%20JSONEachRow",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/x-ndjson",
        "body": "={{$json.row}}",
        "options": {
          "response": {
            "response": {
              "fullResponse": true
            }
          },
          "timeout": 15000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        672,
        -1008
      ],
      "id": "370ea391-0930-464c-aa27-5e727a97364c",
      "name": "Logging to Clikhouse",
      "retryOnFail": true,
      "alwaysOutputData": false,
      "credentials": {
        "httpBasicAuth": {
          "id": "bolvzGrkrBMMpXCf",
          "name": "clickhouse"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Load_Config - Production version with Bloom validation\n * FIXED: English messages, better error handling, bloom configuration validation\n */\n\nfunction safeParseJson(value, fieldName) {\n  if (value == null) {\n    return { ok: false, error: `${fieldName} is null/undefined` };\n  }\n  \n  if (typeof value === 'object') {\n    return { ok: true, data: value };\n  }\n  \n  if (typeof value === 'string') {\n    try {\n      return { ok: true, data: JSON.parse(value) };\n    } catch (e) {\n      return { ok: false, error: `${fieldName} JSON parse failed: ${e.message}` };\n    }\n  }\n  \n  return { ok: false, error: `${fieldName} has invalid type: ${typeof value}` };\n}\n\nfunction validateAllowlistSchema(obj) {\n  return obj && typeof obj === 'object' && \n    (obj.$schema || obj.title === 'Sanitizer Allowlist Schema');\n}\n\nfunction validateNormalizeConf(text) {\n  return typeof text === 'string' && \n    (/#\\s*normalize\\.conf/i.test(text) || \n     /\\\\u200B=|leet\\.char\\.|# Zero-width|# LEET map/.test(text));\n}\n\nfunction validatePiiConf(obj) {\n  return obj && typeof obj === 'object' && \n    Array.isArray(obj.rules) && \n    obj.rules.length > 0 &&\n    obj.rules.some(r => r && typeof r.pattern === 'string' && typeof r.name === 'string');\n}\n\nfunction validateThresholds(obj) {\n  return obj && typeof obj === 'object' && \n    obj.ranges && \n    obj.ranges.allow && \n    obj.ranges.block;\n}\n\nfunction validateUnifiedConfig(obj) {\n  return obj && typeof obj === 'object' && \n    obj.normalization && \n    obj.sanitization && \n    obj.scoring;\n}\n\nfunction validateRules(obj) {\n  return obj && typeof obj === 'object' && \n    obj.categories && \n    typeof obj.categories === 'object';\n}\n\nfunction validateBloomConfig(config) {\n  const warnings = [];\n  \n  if (!config.bloom || typeof config.bloom !== 'object') {\n    warnings.push('Missing or invalid bloom configuration, using defaults');\n  }\n  \n  if (!config.prefilter || typeof config.prefilter !== 'object') {\n    warnings.push('Missing or invalid prefilter configuration, using defaults');\n  }\n  \n  if (config.prefilter && !Array.isArray(config.prefilter.dangerous_patterns)) {\n    warnings.push('Missing dangerous_patterns in prefilter, will use defaults');\n  }\n  \n  if (!config.bloom_decisions || typeof config.bloom_decisions !== 'object') {\n    warnings.push('Missing bloom_decisions, using defaults');\n  }\n  \n  return warnings;\n}\n\nconst inputItems = $input.all();\nif (!inputItems || !inputItems.length) {\n  console.error('Load_Config: No input items');\n  return [{\n    json: {\n      error: 'No input items',\n      configError: true,\n      decision: { decision: 'ALLOW', reason: 'CONFIG_ERROR' }\n    }\n  }];\n}\n\nconst firstItem = inputItems[0];\nconst j = firstItem.json ? JSON.parse(JSON.stringify(firstItem.json)) : {};\n\nj._loader = {\n  sources: {},\n  missing: [],\n  errors: [],\n  warnings: []\n};\n\nconst data1Result = safeParseJson(j.data1, 'data1 (allowlist_schema)');\nif (data1Result.ok && validateAllowlistSchema(data1Result.data)) {\n  j.allowlist_schema = data1Result.data;\n  j._loader.sources.allowlist_schema = 'json.data1';\n} else {\n  j._loader.missing.push('allowlist_schema');\n  j._loader.errors.push(data1Result.error || 'data1: invalid allowlist_schema');\n}\n\nif (validateNormalizeConf(j.data2)) {\n  j.normalization_text = j.data2;\n  j._loader.sources.normalize_conf = 'json.data2';\n} else {\n  j._loader.missing.push('normalize_conf');\n  j._loader.errors.push('data2: invalid normalize.conf format');\n}\n\nconst data3Result = safeParseJson(j.data3, 'data3 (pii.conf)');\nif (data3Result.ok && validatePiiConf(data3Result.data)) {\n  j.pii_conf = data3Result.data;\n  j.pii_text = typeof j.data3 === 'string' ? j.data3 : JSON.stringify(data3Result.data);\n  j._loader.sources.pii_conf = 'json.data3';\n} else {\n  j._loader.missing.push('pii_conf');\n  j._loader.errors.push(data3Result.error || 'data3: invalid pii.conf format');\n}\n\nconst data4Result = safeParseJson(j.data4, 'data4 (thresholds)');\nif (data4Result.ok && validateThresholds(data4Result.data)) {\n  j.thresholds = data4Result.data;\n  j._loader.sources.thresholds = 'json.data4';\n} else {\n  j._loader.missing.push('thresholds');\n  j._loader.errors.push(data4Result.error || 'data4: invalid thresholds format');\n}\n\nconst data5Result = safeParseJson(j.data5, 'data5 (unified_config)');\nif (data5Result.ok && validateUnifiedConfig(data5Result.data)) {\n  j.config = data5Result.data;\n  j._loader.sources.unified_config = 'json.data5';\n  \n  // Validate bloom configuration and collect warnings\n  const bloomWarnings = validateBloomConfig(j.config);\n  if (bloomWarnings.length > 0) {\n    j._loader.warnings = j._loader.warnings.concat(bloomWarnings);\n    console.warn('Bloom config warnings:', bloomWarnings);\n  }\n  \n  // Ensure bloom configuration has required structure\n  if (!j.config.bloom) {\n    j.config.bloom = { m: 32768, k: 5, seed: 1337, match_mod: 97, min_matched_bits: 2 };\n  }\n  \n  if (!j.config.prefilter) {\n    j.config.prefilter = { \n      ngram: { min: 3, max: 6, prefix_window: 96 },\n      sample_limit: 800,\n      obf_signals: { min_count: 2 },\n      dangerous_patterns: []\n    };\n  } else if (!j.config.prefilter.dangerous_patterns) {\n    j.config.prefilter.dangerous_patterns = [];\n  }\n  \n  if (!j.config.bloom_decisions) {\n    j.config.bloom_decisions = {\n      route_to_ac_threshold: 15,\n      hard_block_threshold: 50,\n      require_zusatz_signals: true,\n      phrase_match_bonus: 20\n    };\n  }\n  \n  j.config.references = Object.assign({}, j.config.references || {}, {\n    rules_file: 'rules.config.json',\n    thresholds_file: 'thresholds.config.json',\n    normalize_conf: 'normalize.conf',\n    pii_conf: 'pii.conf'\n  });\n} else {\n  j._loader.missing.push('unified_config');\n  j._loader.errors.push(data5Result.error || 'data5: invalid unified_config format');\n}\n\nconst data6Result = safeParseJson(j.data6, 'data6 (rules)');\nif (data6Result.ok && validateRules(data6Result.data)) {\n  j.rules = data6Result.data;\n  j._loader.sources.rules = 'json.data6';\n} else {\n  j._loader.missing.push('rules');\n  j._loader.errors.push(data6Result.error || 'data6: invalid rules format');\n}\n\nif (j._loader.missing.length > 0) {\n  console.error('Load_Config: Missing required files:', j._loader.missing);\n  console.error('Error details:', j._loader.errors);\n  if (j._loader.warnings.length > 0) {\n    console.warn('Config warnings:', j._loader.warnings);\n  }\n  \n  return [{\n    json: {\n      ...j,\n      configError: true,\n      decision: { decision: 'ALLOW', reason: 'CONFIG_ERROR' },\n      error_message: `Missing required files: ${j._loader.missing.join(', ')}`\n    },\n    pairedItem: 0\n  }];\n}\n\nif (j._loader.warnings.length > 0) {\n  console.info('Config loaded with warnings:', j._loader.warnings);\n}\n\nreturn [{ json: j, pairedItem: 0 }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3600,
        -1008
      ],
      "id": "cc459d0c-d9c7-4310-aefc-be14d50e1355",
      "name": "Config Loader"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "numberInputs": 7,
        "options": {
          "includeUnpaired": true
        }
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -3808,
        -1024
      ],
      "id": "12c7beb3-77fa-4607-bd9d-4e75df5c0127",
      "name": "Merge"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b6fecd17-5c91-41b2-a235-85ac60cb4dc5",
              "name": "chat_payload",
              "value": "={{ {\n    chatInput: $json.body.chatInput || $json.chatInput || $json.text || \"\",\n    sessionId: $json.body.sessionId || $json.sessionId || $now.format('x'),\n    action: $json.body.action || $json.action || \"sendMessage\"\n  } }}",
              "type": "object"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -4800,
        -1040
      ],
      "id": "565ab5a1-d03e-4b33-8724-0a75face20fe",
      "name": "Keep only set"
    },
    {
      "parameters": {
        "operation": "fromJson",
        "destinationKey": "data1",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        -784
      ],
      "id": "7179c31d-ab53-4bfe-8a2f-af09224fea90",
      "name": "Extract from File"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data2",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        -592
      ],
      "id": "4b4cd9f3-d8f0-4694-9c35-8dc5397e7b9d",
      "name": "Extract from File1"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Normalize_Node - Production version with decodeNested()\n * FIXED: Added encoding bypass detection (base64, URL, hex)\n */\n\nfunction parseNormalizeConf(confText) {\n  const lines = (confText || \"\").split(/\\r?\\n/);\n  const map = new Map();\n  const leetChar = new Map();\n  const leetSingle = new Map();\n\n  for (const raw of lines) {\n    const line = raw.trim();\n    if (!line || line.startsWith(\"#\")) continue;\n    let m;\n    if ((m = line.match(/^leet\\.single\\.([^=]+)=(.*)$/))) {\n      leetSingle.set(m[1], m[2]);\n      continue;\n    }\n    if ((m = line.match(/^leet\\.char\\.([^=]+)=(.*)$/))) {\n      leetChar.set(m[1], m[2]);\n      continue;\n    }\n    const eq = line.indexOf(\"=\");\n    if (eq >= 0) {\n      const lhs = line.slice(0, eq);\n      const rhs = line.slice(eq + 1) || '';\n      const from = lhs.replace(/\\\\u\\{?([0-9A-Fa-f]{4,6})\\}?/g, (_, h) =>\n        String.fromCodePoint(parseInt(h, 16)),\n      );\n      const to = rhs.replace(/\\\\u\\{?([0-9A-Fa-f]{4,6})\\}?/g, (_, h) =>\n        String.fromCodePoint(parseInt(h, 16)),\n      );\n      map.set(from, to);\n    }\n  }\n  return { map, leetChar, leetSingle };\n}\n\n/**\n * decodeNested - Detects and decodes multiple encoding layers\n * Handles: URL encoding (double/triple), base64, hex\n */\nfunction decodeNested(input) {\n  let current = input;\n  let decoded = input;\n  const decodingSteps = [];\n  let changed = true;\n  let iterations = 0;\n  const MAX_ITERATIONS = 5; // Support multi-level encoding (was 3)\n\n  while (changed && iterations < MAX_ITERATIONS) {\n    changed = false;\n    iterations++;\n\n    // 1. URL Decode (multi-level)\n    try {\n      const urlDecoded = decodeURIComponent(current);\n      if (urlDecoded !== current) {\n        decodingSteps.push({ type: 'url', iteration: iterations });\n        current = urlDecoded;\n        decoded = urlDecoded;\n        changed = true;\n        continue;\n      }\n    } catch (e) {\n      // Invalid URL encoding - skip\n    }\n\n    // 2. Base64 Decode (with validation)\n    // FIXED: Match embedded base64 substrings (32+ chars) AND handle case-insensitive\n    const base64Pattern = /[A-Za-z0-9+/]{32,}={0,2}/;\n    const base64Match = current.match(base64Pattern);\n    if (base64Match) {\n      try {\n        const b64String = base64Match[0];\n        // Use Buffer for better compatibility than atob\n        const b64Decoded = (typeof Buffer !== 'undefined') ?\n          Buffer.from(b64String, 'base64').toString('utf-8') :\n          atob(b64String);\n\n        // Check if decoded result contains printable ASCII (likely malicious text)\n        if (b64Decoded && /[\\x20-\\x7E]{5,}/.test(b64Decoded)) {\n          decodingSteps.push({ type: 'base64', iteration: iterations, originalSubstr: b64String.substring(0, 30) });\n          // Replace base64 substring with decoded content\n          current = current.replace(b64String, b64Decoded);\n          decoded = current;\n          changed = true;\n          continue;\n        }\n      } catch (e) {\n        // Not valid base64 - skip\n      }\n    }\n\n    // 3. Hex Decode (0x prefix or pure hex)\n    const hexPattern = /^(?:0x)?([A-Fa-f0-9]{16,})$/;\n    const hexMatch = current.trim().match(hexPattern);\n    if (hexMatch) {\n      try {\n        const hexStr = hexMatch[1];\n        let hexDecoded = '';\n        for (let i = 0; i < hexStr.length; i += 2) {\n          hexDecoded += String.fromCharCode(parseInt(hexStr.substr(i, 2), 16));\n        }\n        // Check if decoded contains printable ASCII\n        if (hexDecoded && /[\\x20-\\x7E]{5,}/.test(hexDecoded)) {\n          decodingSteps.push({ type: 'hex', iteration: iterations });\n          current = hexDecoded;\n          decoded = hexDecoded;\n          changed = true;\n          continue;\n        }\n      } catch (e) {\n        // Invalid hex - skip\n      }\n    }\n  }\n\n  return {\n    decoded: decoded,\n    originalLength: input.length,\n    decodedLength: decoded.length,\n    steps: decodingSteps,\n    levelsDetected: decodingSteps.length\n  };\n}\n\nfunction stripZeroWidth(s) {\n  return s.replace(/[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\uFEFF]/g, \"\");\n}\n\nfunction collapseWhitespace(s) {\n  return s.replace(/\\s+/g, \" \").trim();\n}\n\nfunction hasMathAlnumSymbols(s) {\n  for (const ch of s) {\n    const cp = ch.codePointAt(0);\n    if (cp >= 0x1D400 && cp <= 0x1D7FF) return true;\n  }\n  return false;\n}\n\n/**\n * detectMixedScripts - Enhanced polyglot attack detection\n * Detects mixing of multiple writing systems (11 scripts total)\n * Returns: { detected: boolean, scripts: string[], count: number, suspicionBonus: number, signal: string }\n */\nfunction detectMixedScripts(text) {\n  const scriptRanges = {\n    latin: [\n      [0x0041, 0x007A],  // Basic Latin (A-Z, a-z)\n      [0x00C0, 0x024F]   // Latin Extended-A/B\n    ],\n    cyrillic: [\n      [0x0400, 0x04FF],  // Cyrillic\n      [0x0500, 0x052F]   // Cyrillic Supplement\n    ],\n    greek: [\n      [0x0370, 0x03FF],  // Greek and Coptic\n      [0x1F00, 0x1FFF]   // Greek Extended\n    ],\n    arabic: [\n      [0x0600, 0x06FF],  // Arabic\n      [0x0750, 0x077F],  // Arabic Supplement\n      [0xFB50, 0xFDFF],  // Arabic Presentation Forms-A\n      [0xFE70, 0xFEFF]   // Arabic Presentation Forms-B\n    ],\n    hebrew: [\n      [0x0590, 0x05FF]   // Hebrew\n    ],\n    thai: [\n      [0x0E00, 0x0E7F]   // Thai\n    ],\n    hangul: [\n      [0xAC00, 0xD7AF],  // Hangul Syllables\n      [0x1100, 0x11FF]   // Hangul Jamo\n    ],\n    hiragana: [\n      [0x3040, 0x309F]   // Hiragana\n    ],\n    katakana: [\n      [0x30A0, 0x30FF]   // Katakana\n    ],\n    cjk: [\n      [0x4E00, 0x9FFF],  // CJK Unified Ideographs\n      [0x3400, 0x4DBF]   // CJK Extension A\n    ],\n    emoji: [\n      [0x1F300, 0x1F9FF], // Emoticons, Symbols, Pictographs\n      [0x2600, 0x26FF],   // Miscellaneous Symbols\n      [0x2700, 0x27BF]    // Dingbats\n    ]\n  };\n\n  const detectedScripts = new Set();\n\n  // Scan text for scripts\n  for (const ch of text) {\n    const cp = ch.codePointAt(0);\n    \n    for (const [scriptName, ranges] of Object.entries(scriptRanges)) {\n      for (const [start, end] of ranges) {\n        if (cp >= start && cp <= end) {\n          detectedScripts.add(scriptName);\n          break;\n        }\n      }\n    }\n  }\n\n  const scriptsArray = Array.from(detectedScripts).sort();\n  const scriptCount = scriptsArray.length;\n\n  // Calculate suspicion bonus\n  let suspicionBonus = 0;\n  let signal = '';\n\n  if (scriptCount >= 3) {\n    suspicionBonus = 30;  // 3+ scripts = high suspicion\n    const first3 = scriptsArray.slice(0, 3);\n    signal = 'mixed-scripts-' + first3.join('-') + '+';\n  } else if (scriptCount === 2) {\n    // FIXED (Faza 2.3): Don't flag emoji+Latin as suspicious (normal use case)\n    // Only flag emoji with non-Latin scripts OR 2 non-emoji scripts\n    const hasEmoji = scriptsArray.includes('emoji');\n    const hasLatin = scriptsArray.includes('latin');\n    \n    if (hasEmoji && hasLatin && scriptCount === 2) {\n      // Emoji + Latin only = benign (e.g., \"Hello 👋\", \"Great job! 🎉\")\n      suspicionBonus = 0;\n      signal = '';\n    } else {\n      // Emoji + other script OR 2 non-emoji scripts = suspicious\n      suspicionBonus = 15;\n      signal = 'mixed-scripts-' + scriptsArray[0] + '-' + scriptsArray[1];\n    }\n  }\n\n  return {\n    detected: scriptCount >= 2,\n    scripts: scriptsArray,\n    count: scriptCount,\n    suspicionBonus: suspicionBonus,\n    signal: signal\n  };\n}\n\nfunction htmlDecodeIfNeeded(s, decode) {\n  if (!decode) return s;\n  return s\n    .replace(/&nbsp;/g, \" \")\n    .replace(/&amp;/g, \"&\")\n    .replace(/&lt;/g, \"<\")\n    .replace(/&gt;/g, \">\")\n    .replace(/&#(\\d+);/g, (_, d) => String.fromCodePoint(parseInt(d, 10)))\n    .replace(/&#x([0-9A-Fa-f]+);/g, (_, h) => String.fromCodePoint(parseInt(h, 16)));\n}\n\nfunction applyMap(s, mp) {\n  if (!mp || mp.size === 0) return s;\n  const keys = [...mp.keys()].sort((a, b) => b.length - a.length);\n  for (const k of keys) {\n    if (!k) continue;\n    const v = mp.get(k);\n    const re = new RegExp(k.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\"), \"g\");\n    s = s.replace(re, v);\n  }\n  return s;\n}\n\nfunction casefold(s) {\n  return s.toLocaleLowerCase(\"en\");\n}\n\n/**\n * detectObfuscation - Detects whitespace obfuscation BEFORE normalization\n * Returns: { detected: boolean, score: number, flags: object, signals: string[] }\n */\nfunction detectObfuscation(text) {\n  let obfuscationScore = 0;\n  const flags = {\n    zeroWidth: false,\n    excessiveSpacing: false,\n    spacedOutLetters: false\n  };\n  const signals = [];\n\n  // 1. Zero-width character detection\n  const zeroWidthPattern = /[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\uFEFF]/;\n  if (zeroWidthPattern.test(text)) {\n    flags.zeroWidth = true;\n    obfuscationScore += 25;\n    signals.push('zero-width-chars');\n\n    // Count zero-width characters\n    const zwCount = (text.match(new RegExp(zeroWidthPattern, 'g')) || []).length;\n    if (zwCount > 5) {\n      obfuscationScore += 10;  // Heavy use of zero-width\n      signals.push('zero-width-heavy');\n    }\n  }\n\n  // 2. Excessive spacing detection (3+ consecutive spaces)\n  if (/\\s{3,}/.test(text)) {\n    flags.excessiveSpacing = true;\n    obfuscationScore += 15;\n    signals.push('excessive-spacing');\n  }\n\n  // 3. Spaced-out letters detection (e.g., \"i g n o r e\")\n  // Look for pattern: letter + space + letter + space + letter (at least 5 chars with spaces)\n  const spacedLetterPattern = /\\b[a-zA-Z]\\s+[a-zA-Z]\\s+[a-zA-Z]\\s+[a-zA-Z]\\s+[a-zA-Z]/;\n  if (spacedLetterPattern.test(text)) {\n    flags.spacedOutLetters = true;\n    obfuscationScore += 20;\n    signals.push('spaced-out-letters');\n  }\n\n  return {\n    detected: obfuscationScore > 0,\n    score: obfuscationScore,\n    flags: flags,\n    signals: signals\n  };\n}\n\nfunction buildSignals(original, beforeHomoglyphMap, afterLeet, final, decodingResult, mixedScriptsResult) {\n  const sigs = [];\n\n  // Existing signals\n  if (original.length !== stripZeroWidth(original).length) sigs.push(\"zero-width-removed\");\n  if (hasMathAlnumSymbols(original) || hasMathAlnumSymbols(afterLeet)) sigs.push(\"math-alnum/fraktur\");\n  if (mixedScriptsResult && mixedScriptsResult.detected) {\n    sigs.push(mixedScriptsResult.signal);\n  }\n  if (/[A-Za-z]/.test(original) && /[0-9]/.test(original) && /[@$%|]/.test(original)) sigs.push(\"leet-like-mix\");\n  \n  const separators = beforeHomoglyphMap.match(/(?:_{3,}|-{3,}|\\.{3,}|={3,}|\\*{3,}){1,}/g);\n  if (separators && separators.length >= 3) sigs.push(\"separator-abuse\");\n\n  if (/(?:<\\|\\/?(system|assistant|user|user_query)\\|>|\\{\\{\\s*system\\s*\\}\\}|\\[\\[\\s*system\\s*\\]\\])/.test(beforeHomoglyphMap)) {\n    sigs.push(\"template-markers\");\n  }\n\n  // NEW: Encoding detection signals\n  if (decodingResult && decodingResult.levelsDetected > 0) {\n    sigs.push(`encoding-detected-${decodingResult.levelsDetected}-levels`);\n    decodingResult.steps.forEach(step => {\n      sigs.push(`encoding-${step.type}`);\n    });\n  }\n  \n  return sigs;\n}\n\n// FIXED: Added items declaration\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Normalize_Node: No input items');\n  return [];\n}\n\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const cfg = (j.config ?? {});\n  const ncfg = cfg.normalization ?? {};\n  const confText = j.normalization_text || \"\";\n  const { map, leetChar, leetSingle } = parseNormalizeConf(confText);\n\n  const input =\n    j?.chat_payload?.chatInput ??\n    j?.chatInput ??\n    j?.input ??\n    \"\";\n\n  const steps = [];\n  let s = String(input);\n  const original = s;\n\n  // **NEW: Detect obfuscation BEFORE any normalization**\n  const obfuscationDetected = detectObfuscation(s);\n\n  // **NEW: Decode nested encodings FIRST**\n  const decodingResult = decodeNested(s);\n  if (decodingResult.levelsDetected > 0) {\n    s = decodingResult.decoded;\n    steps.push({ \n      step: \"decode_nested\", \n      levels: decodingResult.levelsDetected,\n      decodingSteps: decodingResult.steps,\n      originalLen: decodingResult.originalLength,\n      decodedLen: decodingResult.decodedLength\n    });\n  }\n\n  s = htmlDecodeIfNeeded(s, !!ncfg.decode_entities);\n  steps.push({ step: \"html_decode\", outLen: s.length });\n\n  try {\n    s = s.normalize(\"NFKC\");\n  } catch {}\n  steps.push({ step: \"nfkc\", outLen: s.length });\n\n  s = casefold(s);\n  steps.push({ step: \"casefold\", outLen: s.length });\n\n  if (ncfg.remove_zero_width !== false) {\n    const s0 = s;\n    s = stripZeroWidth(s);\n    if (s !== s0) steps.push({ step: \"strip_zwsp\", removed: s0.length - s.length });\n  }\n\n  const beforeHomoglyphMap = s;\n\n  s = applyMap(s, map);\n  steps.push({ step: \"homoglyph_map\", outLen: s.length });\n\n  const HEART_PLACEHOLDER = '\\uE000HEART\\uE001';\n  s = s.replace(/<3/g, HEART_PLACEHOLDER);\n  \n  if (leetChar.size) {\n    for (const [k, v] of leetChar.entries()) {\n      if (!k) continue;\n      const re = new RegExp(k.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\"), \"g\");\n      s = s.replace(re, v);\n    }\n    steps.push({ step: \"leet.char\", outLen: s.length });\n  }\n  \n  s = s.replace(new RegExp(HEART_PLACEHOLDER, 'g'), '<3');\n\n  const afterLeet = s;\n\n  if (leetSingle.size) {\n    const tokens = s.split(/(\\b)/);\n    for (let i = 0; i < tokens.length; i++) {\n      const t = tokens[i];\n      if (/^\\b$/.test(t)) continue;\n      const mapped = leetSingle.get(t);\n      if (mapped) tokens[i] = mapped;\n    }\n    s = tokens.join(\"\");\n    steps.push({ step: \"leet.single\", outLen: s.length });\n  }\n\n  if (ncfg.collapse_whitespace !== false) {\n    s = collapseWhitespace(s);\n    steps.push({ step: \"collapse_ws\", outLen: s.length });\n  }\n\n  const canonical = s;\n\n  // FIXED: Use decoded text for scoring IF encoding was detected\n  // This ensures Pattern_Matching_Engine analyzes the actual malicious content\n  let forScoring = canonical;\n  if (decodingResult.levelsDetected > 0) {\n    // Apply same normalization to decoded text before scoring\n    let decodedForScoring = decodingResult.decoded;\n\n    // Apply critical normalization steps\n    try {\n      decodedForScoring = decodedForScoring.normalize(\"NFKC\");\n    } catch {}\n\n    decodedForScoring = casefold(decodedForScoring);\n    decodedForScoring = stripZeroWidth(decodedForScoring);\n    decodedForScoring = applyMap(decodedForScoring, map);\n    decodedForScoring = collapseWhitespace(decodedForScoring);\n\n    forScoring = decodedForScoring;\n  }\n\n  // Polyglot attack detection (moved before buildSignals)\n  const mixedScriptsResult = detectMixedScripts(original);\n  \n  const signals = buildSignals(original, beforeHomoglyphMap, afterLeet, canonical, decodingResult, mixedScriptsResult);\n\n  j._pipeline_snapshots = j._pipeline_snapshots || {};\n  j._pipeline_snapshots.input_raw = original;\n  j._pipeline_snapshots.input_normalized = canonical;\n  if (decodingResult.levelsDetected > 0) {\n    j._pipeline_snapshots.input_decoded = decodingResult.decoded;\n  }\n\n  j.normalization = {\n    original: original,\n    normalized: canonical,\n    canonical: canonical,\n    forScoring: forScoring,\n    steps,\n    obfuscationSignals: signals,\n    mixedScripts: mixedScriptsResult,\n    decodingDetected: decodingResult.levelsDetected > 0 ? decodingResult : null,\n    obfuscationDetected: obfuscationDetected.detected ? obfuscationDetected : null\n  };\n\n  j.chat_payload = j.chat_payload || {};\n  j.chat_payload.chatInput = canonical;\n  j.input_raw = original;\n\n  item.json = j;\n  results.push(item);\n}\n\nreturn results;\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2944,
        -1008
      ],
      "id": "09f24c45-0b0f-41e0-9e5f-a8d6a5ed24ba",
      "name": "Normalize_Node"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "583cd94d-198b-4b10-a901-b4feb6edc51a",
              "name": "sessionId",
              "value": "={{ $('Build+Sanitize NDJSON').item.json.ndjson.chat_payload.sessionId }}",
              "type": "string"
            },
            {
              "id": "998db0bf-ad74-49e7-bbad-7d720cedea60",
              "name": "chatInput",
              "value": "={{ $('Build+Sanitize NDJSON').item.json.ndjson.chat_payload.chatInput || $('Build+Sanitize NDJSON').item.json.ndjson.pipeline_flow.input_raw || '' }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        928,
        -1008
      ],
      "id": "a9a83eb7-5639-4aa5-a20c-69bfcba5d129",
      "name": "Clean output"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/normalize.conf",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        -592
      ],
      "id": "21b28d1c-ee14-414d-b7d1-aebe17019a66",
      "name": "Loading config files *.conf"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/allowlist.schema.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        -784
      ],
      "id": "8a15edc8-2bf4-4a1e-b8ba-795d847f8f45",
      "name": "Loading config files *.json"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Unified Decision Engine - FIXED: Added items declaration, score validation\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n  \n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n  \n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\n// FIXED: Added items declaration\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Unified Decision Engine: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json || {};\n  \n  // Skip processing if already blocked by validator\n  if (j.configError === true || j._isBlocked === true) {\n    out.push(item);\n    continue;\n  }\n  \n  // Validate score (handle NaN, Infinity, wrong types)\n  let score = 0;\n  const rawScore = j.score;\n  \n  if (typeof rawScore === 'number' && !isNaN(rawScore) && isFinite(rawScore)) {\n    score = Math.max(0, Math.min(100, rawScore));\n  } else if (typeof rawScore === 'string') {\n    const parsed = parseFloat(rawScore);\n    score = (!isNaN(parsed) && isFinite(parsed)) ? Math.max(0, Math.min(100, parsed)) : 0;\n  } else {\n    score = 0;\n  }\n  \n  if (score !== rawScore) {\n    console.warn(`Invalid score detected: ${rawScore}, normalized to ${score}`);\n  }\n  \n  const scoreBreakdown = j.scoreBreakdown ?? {};\n  const thresholds = j.thresholds || {};\n  \n  const ranges = (thresholds && thresholds.ranges) || {\n    allow: { min: 0, max: 29 },\n    sanitize_light: { min: 30, max: 55 },\n    sanitize_heavy: { min: 56, max: 75 },\n    block: { min: 76, max: 100 },\n  };\n\n  let decision = 'ALLOW';\n  if (score >= ranges.block.min) decision = 'BLOCK';\n  else if (score >= ranges.sanitize_heavy.min) decision = 'SANITIZE_HEAVY';\n  else if (score >= ranges.sanitize_light.min) decision = 'SANITIZE_LIGHT';\n\n  mergeDecision(j, decision, 'unified_decision_engine', {\n    score: score,\n    scoreBreakdown: scoreBreakdown,\n    reason: decision === 'ALLOW' ? 'OK' : 'POLICY'\n  });\n\n  // FIX 2.5.1: Set unified_decision.threat_score for sliding window gating\n  j.unified_decision = {\n    threat_score: score,\n    decision: decision,\n    ranges_used: ranges\n  };\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1968,
        -1008
      ],
      "id": "ead5b178-108f-4df6-b0f9-0b1d6330f10d",
      "name": "Unified Decision Engine"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Allowlist_Validator - FIXED: Better error handling, English messages\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n  \n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n  \n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\nfunction validateJsonSchema(data, schema) {\n  if (!schema || !schema.required) return { valid: true, errors: [] };\n  \n  const errors = [];\n  for (const field of schema.required || []) {\n    if (!(field in data)) {\n      errors.push(`Missing required field: ${field}`);\n    }\n  }\n  \n  if (schema.properties) {\n    for (const [key, propSchema] of Object.entries(schema.properties)) {\n      if (key in data) {\n        const value = data[key];\n        const expectedType = Array.isArray(propSchema.type) ? propSchema.type : [propSchema.type];\n        const actualType = value === null ? 'null' : typeof value === 'object' && Array.isArray(value) ? 'array' : typeof value;\n        \n        if (!expectedType.includes(actualType) && !(expectedType.includes('null') && value === null)) {\n          errors.push(`Field ${key}: expected ${expectedType.join('|')}, got ${actualType}`);\n        }\n      }\n    }\n  }\n  \n  return { valid: errors.length === 0, errors };\n}\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Allowlist_Validator: No input items');\n  return [];\n}\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const schema = j.allowlist_schema || null;\n  \n  const hasInput = !!(j.chat_payload && typeof j.chat_payload.chatInput === \"string\" && j.chat_payload.chatInput.length >= 0);\n  \n  let schemaValid = true;\n  let schemaErrors = [];\n  \n  if (schema && hasInput) {\n    const validation = validateJsonSchema(j, schema);\n    schemaValid = validation.valid;\n    schemaErrors = validation.errors;\n  }\n  \n  const ok = hasInput && schemaValid;\n  \n  j.validation = {\n    ok,\n    errors: ok ? [] : [\n      ...(!hasInput ? [\"chat_payload_missing_or_invalid\"] : []),\n      ...schemaErrors\n    ],\n    enforced: true,\n    schemaVersion: schema ? (schema.$schema || \"unknown\") : \"none\",\n  };\n  \n  if (!ok) {\n    j.configError = true;\n    \n    mergeDecision(j, 'BLOCK', 'allowlist_validator', {\n      validation_failed: true,\n      validation_errors: j.validation.errors,\n      processingMs: 0\n    });\n    \n    if (j.config?.enforcement?.block_message) {\n      j.chat_payload = j.chat_payload || {};\n      j.chat_payload.chatInput = j.config.enforcement.block_message;\n    }\n  }\n  \n  item.json = j;\n}\n\nreturn items;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2464,
        -1008
      ],
      "id": "c6766b05-21b7-4026-b60a-46533ea04225",
      "name": "Allowlist_Validator"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Sanitization_Enforcement - VERSION 2.0\n *\n * FIXED: Now uses ACTUAL detected patterns from Pattern_Matching_Engine\n * instead of hardcoded patterns in unified_config.json\n *\n * Strategy:\n * - SANITIZE_LIGHT: Remove patterns from LOW/MEDIUM severity categories\n * - SANITIZE_HEAVY: Remove patterns from ALL detected categories\n * - Uses matchDetails from Pattern_Matching_Engine to get actual regex patterns\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n\n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n\n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\n/**\n * Category severity mapping for LIGHT sanitization\n * LOW/MEDIUM categories will be removed in LIGHT mode\n * HIGH/CRITICAL categories will be removed in HEAVY mode\n */\nconst LOW_MEDIUM_CATEGORIES = [\n  \"MILD_SUSPICIOUS\",\n  \"ENCODING_SUSPICIOUS\",\n  \"FORMAT_COERCION\",\n  \"HYPOTHETICAL_ESCAPE\",\n  \"UNFILTERED_REQUEST\",\n  \"REBEL_RESPONSE\",\n  \"ENCODING_INDICATORS\",\n  \"JAILBREAK_ATTEMPT\",\n  \"GODMODE_JAILBREAK\",\n  \"EXPLICIT_JAILBREAK\"\n];\n\nconst HIGH_CRITICAL_CATEGORIES = [\n  \"CRITICAL_INJECTION\",\n  \"CONTROL_OVERRIDE\",\n  \"PROMPT_LEAK_ATTEMPT\",\n  \"HEAVY_OBFUSCATION\",\n  \"DANGEROUS_CONTENT\",\n  \"PROMPT_TEMPLATING_MARKERS\",\n  \"SEPARATOR_ABUSE\",\n  \"TEMPLATE_TOKEN\",\n  \"HEADER_ESCAPE\",\n  \"DIVIDER_ABUSE\",\n  \"SQL_XSS_ATTACKS\",\n  \"PRIVILEGE_ESCALATION\",\n  \"COMMAND_INJECTION\",\n  \"PATH_TRAVERSAL\",\n  \"XXE_INJECTION\",\n  \"LDAP_INJECTION\",\n  \"SSRF_ATTEMPT\",\n  \"CRLF_INJECTION\",\n  \"NOSQL_INJECTION\",\n  \"TEMPLATE_INJECTION\"\n];\n\n/**\n * Extract all unique regex patterns from matchDetails\n * @param {Array} matchDetails - Array from Pattern_Matching_Engine\n * @param {Array} categoryFilter - List of category names to include (null = all)\n * @returns {Array} Array of regex pattern strings\n */\nfunction extractPatternsFromMatches(matchDetails, categoryFilter = null) {\n  const patterns = [];\n\n  if (!matchDetails || !Array.isArray(matchDetails)) {\n    return patterns;\n  }\n\n  for (const detail of matchDetails) {\n    // Skip if category filter specified and this category not in filter\n    if (categoryFilter && !categoryFilter.includes(detail.category)) {\n      continue;\n    }\n\n    // Skip non-pattern categories (Mixed Scripts, Encoding Detection, Obfuscation Detection)\n    if (!detail.matches || !Array.isArray(detail.matches)) {\n      continue;\n    }\n\n    // Extract patterns from matches\n    for (const match of detail.matches) {\n      if (match.pattern) {\n        patterns.push(match.pattern);\n      }\n    }\n  }\n\n  return patterns;\n}\n\n/**\n * Apply sanitization using detected patterns\n * @param {string} text - Original text\n * @param {Array} patterns - Array of regex pattern strings\n * @param {string} redact - Replacement token\n * @returns {Object} {out: sanitized text, removedPct: percentage removed, removedChars: count}\n */\nfunction applySanitizeFromMatches(text, patterns, redact) {\n  if (!patterns || !patterns.length) {\n    return { out: text, removedPct: 0, removedChars: 0 };\n  }\n\n  let out = text;\n  let removed = 0;\n  const uniquePatterns = [...new Set(patterns)]; // Remove duplicates\n\n  for (const pattern of uniquePatterns) {\n    try {\n      const re = new RegExp(pattern, \"giu\");\n      out = out.replace(re, (m) => {\n        removed += m.length;\n        return redact || \"\";\n      });\n    } catch (e) {\n      console.warn(`Invalid sanitization regex: ${pattern}`, e);\n    }\n  }\n\n  const removedPct = text.length ? Math.round((removed / text.length) * 100) : 0;\n  return { out, removedPct, removedChars: removed };\n}\n\n// ============================================================================\n// MAIN LOGIC\n// ============================================================================\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Sanitization_Enforcement: No input items');\n  return [];\n}\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const decision = j.decision?.decision || \"ALLOW\";\n\n  // Skip if config error or validation failed\n  if (j.configError === true) {\n    console.error(\"Sanitization_Enforcement: Config error detected\");\n    item.json = j;\n    continue;\n  }\n\n  if (!j.config || !j.config.enforcement) {\n    console.error(\"Sanitization_Enforcement: Missing config.enforcement\");\n    j.error = \"Missing enforcement config\";\n    j.decision = { decision: \"ALLOW\", reason: \"CONFIG_ERROR\" };\n    item.json = j;\n    continue;\n  }\n\n  const inText = j.chat_payload?.chatInput ?? j.chatInput ?? \"\";\n  const sessionId = j.sessionId ?? j.chat_payload?.sessionId ?? \"unknown\";\n  const action = j.action ?? j.chat_payload?.action ?? \"sendMessage\";\n  const matchDetails = j.matchDetails || [];\n\n  let finalText = inText;\n  let mode = \"none\";\n  let removalPct = 0;\n  let patternsUsed = [];\n\n  j._pipeline_snapshots = j._pipeline_snapshots || {};\n  j._pipeline_snapshots.beforeSanitization = inText;\n\n  if (decision === \"SANITIZE_LIGHT\") {\n    // LIGHT: Remove only LOW/MEDIUM severity patterns\n    patternsUsed = extractPatternsFromMatches(matchDetails, LOW_MEDIUM_CATEGORIES);\n\n    if (patternsUsed.length === 0) {\n      console.warn(\"Sanitization_Enforcement: SANITIZE_LIGHT but no LOW/MEDIUM patterns detected\");\n      finalText = inText;\n      mode = \"light_nopatterns\";\n    } else {\n      const res = applySanitizeFromMatches(inText, patternsUsed, \"[removed]\");\n      finalText = res.out;\n      removalPct = res.removedPct;\n      mode = \"light\";\n\n      console.log(`Sanitization_Enforcement LIGHT: Removed ${res.removedChars} chars (${removalPct}%) using ${patternsUsed.length} patterns`);\n    }\n  }\n  else if (decision === \"SANITIZE_HEAVY\") {\n    // HEAVY: Remove ALL detected patterns\n    patternsUsed = extractPatternsFromMatches(matchDetails, null);\n\n    if (patternsUsed.length === 0) {\n      console.warn(\"Sanitization_Enforcement: SANITIZE_HEAVY but no patterns detected\");\n      finalText = inText;\n      mode = \"heavy_nopatterns\";\n    } else {\n      const res = applySanitizeFromMatches(inText, patternsUsed, \"[REDACTED]\");\n      removalPct = res.removedPct;\n\n      // Check if removal exceeds threshold (default: 60%)\n      const threshold = j.config.sanitization?.heavy?.max_removal_percent || 60;\n      const policy = j.config.sanitization?.heavy?.policy || \"sanitize_if_exceeds\";\n\n      if (policy === \"block_if_exceeds\" && removalPct > threshold) {\n        // TOO MUCH removed - escalate to BLOCK\n        mergeDecision(j, 'BLOCK', 'sanitization_enforcement', {\n          removal_pct: removalPct,\n          sanitizer_decision: 'SANITIZE_HEAVY',\n          blocked_by_sanitizer: true,\n          threshold_exceeded: threshold,\n          patterns_attempted: patternsUsed.length\n        });\n\n        finalText = j.config.enforcement.block_message || \"Content blocked by security policy\";\n        mode = \"blocked_excessive_removal\";\n\n        console.log(`Sanitization_Enforcement: BLOCKED due to excessive removal (${removalPct}% > ${threshold}%)`);\n      } else {\n        // Acceptable removal - proceed with sanitization\n        finalText = res.out;\n        mode = \"heavy\";\n\n        console.log(`Sanitization_Enforcement HEAVY: Removed ${res.removedChars} chars (${removalPct}%) using ${patternsUsed.length} patterns`);\n      }\n    }\n  }\n  else if (decision === \"BLOCK\") {\n    j._isBlocked = true;\n    finalText = j.config.enforcement?.block_message || \"Content blocked by security policy\";\n    mode = \"blocked\";\n  }\n  else {\n    // ALLOW - no sanitization\n    mode = \"allow\";\n  }\n\n  // Update chat_payload with sanitized text\n  j.chat_payload = j.chat_payload || {};\n  j.chat_payload.sessionId = sessionId;\n  j.chat_payload.action = action;\n  j.chat_payload.chatInput = finalText;\n\n  j._pipeline_snapshots.afterSanitization = finalText;\n\n  j.enforcement = Object.assign({}, j.enforcement, {\n    mode,\n    removalPct,\n    patternsUsed: patternsUsed.length,\n    patternsPreview: patternsUsed.slice(0, 5).map(p => p.substring(0, 30))\n  });\n\n  j.__san = {\n    sessionId,\n    action,\n    chat_payload: { sessionId, action, chatInput: finalText },\n    _pipeline_snapshots: {\n      beforeSanitization: j._pipeline_snapshots.beforeSanitization,\n      afterSanitization: j._pipeline_snapshots.afterSanitization\n    },\n    normalization: j.normalization,\n    enforcement: {\n      mode,\n      removalPct,\n      patternsUsed: patternsUsed.length,\n      heavy_policy: j.config.sanitization?.heavy?.policy || \"sanitize_if_exceeds\",\n      heavy_threshold_pct: j.config.sanitization?.heavy?.max_removal_percent || 60\n    }\n  };\n\n  j.__metadata = j.__metadata || {};\n  const finalStatus = j.decision?.decision || \"ALLOW\";\n  j.__metadata.should_run_prompt_guard = (finalStatus !== \"BLOCK\");\n\n  item.json = j;\n}\n\nreturn items;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1456,
        -1008
      ],
      "id": "47b566e0-a797-4351-b893-159057efdfd6",
      "name": "Sanitization_Enforcement"
    },
    {
      "parameters": {
        "jsCode": "/**\n * PII_Redactor - FIXED: English messages, proper error handling\n */\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('PII_Redactor: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  \n  if (j.configError === true || j._isBlocked === true) {\n    out.push(item);\n    continue;\n  }\n  \n  const piiConf = j.pii_conf;\n  if (!piiConf || !piiConf.rules) {\n    j.pii_error = \"PII_Redactor: missing pii_conf\";\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n  \n  let text = j.chat_payload?.chatInput ?? j.chatInput ?? \"\";\n  \n  if (!text) {\n    j.pii_error = \"PII_Redactor: no text to redact\";\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n  \n  let redactedText = text;\n  let redactionCount = 0;\n  const order = piiConf.order || piiConf.rules.map(r => r.name);\n  \n  for (const ruleName of order) {\n    const rule = piiConf.rules.find(r => r.name === ruleName);\n    if (!rule) continue;\n    \n    try {\n      const re = new RegExp(rule.pattern, rule.flags || 'giu');\n      const beforeText = redactedText;\n      \n      redactedText = redactedText.replace(re, rule.replacement);\n      \n      if (redactedText !== beforeText) {\n        redactionCount++;\n      }\n    } catch (e) {\n      console.warn(`PII regex failed for ${ruleName}:`, e.message);\n    }\n  }\n  \n  const hasPII = (redactedText !== text);\n  \n  if (hasPII) {\n    j.chat_payload = j.chat_payload || {};\n    j.chat_payload.chatInput = redactedText;\n  }\n  \n  j._pipeline_snapshots = j._pipeline_snapshots || {};\n  j._pipeline_snapshots.afterPII = redactedText;\n  \n  j.pii = {\n    redactedPreview: redactedText.substring(0, 200),\n    previewRedactionCount: redactionCount,\n    has: hasPII\n  };\n  \n  j.output_text_redacted = redactedText;\n  j.pii_error = null;\n  \n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3168,
        -1008
      ],
      "id": "f923534b-7e53-4005-935a-09eaee47028e",
      "name": "PII_Redactor"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Correlation_Engine - FIXED: Added items validation\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n  \n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n  \n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Correlation_Engine: No input items');\n  return [];\n}\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  \n  // Skip correlation if validation failed\n  if (j.configError === true) {\n    item.json = j;\n    continue;\n  }\n  \n  const sigs = j.normalization?.obfuscationSignals || [];\n  const dec = j.decision?.decision || \"ALLOW\";\n\n  let escalated = dec;\n  \n  if (sigs.includes(\"template-markers\")) {\n    escalated = \"BLOCK\";\n  }\n  else if (sigs.includes(\"math-alnum/fraktur\")) {\n    // Math/Fraktur obfuscation - single escalation level\n    if (dec === \"ALLOW\") escalated = \"SANITIZE_LIGHT\";\n    else if (dec === \"SANITIZE_LIGHT\") escalated = \"SANITIZE_HEAVY\";\n    else if (dec === \"SANITIZE_HEAVY\") escalated = \"BLOCK\";\n  }\n  else {\n    // Mixed scripts detection (Phase 2.1) - 4-level escalation based on script count\n    const mixedScriptsSig = sigs.find(s => s.startsWith(\"mixed-scripts-\"));\n    if (mixedScriptsSig) {\n      const is3PlusScripts = mixedScriptsSig.endsWith('+');\n      \n      if (is3PlusScripts) {\n        // 3+ scripts = CRITICAL threat (30 pts bonus) - double escalation\n        if (dec === \"ALLOW\") escalated = \"SANITIZE_HEAVY\";  // Skip LIGHT\n        else if (dec === \"SANITIZE_LIGHT\") escalated = \"BLOCK\";  // Skip HEAVY\n        else if (dec === \"SANITIZE_HEAVY\") escalated = \"BLOCK\";\n      } else {\n        // 2 scripts = HIGH threat (15 pts bonus) - single escalation\n        if (dec === \"ALLOW\") escalated = \"SANITIZE_LIGHT\";\n        else if (dec === \"SANITIZE_LIGHT\") escalated = \"SANITIZE_HEAVY\";\n        else if (dec === \"SANITIZE_HEAVY\") escalated = \"BLOCK\";\n      }\n    }\n  }\n\n  const correlationReason = escalated !== dec \n    ? `ESCALATED_FROM_${dec}_BY_SIGNALS_${sigs.join(',')}` \n    : (j.decision?.reason || 'POLICY');\n\n  j.correlation = { \n    signals: sigs, \n    before: dec, \n    after: escalated,\n    escalated: escalated !== dec\n  };\n  \n  mergeDecision(j, escalated, 'correlation_engine', {\n    correlation_applied: escalated !== dec,\n    correlation_signals: sigs,\n    previous_decision: dec,\n    reason: correlationReason,\n    escalated_by_correlation: escalated !== dec\n  });\n  \n  item.json = j;\n}\n\nreturn items;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1728,
        -1008
      ],
      "id": "e4b6227b-d204-4122-b5e1-e89b4b6122b6",
      "name": "Correlation_Engine"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Pattern_Matching_Engine - OPTIMIZED VERSION (Faza 2.2)\n *\n * OPTIMIZATIONS:\n * 1. Pre-compilation: Regex patterns compiled once and cached\n * 2. Early exit: Loop breaks when totalScore >= 100\n * 3. Category sorting: Process high-weight categories first for faster exit\n *\n * Target: 20% latency reduction on P95\n */\n\n// ============================================================================\n// GLOBAL REGEX CACHE - Persists across workflow executions\n// ============================================================================\n// Note: In n8n Code nodes, global variables persist during the workflow run\n// but are cleared when workflow is restarted. This is acceptable for caching.\nif (typeof globalThis.COMPILED_PATTERNS_CACHE === 'undefined') {\n  globalThis.COMPILED_PATTERNS_CACHE = new Map();\n  globalThis.CACHE_STATS = { hits: 0, misses: 0, compilations: 0 };\n}\n\n/**\n * Safe regex compilation with caching\n * @param {string} pattern - Regex pattern string\n * @param {string} flags - Regex flags (default: 'giu')\n * @returns {RegExp|null} Compiled regex or null if invalid\n */\nfunction safeRegexCached(pattern, flags = 'giu') {\n  const cacheKey = `${pattern}|||${flags}`;\n\n  // Check cache first\n  if (globalThis.COMPILED_PATTERNS_CACHE.has(cacheKey)) {\n    globalThis.CACHE_STATS.hits++;\n    return globalThis.COMPILED_PATTERNS_CACHE.get(cacheKey);\n  }\n\n  // Cache miss - compile new regex\n  globalThis.CACHE_STATS.misses++;\n  try {\n    const regex = new RegExp(pattern, flags);\n    globalThis.COMPILED_PATTERNS_CACHE.set(cacheKey, regex);\n    globalThis.CACHE_STATS.compilations++;\n    return regex;\n  } catch (e) {\n    console.warn(`Invalid regex pattern: ${pattern}`, e);\n    // Cache the null result to avoid recompiling invalid patterns\n    globalThis.COMPILED_PATTERNS_CACHE.set(cacheKey, null);\n    return null;\n  }\n}\n\n/**\n * Calculate category score based on match count\n */\nfunction calculateCategoryScore(baseWeight, multiplier, matchCount) {\n  if (matchCount === 0) return 0;\n  return Math.round(baseWeight * Math.pow(multiplier, matchCount - 1));\n}\n\n// ============================================================================\n// MAIN PROCESSING LOGIC\n// ============================================================================\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Pattern_Matching_Engine: No input items');\n  return [];\n}\n\nconst out = [];\nconst startTime = Date.now(); // Track overall execution time\n\nfor (const item of items) {\n  const itemStartTime = Date.now();\n  const j = item.json ?? {};\n\n  // Skip only if config error (not if already blocked - we still want to add detection metadata)\n  if (j.configError === true) {\n    out.push(item);\n    continue;\n  }\n\n  // Check if already blocked (will skip pattern matching but still add detection bonuses)\n  const alreadyBlocked = (j._isBlocked === true);\n\n  const text = j.normalization?.forScoring ?? j.chat_payload?.chatInput ?? \"\";\n  const rules = j.rules?.categories ?? {};\n\n  if (!text) {\n    j.scoreBreakdown = {};\n    j.score = 0;\n    j._performance = { patternMatchingMs: 0, earlyExitTriggered: false };\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n\n  const scoreBreakdown = {};\n  let totalScore = 0;\n  const matchDetails = [];\n  let earlyExitTriggered = false;\n  let categoriesProcessed = 0;\n\n  // Only run expensive pattern matching if NOT already blocked\n  if (!alreadyBlocked) {\n    // OPTIMIZATION: Sort categories by base_weight DESC for faster early exit\n    const sortedCategories = Object.entries(rules).sort((a, b) => {\n      const weightA = a[1].base_weight || 0;\n      const weightB = b[1].base_weight || 0;\n      return weightB - weightA; // Descending order\n    });\n\n    // Iterate through categories (highest weight first)\n    for (const [categoryName, categoryData] of sortedCategories) {\n      const { base_weight, multiplier, patterns } = categoryData;\n\n      if (!patterns || !Array.isArray(patterns)) continue;\n\n      categoriesProcessed++;\n      let categoryMatchCount = 0;\n      const categoryMatches = [];\n\n      // Iterate through patterns in category\n      for (const pattern of patterns) {\n        const re = safeRegexCached(pattern, 'giu');\n        if (!re) continue;\n\n        // Reset lastIndex for global regex (important!)\n        re.lastIndex = 0;\n        const matches = text.match(re);\n\n        if (matches && matches.length > 0) {\n          categoryMatchCount += matches.length;\n          categoryMatches.push({\n            pattern: pattern.substring(0, 50),\n            count: matches.length,\n            samples: matches.slice(0, 3).map(m => m.substring(0, 50) + (m.length > 50 ? '...' : ''))\n          });\n        }\n      }\n\n      // Add category score if matches found\n      if (categoryMatchCount > 0) {\n        const categoryScore = calculateCategoryScore(base_weight, multiplier, categoryMatchCount);\n        scoreBreakdown[categoryName] = categoryScore;\n        totalScore += categoryScore;\n\n        matchDetails.push({\n          category: categoryName,\n          matchCount: categoryMatchCount,\n          score: categoryScore,\n          matches: categoryMatches\n        });\n      }\n\n      // OPTIMIZATION: Early exit if score already at maximum\n      if (totalScore >= 100) {\n        earlyExitTriggered = true;\n        break;\n      }\n    }\n  }\n\n  // Add suspicion bonus from mixed scripts detection\n  const mixedScripts = j.normalization?.mixedScripts || {};\n  if (mixedScripts.suspicionBonus > 0) {\n    totalScore += mixedScripts.suspicionBonus;\n    matchDetails.push({\n      category: \"Mixed Scripts\",\n      score: mixedScripts.suspicionBonus,\n      matches: [mixedScripts.signal]\n    });\n  }\n\n  // Add encoding detection bonus (ENHANCED: Higher scores for suspicious encoding)\n  const decodingDetected = j.normalization?.decodingDetected || {};\n  if (decodingDetected.levelsDetected > 0) {\n    // Calculate bonus based on encoding types (base64 is VERY suspicious in prompts)\n    let encodingBonus = 0;\n    const encodingTypes = [];\n\n    for (const step of decodingDetected.steps) {\n      encodingTypes.push(step.type);\n      if (step.type === 'base64') {\n        encodingBonus += 45;  // Base64 in prompts is HIGHLY suspicious\n      } else if (step.type === 'url') {\n        encodingBonus += 30;  // URL encoding in prompts is very suspicious\n      } else if (step.type === 'hex') {\n        encodingBonus += 35;  // Hex encoding is quite suspicious\n      }\n    }\n\n    totalScore += encodingBonus;\n    matchDetails.push({\n      category: \"Encoding Detection\",\n      score: encodingBonus,\n      matches: [`${decodingDetected.levelsDetected} layer(s): ${encodingTypes.join(', ')}`]\n    });\n    scoreBreakdown[\"ENCODING_DETECTED\"] = encodingBonus;\n  }\n\n  // Add obfuscation detection bonus (whitespace, zero-width chars)\n  const obfuscationDetected = j.normalization?.obfuscationDetected || {};\n  if (obfuscationDetected.detected && obfuscationDetected.score > 0) {\n    totalScore += obfuscationDetected.score;\n    matchDetails.push({\n      category: \"Obfuscation Detection\",\n      score: obfuscationDetected.score,\n      matches: obfuscationDetected.signals\n    });\n    scoreBreakdown[\"OBFUSCATION_DETECTED\"] = obfuscationDetected.score;\n  }\n\n  // Cap score at 100\n  if (totalScore > 100) totalScore = 100;\n\n  // Calculate item processing time\n  const itemProcessingMs = Date.now() - itemStartTime;\n\n  // Store results\n  j.scoreBreakdown = scoreBreakdown;\n  j.score = totalScore;\n  j.matchDetails = matchDetails;\n  j._performance = {\n    patternMatchingMs: itemProcessingMs,\n    earlyExitTriggered: earlyExitTriggered,\n    categoriesProcessed: categoriesProcessed,\n    totalCategories: Object.keys(rules).length,\n    cacheStats: {\n      hits: globalThis.CACHE_STATS.hits,\n      misses: globalThis.CACHE_STATS.misses,\n      compilations: globalThis.CACHE_STATS.compilations,\n      cacheSize: globalThis.COMPILED_PATTERNS_CACHE.size\n    }\n  };\n\n  item.json = j;\n  out.push(item);\n}\n\n// Log overall execution stats\nconst totalExecutionMs = Date.now() - startTime;\nconsole.log(`Pattern_Matching_Engine OPTIMIZED: Processed ${items.length} items in ${totalExecutionMs}ms (avg: ${(totalExecutionMs / items.length).toFixed(2)}ms/item)`);\nconsole.log(`Cache stats: ${globalThis.CACHE_STATS.hits} hits, ${globalThis.CACHE_STATS.misses} misses, ${globalThis.CACHE_STATS.compilations} compilations, ${globalThis.COMPILED_PATTERNS_CACHE.size} cached patterns`);\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2224,
        -1008
      ],
      "id": "e8a5f2e1-2807-4512-9693-98986cc64c3b",
      "name": "Pattern_Matching_Engine"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data3",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        -384
      ],
      "id": "ee3684fd-b155-4a12-835b-f518abedbb7b",
      "name": "Extract from File2"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/pii.conf",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        -384
      ],
      "id": "a7801b47-12f1-4f69-bed3-ec3586d45957",
      "name": "Loading config files *.conf1"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data4",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        -176
      ],
      "id": "91e941c7-4e1c-4396-ab7e-4b28863eddb9",
      "name": "Extract from File3"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/thresholds.config.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        -176
      ],
      "id": "2801e95d-b037-43cd-a766-4459efc8888a",
      "name": "Loading config files *.conf2"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data5",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        32
      ],
      "id": "fd0ec6ff-dc25-4e2f-9681-556e122395f1",
      "name": "Extract from File4"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/unified_config.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        32
      ],
      "id": "97a5b3c6-0924-4723-a45e-b2d5a78a3096",
      "name": "Loading config files *.conf3"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data6",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        256
      ],
      "id": "56b6e5eb-e7c3-48e1-82e7-6a16016deeb5",
      "name": "Extract from File5"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/rules.config.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        256
      ],
      "id": "253bd462-e896-455b-9b60-b772fccf7976",
      "name": "Loading config files *.conf4"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Final Decision Node - BINARY CLASSIFICATION MODE\n * Updated for Llama Prompt Guard 2 (CRITICAL / MINIMAL only)\n * ADDED: output_text field for unified output logic\n * FIXED: shouldWarn and shouldSanitize detection for SANITIZED status\n */\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  throw new Error('Final Decision: No input items available');\n}\n\n// ========================================\n// HELPER FUNCTIONS\n// ========================================\n\nconst in01Regex = /(?:^|[^\\d])(1(?:\\.0+)?|0?\\.?\\d+|0)(?!\\d)/;\n\nfunction tryParse01(val) {\n  if (val === null || val === undefined) return null;\n  if (typeof val === 'number' && val >= 0 && val <= 100) return val;  // Accept 0-100 range\n  const str = String(val);\n  const m = str.match(in01Regex);\n  if (!m) return null;\n  const v = parseFloat(m[1]);\n  return (v >= 0 && v <= 100) ? v : null;  // Accept 0-100 range\n}\n\nfunction pickCtxItem(all) {\n  const fullConfigItem = all.find(it => {\n    const j = it?.json;\n    return j && j.config && j.rules && j.thresholds && j.chat_payload;\n  });\n  if (fullConfigItem) return fullConfigItem;\n\n  const configItem = all.find(it => {\n    const j = it?.json;\n    return j && (j.config || j.data5);\n  });\n  if (configItem) return configItem;\n\n  const restoredItem = all.find(it => {\n    const j = it?.json;\n    return j && j._llm_context_restored === true;\n  });\n  if (restoredItem) return restoredItem;\n\n  return all[0];\n}\n\nfunction findPgScore(all) {\n  let score = null, src = null, raw = null;\n\n  for (const it of all) {\n    const j = it?.json;\n\n    // Check for risk_score from Prompt Guard API\n    if (j && typeof j.risk_score === 'number') {\n      score = j.risk_score;\n      src = 'json.risk_score (Prompt Guard API)';\n      raw = j;\n      break;\n    }\n\n    if (j && j.llm_result && typeof j.llm_result.score === 'number') {\n      score = j.llm_result.score;\n      src = 'llm_result.score (restored context)';\n      raw = j.llm_result.raw_output;\n      break;\n    }\n\n    if (typeof j === 'string') {\n      const v = tryParse01(j);\n      if (v !== null) { score = v; src = 'json:string'; raw = j; break; }\n    }\n\n    if (Array.isArray(j) && j.length) {\n      const first = j[0];\n      if (first && typeof first === 'object' && 'text' in first) {\n        const v = tryParse01(first.text);\n        if (v !== null) { score = v; src = 'array[0].text'; raw = first; break; }\n      } else {\n        const v = tryParse01(first);\n        if (v !== null) { score = v; src = 'array[0]'; raw = first; break; }\n      }\n    }\n\n    if (j && typeof j === 'object' && 'text' in j) {\n      const v = tryParse01(j.text);\n      if (v !== null) { score = v; src = 'json.text'; raw = j.text; break; }\n    }\n\n    if (j && j.data && Array.isArray(j.data) && j.data[0] && 'text' in j.data[0]) {\n      const v = tryParse01(j.data[0].text);\n      if (v !== null) { score = v; src = 'json.data[0].text'; raw = j.data[0].text; break; }\n    }\n\n    if (j && j.metrics && j.metrics.injectionScore !== undefined) {\n      const v = tryParse01(j.metrics.injectionScore);\n      if (v !== null) { score = v; src = 'json.metrics.injectionScore'; raw = j.metrics.injectionScore; break; }\n    }\n  }\n\n  if (score === null) { score = 0; src = 'default:0'; raw = null; }\n\n  return { score, src, raw };\n}\n\n// ========================================\n// MAIN LOGIC\n// ========================================\n\nconst ctxItem = pickCtxItem(items);\nconst { score: injectionScoreRaw, src: extractedFrom, raw: pgRaw } = findPgScore(items);\n\nlet config = ctxItem?.json?.config || ctxItem?.json?.data5;\n\nif (!config) {\n  const configFromOtherItem = items.find(it => it?.json?.config || it?.json?.data5);\n\n  if (!configFromOtherItem) {\n    throw new Error(\n      'Final Decision: Missing config in all items. ' +\n      'Ensure Config Loader output is properly merged. ' +\n      'Available item keys: ' +\n      items.map((it, i) => `[${i}]: ${Object.keys(it?.json || {}).join(', ')}`).join(' | ')\n    );\n  }\n\n  config = configFromOtherItem.json.config || configFromOtherItem.json.data5;\n\n  if (!ctxItem.json.rules && configFromOtherItem.json.rules) {\n    ctxItem.json.rules = configFromOtherItem.json.rules;\n  }\n  if (!ctxItem.json.thresholds && configFromOtherItem.json.thresholds) {\n    ctxItem.json.thresholds = configFromOtherItem.json.thresholds;\n  }\n}\n\nconst promptGuardConfig = config.prompt_guard_policy;\nif (!promptGuardConfig) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy');\n}\n\nconst configEnabled = promptGuardConfig.enabled !== false;\nconst riskLevelsConfig = promptGuardConfig.risk_levels;\n\nif (!riskLevelsConfig) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy.risk_levels');\n}\n\n// Binary classification: only CRITICAL and MINIMAL required\nif (!riskLevelsConfig.CRITICAL) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy.risk_levels.CRITICAL');\n}\nif (!riskLevelsConfig.MINIMAL) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy.risk_levels.MINIMAL');\n}\n\nif (typeof riskLevelsConfig.CRITICAL.threshold_min !== 'number') {\n  throw new Error('Final Decision: Missing threshold_min for CRITICAL risk level');\n}\nif (typeof riskLevelsConfig.MINIMAL.threshold_min !== 'number') {\n  throw new Error('Final Decision: Missing threshold_min for MINIMAL risk level');\n}\nif (!riskLevelsConfig.CRITICAL.policy) {\n  throw new Error('Final Decision: Missing policy for CRITICAL risk level');\n}\nif (!riskLevelsConfig.MINIMAL.policy) {\n  throw new Error('Final Decision: Missing policy for MINIMAL risk level');\n}\n\nconst thresholds = {\n  critical: riskLevelsConfig.CRITICAL.threshold_min,\n  minimal: riskLevelsConfig.MINIMAL.threshold_min\n};\n\nconst policies = {\n  CRITICAL: riskLevelsConfig.CRITICAL.policy,\n  MINIMAL: riskLevelsConfig.MINIMAL.policy\n};\n\nif (!config.enforcement || !config.enforcement.block_message) {\n  throw new Error('Final Decision: Missing config.enforcement.block_message');\n}\nconst blockMessage = config.enforcement.block_message;\n\nlet injectionScore = Math.max(0, Math.min(100, injectionScoreRaw));  // Accept 0-100 range\nlet riskLevel, severity;\n\n// Binary classification: CRITICAL (>=0.9) or MINIMAL (<0.9)\nif (injectionScore >= thresholds.critical * 100) {  // Compare in 0-100 scale\n  riskLevel = 'CRITICAL';\n  severity = 5;\n} else {\n  riskLevel = 'MINIMAL';\n  severity = 1;\n}\n\nconst configPolicy = policies[riskLevel];\nconst shouldBlockByPolicy = configPolicy === 'block';\n\nlet action, route, userMessage = null, internalNote;\n\nif (riskLevel === 'CRITICAL') {\n  if (shouldBlockByPolicy) {\n    action = 'BLOCK_IMMEDIATE';\n    route = 'blocked';\n    userMessage = blockMessage;\n    internalNote = `Critical injection attempt detected by Prompt Guard (risk_score: ${injectionScore.toFixed(4)}) - blocked by policy=${configPolicy}`;\n  } else {\n    action = 'ALLOW_WITH_LOGGING';\n    route = 'safe';\n    userMessage = null;\n    internalNote = `Critical risk detected (risk_score: ${injectionScore.toFixed(4)}) - allowed by policy=${configPolicy} (unusual config)`;\n  }\n} else {\n  // MINIMAL risk level\n  if (shouldBlockByPolicy) {\n    action = 'BLOCK_WITH_WARNING';\n    route = 'blocked';\n    userMessage = blockMessage;\n    internalNote = `Minimal risk (risk_score: ${injectionScore < 0.01 ? injectionScore.toExponential(2) : injectionScore.toFixed(4)}) - blocked by policy=${configPolicy} (unusual config)`;\n  } else {\n    action = 'ALLOW';\n    route = 'safe';\n    userMessage = null;\n    internalNote = `Safe request confirmed by Prompt Guard (risk_score: ${injectionScore < 0.01 ? injectionScore.toExponential(2) : injectionScore.toFixed(4)}) - allowed`;\n  }\n}\n\n// Check for sanitizer override\nconst previousDecision =\n  ctxItem?.json?.decision?.decision ||\n  ctxItem?.json?.__metadata?.final_decision ||\n  ctxItem?.json?.correlation?.after;\n\nif (previousDecision === 'BLOCK' || previousDecision === 'blocked' || ctxItem?.json?._isBlocked === true) {\n  route = 'blocked';\n  action = 'BLOCK_BY_SANITIZER';\n  userMessage = userMessage || blockMessage;\n  internalNote += ' | Forced block by sanitizer (previousDecision=' + previousDecision + ', _isBlocked=' + ctxItem?.json?._isBlocked + ')';\n}\n\n// ========================================\n// DETECT SANITIZATION\n// ========================================\n\n// Check if content was sanitized by Sanitization_Enforcement node\nconst enforcementMode = ctxItem?.json?.enforcement?.mode;\nconst wasSanitized = (enforcementMode === 'light' || enforcementMode === 'heavy');\n\n// Alternative check: previous decision was SANITIZE_LIGHT or SANITIZE_HEAVY\nconst sanitizeDecision = (\n  previousDecision === 'SANITIZE_LIGHT' ||\n  previousDecision === 'SANITIZE_HEAVY'\n);\n\n// Final sanitization flag\nconst isSanitized = wasSanitized || sanitizeDecision;\n\n// ========================================\n// DETERMINE OUTPUT_TEXT\n// ========================================\n\nlet outputText;\n\nif (route === 'blocked') {\n  // BLOCKED: use block message\n  outputText = userMessage || blockMessage;\n} else {\n  // ALLOWED or SANITIZED: use text after PII redaction or sanitization\n  outputText = ctxItem?.json?._pipeline_snapshots?.afterSanitization ||\n               ctxItem?.json?._pipeline_snapshots?.afterPII ||\n               ctxItem?.json?.output_text_redacted ||\n               ctxItem?.json?.chat_payload?.chatInput ||\n               ctxItem?.json?.normalization?.canonical ||\n               'N/A';\n}\n\n// ========================================\n// BUILD RESULT\n// ========================================\n\nconst result = {\n  decision: {\n    action,\n    route,\n    severity,\n    riskLevel,\n    scoreRaw: injectionScore,\n    scorePercent: Math.round(injectionScore * 100),\n    scoreFormatted: injectionScore < 0.01 ? injectionScore.toExponential(2) : injectionScore.toFixed(4),\n    appliedPolicy: configPolicy,\n    model: 'Llama-Prompt-Guard-2-86M'\n  },\n  messages: {\n    user: userMessage,\n    internal: internalNote\n  },\n  routing: {\n    shouldBlock: route === 'blocked',\n    shouldWarn: isSanitized && route !== 'blocked',  // ✓ FIXED: detect sanitization\n    shouldLog: severity >= 2,\n    shouldSanitize: isSanitized,  // ✓ FIXED: detect sanitization\n    isSafe: route === 'safe' && !isSanitized  // Safe only if NOT sanitized\n  },\n  metrics: {\n    injectionScore,\n    scorePercent: Math.round(injectionScore * 100),\n    severity,\n    confidence: injectionScore > 0.9 || injectionScore < 0.1 ? 'high' : 'medium',\n    processingTime: Date.now()\n  },\n  technical: {\n    thresholdsUsed: thresholds,\n    policiesUsed: policies,\n    configEnabled: configEnabled,\n    pgRaw,\n    extractedFrom,\n    binaryClassification: true,\n    enforcementMode: enforcementMode || 'none',  // ✓ ADDED: debugging info\n    wasSanitized: isSanitized  // ✓ ADDED: debugging info\n  },\n  audit: {\n    timestamp: new Date().toISOString(),\n    node: 'final_decision',\n    originalPrompt:\n      ctxItem?.json?.output_text_redacted ||\n      ctxItem?.json?.chatInput ||\n      ctxItem?.json?.input ||\n      ctxItem?.json?.chat_payload?.chatInput ||\n      'N/A',\n    llmScore: injectionScore,\n    finalDecision: action,\n    appliedPolicy: configPolicy,\n    configSource: 'unified_config.json',\n    previousDecision: previousDecision || 'none',\n    blockFlagSet: ctxItem?.json?._isBlocked === true,\n    promptGuardModel: 'Llama-Prompt-Guard-2-86M',\n    sanitizationApplied: isSanitized  // ✓ ADDED: audit trail\n  },\n\n  __san: ctxItem?.json?.__san || {},\n  _pipeline_snapshots: ctxItem?.json?._pipeline_snapshots || {},\n  normalization: ctxItem?.json?.normalization || {},\n  chat_payload: ctxItem?.json?.chat_payload || {},\n  sessionId: ctxItem?.json?.sessionId || ctxItem?.json?.chat_payload?.sessionId || 'unknown',\n  action: ctxItem?.json?.action || ctxItem?.json?.chat_payload?.action || 'sendMessage',\n  config: config,\n  rules: ctxItem?.json?.rules || {},\n  thresholds: ctxItem?.json?.thresholds || {},\n  enforcement: ctxItem?.json?.enforcement || {},\n  _loader: ctxItem?.json?._loader || {},\n  score: ctxItem?.json?.score || 0,\n  scoreBreakdown: ctxItem?.json?.scoreBreakdown || {},\n  matchDetails: ctxItem?.json?.matchDetails || [],\n  sanitizer_decision: ctxItem?.json?.decision || {},\n\n  // ✓ UNIFIED OUTPUT FIELD\n  output_text: outputText,\n\n  _route: route,\n  _shouldContinue: route === 'safe',\n  _requiresSanitization: isSanitized,  // ✓ FIXED: proper sanitization flag\n  _isBlocked: route === 'blocked'\n};\n\nreturn [{\n  json: result,\n  binary: ctxItem?.binary || {}\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        208,
        -1008
      ],
      "id": "ac4fba87-f06f-42e3-a591-b86954c09603",
      "name": "Finale Decision"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {
          "includeUnpaired": true
        }
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -32,
        -1008
      ],
      "id": "e8cdeee3-229b-4b08-a519-d08038ca4aaa",
      "name": "Merge1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "36e14137-f077-4f9b-8bb7-0596338fa273",
              "leftValue": "={{ $json.decision?.decision }}",
              "rightValue": "BLOCK",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -1200,
        -1008
      ],
      "id": "151ad3fd-8494-42f3-b74b-bd2535c7ebfa",
      "name": "If"
    },
    {
      "parameters": {
        "jsCode": "// NEW VERSION: LLM Context Restore with Multi-Chunk Aggregation\n\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json;\n  const responses = j.pg_responses || [];\n\n  // Helper function: Determine risk level from score\n  function determineRiskLevel(score) {\n    if (score >= 80) return 'CRITICAL';\n    if (score >= 60) return 'HIGH';\n    if (score >= 40) return 'MEDIUM';\n    if (score >= 20) return 'LOW';\n    return 'SAFE';\n  }\n\n  let riskScore = 0;\n  let llmRawOutput = null;\n  let llmVerdict = null;\n  let llmIsAttack = false;\n  let confidence = 0;\n\n  // CASE 1: Multi-chunk analysis (sliding window used)\n  if (responses.length > 1) {\n    const scores = responses.map(r => r.risk_score || 0);\n    const maxScore = Math.max(...scores);\n    const avgScore = scores.reduce((a, b) => a + b, 0) / scores.length;\n    const attackDetected = responses.some(r => r.is_attack);\n\n    // Use MAX score (most conservative approach)\n    riskScore = maxScore;\n    confidence = maxScore / 100;  // Convert to 0-1 range\n    llmIsAttack = attackDetected;\n    llmVerdict = attackDetected ? '🚨 ATTACK DETECTED (multi-chunk)!' : '✅ Safe (multi-chunk)';\n\n    // Create summary output\n    llmRawOutput = JSON.stringify({\n      analysis_type: 'sliding_window',\n      chunks_analyzed: responses.length,\n      max_score: maxScore,\n      avg_score: avgScore.toFixed(2),\n      attack_detected: attackDetected,\n      chunks_with_attacks: responses.filter(r => r.is_attack).length,\n      chunks_details: responses.map(r => ({\n        index: r.chunk_index,\n        score: r.risk_score,\n        is_attack: r.is_attack,\n        verdict: r.verdict\n      }))\n    });\n\n    // Store detailed aggregation in j\n    j.llm_guard_score = maxScore;\n    j.llm_guard_score_avg = avgScore;\n    j.llm_guard_score_max = maxScore;\n    j.llm_guard_attack_detected = attackDetected;\n    j.risk_level = determineRiskLevel(maxScore);\n\n    // Audit trail\n    j.audit = j.audit || {};\n    j.audit.chunks_analyzed = responses.length;\n    j.audit.chunks_with_attacks = responses.filter(r => r.is_attack).length;\n    j.audit.sliding_window_used = j.sliding_window_enabled || false;\n  }\n  // CASE 2: Single chunk analysis (original behavior) or fallback\n  else if (responses.length === 1) {\n    const apiData = responses[0];\n\n    riskScore = apiData.risk_score || 0;\n    confidence = apiData.confidence || 0;\n    llmIsAttack = apiData.is_attack || false;\n    llmVerdict = apiData.verdict || 'unknown';\n\n    llmRawOutput = JSON.stringify({\n      analysis_type: 'single_chunk',\n      text: apiData.text_analyzed,\n      is_attack: apiData.is_attack,\n      risk_score: apiData.risk_score,\n      confidence: apiData.confidence,\n      verdict: apiData.verdict\n    });\n\n    j.llm_guard_score = riskScore;\n    j.llm_guard_attack_detected = llmIsAttack;\n    j.risk_level = determineRiskLevel(riskScore);\n\n    // Audit trail\n    j.audit = j.audit || {};\n    j.audit.chunks_analyzed = 1;\n    j.audit.chunks_with_attacks = llmIsAttack ? 1 : 0;\n    j.audit.sliding_window_used = false;\n  }\n  // CASE 3: No responses (error fallback)\n  else {\n    riskScore = 0;\n    confidence = 0;\n    llmIsAttack = false;\n    llmVerdict = 'no_analysis';\n    llmRawOutput = JSON.stringify({ error: 'No Prompt Guard responses available' });\n\n    j.llm_guard_score = 0;\n    j.llm_guard_attack_detected = false;\n    j.risk_level = 'SAFE';\n\n    j.audit = j.audit || {};\n    j.audit.chunks_analyzed = 0;\n    j.audit.chunks_with_attacks = 0;\n    j.audit.sliding_window_used = false;\n    j.audit.error = 'no_pg_responses';\n  }\n\n  // Ensure score is valid (0-100 range for compatibility)\n  if (isNaN(riskScore)) riskScore = 0;\n  riskScore = Math.max(0, Math.min(100, riskScore));\n\n  // Normalize to 0-1 range for risk_score (backwards compatible)\n  j.risk_score = riskScore;  // Already in 0-100 range from Prompt Guard API node\n\n  // Store full result object\n  j.llm_result = {\n    score: riskScore,  // 0-100 range (already scaled)\n    score_raw: riskScore,    // 0-100 range\n    raw_output: llmRawOutput,\n    is_attack: llmIsAttack,\n    verdict: llmVerdict,\n    confidence: confidence,\n    source: 'meta-llama/llama-prompt-guard-2-86m',\n    timestamp: new Date().toISOString()\n  };\n\n  j._llm_context_restored = true;\n\n  // Clean up temporary fields\n  delete j.chunks_array;\n  delete j.pg_responses;\n\n  results.push({\n    json: j,\n    pairedItem: item.pairedItem\n  });\n}\n\nreturn results;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -304,
        -880
      ],
      "id": "d9218db3-8bb1-4a28-b2fa-734321c07453",
      "name": "LLM Context Restore"
    },
    {
      "parameters": {
        "jsCode": "// NEW VERSION: Prepare LLM Request with Sliding Window Analysis\n\n/**\n * Analyzes text using sliding window approach for long inputs\n * @param {string} text - Input text to analyze\n * @param {number} windowSize - Size of each chunk (default: 500)\n * @param {number} stride - Step size between chunks (default: 250)\n * @param {number} maxChunks - Maximum number of chunks (default: 5)\n * @returns {Array} Array of chunk objects\n */\nfunction analyzeWithSlidingWindow(text, windowSize = 500, stride = 250, maxChunks = 5) {\n  // If text shorter than window → return single chunk\n  if (text.length <= windowSize) {\n    return [{\n      chunk: text,\n      start: 0,\n      end: text.length,\n      index: 0,\n      isLast: true\n    }];\n  }\n\n  const chunks = [];\n  let position = 0;\n  let chunkIndex = 0;\n\n  while (position < text.length && chunkIndex < maxChunks) {\n    const end = Math.min(position + windowSize, text.length);\n    const chunk = text.substring(position, end);\n\n    chunks.push({\n      chunk: chunk,\n      start: position,\n      end: end,\n      index: chunkIndex,\n      isLast: (end === text.length)\n    });\n\n    position += stride;\n    chunkIndex++;\n\n    // Break if we reached end\n    if (end === text.length) break;\n  }\n\n  return chunks;\n}\n\n// Main n8n node logic\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json;\n\n  const content = j._pipeline_snapshots?.afterSanitization ||\n                  j.chat_payload?.chatInput ||\n                  \"test\";\n\n  // Determine if sliding window should be used\n  const preliminaryScore = j.unified_decision?.threat_score || 0;\n  const shouldUseSlidingWindow = (\n    content.length > 500 &&                    // Text longer than window\n    preliminaryScore >= 30                     // Suspicious enough (SANITIZE_LIGHT or higher)\n  );\n\n  let chunksArray;\n  let slidingWindowEnabled;\n\n  if (shouldUseSlidingWindow) {\n    chunksArray = analyzeWithSlidingWindow(content);\n    slidingWindowEnabled = true;\n  } else {\n    // Single chunk mode (original behavior)\n    chunksArray = [{\n      chunk: content,\n      start: 0,\n      end: content.length,\n      index: 0,\n      isLast: true\n    }];\n    slidingWindowEnabled = false;\n  }\n\n  results.push({\n    json: {\n      ...j,\n      chunks_array: chunksArray,\n      sliding_window_enabled: slidingWindowEnabled,\n      sliding_window_config: {\n        window_size: 500,\n        stride: 250,\n        max_chunks: 5,\n        text_length: content.length,\n        chunks_generated: chunksArray.length\n      }\n    },\n    pairedItem: item.pairedItem\n  });\n}\n\nreturn results;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -912,
        -896
      ],
      "id": "25dfe3c7-65d3-47ae-adb1-1de0e83f2bb2",
      "name": "Prepare LLM Request"
    },
    {
      "parameters": {
        "jsCode": "// NEW VERSION v1.3.4: Prompt Guard API with axios\n// Using axios (enabled via NODE_FUNCTION_ALLOW_EXTERNAL=axios)\n\nconst axios = require('axios');\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json;\n  const chunksArray = j.chunks_array || [];\n  const responses = [];\n\n  // Loop through all chunks and call Prompt Guard API\n  for (const chunkData of chunksArray) {\n    try {\n      // Call Prompt Guard API using axios\n      const response = await axios.post('http://prompt-guard-api:8000/detect', {\n        text: chunkData.chunk\n      }, {\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        timeout: 10000  // 10 second timeout\n      });\n\n      const result = response.data;\n\n      // Store response with chunk metadata\n      responses.push({\n        chunk_index: chunkData.index,\n        chunk_start: chunkData.start,\n        chunk_end: chunkData.end,\n        is_attack: result.is_attack || false,\n        confidence: result.confidence || 0,\n        risk_score: (result.risk_score || 0) * 100,  // Convert 0-1 to 0-100\n        verdict: result.verdict || 'unknown',\n        text_analyzed: chunkData.chunk.substring(0, 100) + (chunkData.chunk.length > 100 ? '...' : '')\n      });\n\n    } catch (error) {\n      console.error(`⚠️ Prompt Guard CRITICAL ERROR - chunk ${chunkData.index}:`, error.message);\n\n      // FIX 2.5.2: FAIL-CLOSED - Treat errors as attacks (prevent bypass)\n      responses.push({\n        chunk_index: chunkData.index,\n        chunk_start: chunkData.start,\n        chunk_end: chunkData.end,\n        error: error.message,\n        risk_score: 95,  // ✅ CRITICAL threat level\n        is_attack: true,  // ✅ Fail-closed: treat errors as attacks\n        confidence: 0.95,\n        verdict: '⚠️ PG_ERROR - BLOCKED (fail-closed)',\n        _pg_error: true  // Audit flag for monitoring\n      });\n    }\n  }\n\n  // Attach all responses to item\n  results.push({\n    json: {\n      ...j,\n      pg_responses: responses,\n      chunks_analyzed: responses.length,\n      pg_api_timestamp: new Date().toISOString()\n    },\n    pairedItem: item.pairedItem\n  });\n}\n\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -720,
        -752
      ],
      "id": "1b33c134-01c7-4c05-bc5d-e1ac0954500e",
      "name": "Prompt Guard API"
    },
    {
      "parameters": {
        "mode": "combineByPosition"
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -528,
        -880
      ],
      "id": "233428ae-3b01-43b0-be3c-645adeb8fd1b",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Bloom_Prefilter - FIXED VERSION\n *\n * PROBLEM: Poprzednia implementacja dodawała pełne frazy do Bloom Filter,\n * ale testowała krótkie n-gramy (3-6 znaków). To nigdy nie mogło zadziałać,\n * bo Bloom Filter operuje na pełnych stringach, nie substringach.\n *\n * ROZWIĄZANIE: Opcja A (Performance-Optimized)\n * - Indeksuj wszystkie n-gramy z dangerous patterns\n * - Testuj n-gramy z input text\n * - To zapewnia spójność: te same typy stringów w obu operacjach\n *\n * ROZWIĄZANIE ALTERNATYWNE: Opcja B (Higher Accuracy)\n * - Indeksuj pełne frazy\n * - Testuj sliding windows różnych długości\n * - Wolniejsze, ale wykryje exact phrase matches\n */\n\nclass SimpleBloomFilter {\n  constructor(size = 32768, k = 5, seed = 1337) {\n    this.bits = new Uint8Array(size);\n    this.size = size;\n    this.k = k;\n    this.seed = seed;\n    this.itemCount = 0;\n  }\n\n  hash(str, seed) {\n    let h = seed;\n    for (let i = 0; i < str.length; i++) {\n      h ^= str.charCodeAt(i);\n      h = Math.imul(h ^ (h >>> 16), 0x85ebca6b);\n      h = Math.imul(h ^ (h >>> 13), 0xc2b2ae35);\n      h ^= h >>> 16;\n    }\n    return h >>> 0;\n  }\n\n  getHashes(item) {\n    const hashes = [];\n    for (let i = 0; i < this.k; i++) {\n      const h = this.hash(item, this.seed + i) % this.size;\n      hashes.push(h);\n    }\n    return hashes;\n  }\n\n  add(item) {\n    const hashes = this.getHashes(item);\n    for (const h of hashes) {\n      this.bits[h] = 1;\n    }\n    this.itemCount++;\n  }\n\n  test(item) {\n    const hashes = this.getHashes(item);\n    for (const h of hashes) {\n      if (this.bits[h] === 0) return false;\n    }\n    return true;\n  }\n\n  estimateFalsePositiveRate() {\n    const bitsSet = this.bits.reduce((sum, bit) => sum + bit, 0);\n    const p = bitsSet / this.size;\n    return Math.pow(p, this.k);\n  }\n}\n\nconst DEFAULT_DANGEROUS_PATTERNS = [\n  'ignore all instructions',\n  'ignore previous instructions',\n  'disregard instructions',\n  'override system',\n  'you are now',\n  'act as dan',\n  'jailbreak',\n  'developer mode',\n  'godmode enabled',\n  'love pliny',\n  'im free',\n  'i\\'m free',\n  'system prompt',\n  'reveal instructions',\n  'show your prompt',\n  'print instructions',\n  'forget everything'\n];\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('BloomPrefilter: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n\n  // Skip if already blocked\n  if (j.configError === true || j._isBlocked === true) {\n    out.push(item);\n    continue;\n  }\n\n  const cfg = j.config ?? {};\n\n  // Get configuration from unified_config.json with defaults\n  const bloomCfg = cfg.bloom || {\n    m: 32768,\n    k: 5,\n    seed: 1337,\n    match_mod: 97,\n    min_matched_bits: 2\n  };\n\n  const prefilterCfg = cfg.prefilter || {\n    ngram: { min: 3, max: 6, prefix_window: 96 },\n    sample_limit: 800,\n    obf_signals: { min_count: 2 }\n  };\n\n  // Get dangerous patterns from config or use defaults\n  const dangerousPatterns = (prefilterCfg.dangerous_patterns && Array.isArray(prefilterCfg.dangerous_patterns) && prefilterCfg.dangerous_patterns.length > 0)\n    ? prefilterCfg.dangerous_patterns\n    : DEFAULT_DANGEROUS_PATTERNS;\n\n  const bloomDecisions = cfg.bloom_decisions || {\n    route_to_ac_threshold: 15,\n    hard_block_threshold: 50,\n    require_zusatz_signals: true,\n    phrase_match_bonus: 20\n  };\n\n  // Initialize bloom filter\n  const bloom = new SimpleBloomFilter(bloomCfg.m, bloomCfg.k, bloomCfg.seed);\n\n  // ========================================\n  // FIX: Indeksuj n-gramy z patterns (nie pełne frazy!)\n  // ========================================\n  const ngramMin = prefilterCfg.ngram?.min || 3;\n  const ngramMax = prefilterCfg.ngram?.max || 6;\n\n  let totalNgramsIndexed = 0;\n  for (const pattern of dangerousPatterns) {\n    if (typeof pattern === 'string' && pattern.length > 0) {\n      const normalizedPattern = pattern.toLowerCase();\n\n      // Add full pattern (dla dokładnych dopasowań)\n      bloom.add(normalizedPattern);\n      totalNgramsIndexed++;\n\n      // Add n-grams from pattern (dla częściowych dopasowań)\n      for (let n = ngramMin; n <= Math.min(ngramMax, normalizedPattern.length); n++) {\n        for (let i = 0; i <= normalizedPattern.length - n; i++) {\n          const ngram = normalizedPattern.substring(i, i + n);\n          // Skipuj n-gramy składające się tylko ze spacji\n          if (ngram.trim().length > 0) {\n            bloom.add(ngram);\n            totalNgramsIndexed++;\n          }\n        }\n      }\n    }\n  }\n\n  const text = j.normalization?.forScoring ?? j.chat_payload?.chatInput ?? \"\";\n  const original = j.normalization?.original ?? \"\";\n\n  // Skip if no text to analyze\n  if (!text) {\n    j.prefilter = {\n      bloom: {\n        matchedBitsCount: 0,\n        totalHashes: 0,\n        matchRatio: 0,\n        suspiciousScore: 0,\n        falsePositiveRate: bloom.estimateFalsePositiveRate(),\n        patternsLoaded: dangerousPatterns.length,\n        ngramsIndexed: totalNgramsIndexed,\n        skipped: true,\n        skipReason: 'no_text',\n        version: 'FIXED_v1.0'\n      },\n      ngram: { sampledCount: 0 },\n      routeToAC: false,\n      hardBlock: false,\n      signals: {}\n    };\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n\n  // ========================================\n  // FIX: Testuj zarówno n-gramy jak i sliding windows\n  // ========================================\n  const sampleLimit = prefilterCfg.sample_limit || 800;\n  const testText = text.substring(0, sampleLimit).toLowerCase();\n\n  let matchedNgrams = 0;\n  let totalNgramTests = 0;\n  let matchedPhrases = [];\n\n  // Test 1: N-gram matching (fast, general detection)\n  for (let n = ngramMin; n <= ngramMax; n++) {\n    for (let i = 0; i <= testText.length - n; i++) {\n      const ngram = testText.substring(i, i + n);\n      totalNgramTests++;\n      if (bloom.test(ngram)) {\n        matchedNgrams++;\n      }\n    }\n  }\n\n  // Test 2: Phrase matching (slower, but catches exact phrases)\n  // Testuj sliding windows od 10 do 50 znaków\n  for (let windowSize = 10; windowSize <= Math.min(50, testText.length); windowSize += 5) {\n    for (let i = 0; i <= testText.length - windowSize; i++) {\n      const window = testText.substring(i, i + windowSize).trim();\n      if (bloom.test(window)) {\n        // Znaleźliśmy potencjalną frazę!\n        // Sprawdź czy to jedna z known patterns\n        for (const pattern of dangerousPatterns) {\n          if (window.includes(pattern.toLowerCase())) {\n            if (!matchedPhrases.includes(pattern)) {\n              matchedPhrases.push(pattern);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  const ngramMatchRatio = totalNgramTests > 0 ? matchedNgrams / totalNgramTests : 0;\n\n  // Additional cheap signals\n  const hasZWSP = /[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\uFEFF]/.test(original);\n  const longBase64 = /\\b[A-Za-z0-9+/]{100,}={0,2}\\b/.test(text);\n  const hasTemplateMarkers = j.normalization?.obfuscationSignals?.includes(\"template-markers\") || false;\n  const hasSeparatorAbuse = j.normalization?.obfuscationSignals?.includes(\"separator-abuse\") || false;\n\n  // ========================================\n  // FIX: Scoring z uwzględnieniem phrase matches\n  // ========================================\n  // Base score z n-gramów\n  let suspiciousScore = ngramMatchRatio * 100;\n\n  // Boost score jeśli znaleziono exact phrases\n  if (matchedPhrases.length > 0) {\n    // Każda znaleziona fraza dodaje konfigurowalne punkty\n    const phraseBonus = bloomDecisions.phrase_match_bonus || 20;\n    suspiciousScore += matchedPhrases.length * phraseBonus;\n    // Cap at 100\n    suspiciousScore = Math.min(100, suspiciousScore);\n  }\n\n  // Decision based on config thresholds\n  // n-gram overlap is natural in normal language - need strong signal\n  const routeToAC = (suspiciousScore > bloomDecisions.route_to_ac_threshold) ||\n                    hasTemplateMarkers || hasSeparatorAbuse ||\n                    matchedPhrases.length > 0;  // Route if any phrase matched\n\n  const hardBlock = (suspiciousScore > bloomDecisions.hard_block_threshold) &&\n                    (!bloomDecisions.require_zusatz_signals ||\n                     (hasZWSP || longBase64 || matchedPhrases.length >= 2));\n\n  j.prefilter = {\n    bloom: {\n      matchedBitsCount: matchedNgrams,\n      totalHashes: totalNgramTests,\n      matchRatio: ngramMatchRatio,\n      suspiciousScore: Math.round(suspiciousScore),\n      falsePositiveRate: bloom.estimateFalsePositiveRate(),\n      patternsLoaded: dangerousPatterns.length,\n      ngramsIndexed: totalNgramsIndexed,\n      configSource: (prefilterCfg.dangerous_patterns && prefilterCfg.dangerous_patterns.length > 0) ? 'config' : 'defaults',\n      version: 'FIXED_v1.0'\n    },\n    ngram: {\n      sampledCount: Math.min(text.length, sampleLimit),\n      ngramMin,\n      ngramMax\n    },\n    phrases: {\n      matchedCount: matchedPhrases.length,\n      matched: matchedPhrases.slice(0, 5)  // Limit to first 5 for logging\n    },\n    routeToAC,\n    hardBlock,\n    signals: { hasZWSP, longBase64, hasTemplateMarkers, hasSeparatorAbuse },\n    thresholdsUsed: {\n      route_threshold: bloomDecisions.route_to_ac_threshold,\n      block_threshold: bloomDecisions.hard_block_threshold,\n      zusatz_required: bloomDecisions.require_zusatz_signals\n    }\n  };\n\n  // If hard block detected, set decision early\n  if (hardBlock) {\n    j.decision = j.decision || {};\n    j.decision.decision = 'BLOCK';\n    j.decision.source = 'bloom_prefilter';\n    j.decision.reason = 'HIGH_RISK_PATTERN_DETECTED';\n    j.decision.details = {\n      suspiciousScore: Math.round(suspiciousScore),\n      matchedPhrases: matchedPhrases,\n      signals: Object.keys(j.prefilter.signals).filter(k => j.prefilter.signals[k]),\n      ngramMatchRatio: ngramMatchRatio,\n      threshold: bloomDecisions.hard_block_threshold\n    };\n    j._isBlocked = true;\n  }\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2704,
        -1008
      ],
      "id": "663de637-06cc-4765-97a0-2abaeea4cf5f",
      "name": "Bloom_Prefilter"
    },
    {
      "parameters": {
        "content": "## Standard chat input",
        "height": 320,
        "width": 560,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5424,
        -1136
      ],
      "typeVersion": 1,
      "id": "cda66c79-c560-4d22-8624-bb8a7cad3daf",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "42f773e2-7ebf-42f7-a993-8be016d218e1",
        "responseMode": "lastNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        -5264,
        -464
      ],
      "id": "09d5f5bf-6753-4b9c-a6b1-2b354a7e5a86",
      "name": "Webhook",
      "webhookId": "42f773e2-7ebf-42f7-a993-8be016d218e1"
    },
    {
      "parameters": {
        "content": "## Webhook",
        "height": 320,
        "width": 560,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5440,
        -592
      ],
      "typeVersion": 1,
      "id": "44131ab7-ce21-4806-9c3f-d052fe20dff6",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Input_Validator - Pre-filtering DoS Protection (Phase 2.4)\n * Validates input before main pipeline to prevent resource exhaustion\n */\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Input_Validator: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n\n  // Skip if config error already present\n  if (j.configError === true) {\n    j.validation = { passed: false, reason: 'CONFIG_ERROR' };\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n\n  // Get input text\n  const text = j.chat_payload?.chatInput ?? j.chatInput ?? \"\";\n\n  // Initialize validation result\n  const validation = {\n    passed: true,\n    reason: null,\n    checks: {},\n    input_length: text.length\n  };\n\n  // CHECK 1: Minimum length (empty input)\n  if (text.length < 1) {\n    validation.passed = false;\n    validation.reason = 'EMPTY_INPUT';\n    validation.checks.min_length = false;\n\n    j._isBlocked = true;\n    j.decision = {\n      decision: 'BLOCK',\n      source: 'input_validator',\n      reason: 'EMPTY_INPUT',\n      updated_at: new Date().toISOString()\n    };\n    j.score = 100;\n    j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n  }\n  // CHECK 2: Maximum length (DoS protection)\n  else if (text.length > 10000) {\n    validation.passed = false;\n    validation.reason = 'EXCESSIVE_LENGTH';\n    validation.checks.max_length = false;\n\n    j._isBlocked = true;\n    j.decision = {\n      decision: 'BLOCK',\n      source: 'input_validator',\n      reason: 'EXCESSIVE_LENGTH',\n      updated_at: new Date().toISOString()\n    };\n    j.score = 100;\n    j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n  }\n  // CHECK 3: Excessive control characters (>30%)\n  else {\n    const controlChars = (text.match(/[\\x00-\\x1F\\x7F-\\x9F]/g) || []).length;\n    const controlRatio = text.length > 0 ? controlChars / text.length : 0;\n\n    if (controlRatio > 0.30) {\n      validation.passed = false;\n      validation.reason = 'EXCESSIVE_CONTROL_CHARS';\n      validation.checks.control_chars = false;\n      validation.checks.control_ratio = controlRatio;\n\n      j._isBlocked = true;\n      j.decision = {\n        decision: 'BLOCK',\n        source: 'input_validator',\n        reason: 'EXCESSIVE_CONTROL_CHARS',\n        updated_at: new Date().toISOString()\n      };\n      j.score = 100;\n      j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n    }\n    // CHECK 4: Excessive repetition (uniqueChars < 5 for >100 char inputs)\n    else if (text.length > 100) {\n      const uniqueChars = new Set(text).size;\n\n      if (uniqueChars < 5) {\n        validation.passed = false;\n        validation.reason = 'EXCESSIVE_REPETITION';\n        validation.checks.unique_chars = uniqueChars;\n        validation.checks.repetition_detected = true;\n\n        j._isBlocked = true;\n        j.decision = {\n          decision: 'BLOCK',\n          source: 'input_validator',\n          reason: 'EXCESSIVE_REPETITION',\n          updated_at: new Date().toISOString()\n        };\n        j.score = 100;\n        j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n      } else {\n        validation.checks.unique_chars = uniqueChars;\n        validation.checks.repetition_detected = false;\n      }\n    }\n\n    // Mark all checks passed if no failures\n    if (validation.passed) {\n      validation.checks.min_length = true;\n      validation.checks.max_length = true;\n      validation.checks.control_chars = true;\n      validation.checks.repetition_detected = false;\n    }\n  }\n\n  // Store validation result\n  j.validation = validation;\n  j._validation = validation;  // Protected field for pipeline persistence\n  j._input_validated = true;\n  \n  // CRITICAL: Store in config for pipeline persistence (Phase 2.4)\n  if (!j.config) j.config = {};\n  j.config._validation = validation;\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3424,
        -1008
      ],
      "id": "016d3a22-b310-4c12-8a5b-f41728d618a7",
      "name": "Input_Validator"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "1db9e612-fab9-48c2-83ec-16bd5b821126",
              "leftValue": "={{ $json.validation?.passed }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "true"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3296,
        -656
      ],
      "id": "e1c3598e-7435-43ac-99b4-f675c6f2e3e5",
      "name": "Validation Check"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Early Block Response - Validation failure handler (SIMPLIFIED)\n */\n\nconst items = $input.all();\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const validation = j.validation || {};\n\n  // Get original input\n  const originalInput = j.chat_payload?.chatInput || \"\";\n\n  // Create block message\n  let blockMessage = \"Content blocked by security policy\";\n  switch (validation.reason) {\n    case 'EMPTY_INPUT':\n      blockMessage = \"Invalid request: Empty input\";\n      break;\n    case 'EXCESSIVE_LENGTH':\n      blockMessage = \"Invalid request: Input exceeds maximum length (10000 characters)\";\n      break;\n    case 'EXCESSIVE_CONTROL_CHARS':\n      blockMessage = \"Invalid request: Excessive control characters detected\";\n      break;\n    case 'EXCESSIVE_REPETITION':\n      blockMessage = \"Invalid request: Excessive character repetition detected\";\n      break;\n  }\n\n  // Set output\n  j.output_text = blockMessage;\n  j.chat_payload = j.chat_payload || {};\n  j.chat_payload.chatInput = blockMessage;\n\n  // Preserve original for logging\n  j.audit = j.audit || {};\n  j.audit.originalPrompt = originalInput;\n  j.audit.validationFailure = true;\n  j.audit.validationReason = validation.reason;\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        192,
        -640
      ],
      "id": "88fd9c05-2228-45f6-9cc6-bbae3ef62e4a",
      "name": "Early Block Response"
    },
    {
      "parameters": {
        "jsCode": "/**\n * output to plugin - Format response for browser extension\n * Reads from Build+Sanitize NDJSON node\n */\n\n// Get data from Build+Sanitize NDJSON (not from $input!)\nconst buildOutput = $('Build+Sanitize NDJSON').item.json;\n\nconsole.log('Build output keys:', Object.keys(buildOutput || {}));\n\nconst ndjson = buildOutput?.ndjson;\n\nif (!ndjson) {\n  console.log('❌ No ndjson data from Build+Sanitize NDJSON');\n  return [{\n    json: {\n      action: 'allow',\n      reason: 'no_ndjson_data',\n      error: 'Could not read data from Build+Sanitize NDJSON node'\n    }\n  }];\n}\n\n// Extract decision data\nconst finalStatus = ndjson.final_decision?.status || 'ALLOWED';\nconst threatScore = ndjson.scoring?.sanitizer_score || ndjson.scoring?.prompt_guard_score || 0;\nconst cleanedPrompt = ndjson.chat_payload?.chatInput || '';\nconst sessionId = ndjson.sessionId || 'unknown';\n\nconsole.log('Final status:', finalStatus);\nconsole.log('Threat score:', threatScore);\nconsole.log('Cleaned prompt:', cleanedPrompt);\n\n// Map status to action\nlet action = 'allow';\nif (finalStatus === 'BLOCKED' || threatScore >= 85) {\n  action = 'block';\n} else if (finalStatus === 'SANITIZED' || threatScore >= 30) {\n  action = 'sanitize';\n}\n\n// Build response for plugin\nconst response = {\n  action: action,\n  reason: finalStatus.toLowerCase(),\n  threat_score: threatScore,\n  sessionId: sessionId\n};\n\n// Try to get original request body from Webhook\ntry {\n  const webhookInput = $('Webhook').first().json;\n  const originalBody = webhookInput?._debug?.fullBody;\n  \n  // If sanitizing and we have original body, build sanitizedBody\n  if (action === 'sanitize' && originalBody && originalBody.messages) {\n    response.sanitizedBody = {\n      ...originalBody,\n      messages: [{\n        ...originalBody.messages[0],\n        content: {\n          content_type: \"text\",\n          parts: [cleanedPrompt]\n        }\n      }]\n    };\n    console.log('✅ Built sanitizedBody with cleaned prompt');\n  } else if (action !== 'allow') {\n    // Fallback - return cleaned prompt as simple field\n    response.chatInput = cleanedPrompt;\n  }\n} catch (e) {\n  console.log('⚠️ Could not access Webhook data:', e.message);\n  if (action !== 'allow') {\n    response.chatInput = cleanedPrompt;\n  }\n}\n\nconsole.log('Final response:', JSON.stringify(response, null, 2));\n\n// Return single object\nreturn [{\n  json: response\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        928,
        -768
      ],
      "id": "ef34e25c-36ab-46fb-9c6a-9ac5b89bdde7",
      "name": "output to plugin"
    }
  ],
  "pinData": {},
  "connections": {
    "Build+Sanitize NDJSON": {
      "main": [
        [
          {
            "node": "Logging to Clikhouse",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Logging to Clikhouse": {
      "main": [
        [
          {
            "node": "output to plugin",
            "type": "main",
            "index": 0
          },
          {
            "node": "Clean output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Config Loader": {
      "main": [
        [
          {
            "node": "Input_Validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Config Loader",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Keep only set": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.json",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf3",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Extract from File1": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Normalize_Node": {
      "main": [
        [
          {
            "node": "Bloom_Prefilter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loading config files *.conf": {
      "main": [
        [
          {
            "node": "Extract from File1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loading config files *.json": {
      "main": [
        [
          {
            "node": "Extract from File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Unified Decision Engine": {
      "main": [
        [
          {
            "node": "Correlation_Engine",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Allowlist_Validator": {
      "main": [
        [
          {
            "node": "Pattern_Matching_Engine",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Sanitization_Enforcement": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PII_Redactor": {
      "main": [
        [
          {
            "node": "Normalize_Node",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Correlation_Engine": {
      "main": [
        [
          {
            "node": "Sanitization_Enforcement",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pattern_Matching_Engine": {
      "main": [
        [
          {
            "node": "Unified Decision Engine",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File2": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Loading config files *.conf1": {
      "main": [
        [
          {
            "node": "Extract from File2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File3": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "Loading config files *.conf2": {
      "main": [
        [
          {
            "node": "Extract from File3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File4": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 5
          }
        ]
      ]
    },
    "Loading config files *.conf3": {
      "main": [
        [
          {
            "node": "Extract from File4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File5": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 6
          }
        ]
      ]
    },
    "Loading config files *.conf4": {
      "main": [
        [
          {
            "node": "Extract from File5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Finale Decision": {
      "main": [
        [
          {
            "node": "Build+Sanitize NDJSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "Finale Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare LLM Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Context Restore": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Prompt Guard API": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "LLM Context Restore",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Bloom_Prefilter": {
      "main": [
        [
          {
            "node": "Allowlist_Validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare LLM Request": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prompt Guard API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Keep only set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Keep only set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Input_Validator": {
      "main": [
        [
          {
            "node": "Validation Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validation Check": {
      "main": [
        [
          {
            "node": "PII_Redactor",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Early Block Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Early Block Response": {
      "main": [
        [
          {
            "node": "Build+Sanitize NDJSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "9e6ecfca-de45-44a4-9750-5cd2b71e2d4d",
  "meta": {
    "instanceId": "dfa197c84cd7f4ad8dd4d19b7082aa2a21efac19e31eeea4eeb47113ea54eee9"
  },
  "id": "Hem9Nqtc9GAC4OMh",
  "tags": []
}