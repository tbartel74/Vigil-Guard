{
  "name": "Vigil Guard v1.6.11",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.3,
      "position": [
        -5296,
        -128
      ],
      "id": "ea9f0524-d0f4-47df-82b2-454eba6f8539",
      "name": "When chat message received",
      "webhookId": "42f773e2-7ebf-42f7-a993-8be016d218e1"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Build_Sanitized_NDJSON - strict mode for config values\n * UPDATED: Uses output_text from Final Decision as primary source\n */\n\nfunction err(msg){ throw new Error(msg); }\n\nfunction simpleHash(str){\n  let hash = 0;\n  for (let i = 0; i < str.length; i++){\n    const c = str.charCodeAt(i);\n    hash = ((hash << 5) - hash) + c;\n    hash |= 0;\n  }\n  return hash.toString(36);\n}\n\nconst isPlainObject = v => Object.prototype.toString.call(v) === \"[object Object]\";\nfunction firstDefined(...vals){ for (const v of vals) if (v !== undefined && v !== null) return v; return undefined; }\nfunction s(v){ if (v===undefined||v===null) return undefined; const t=String(v); return t.trim()?t:undefined; }\nfunction deepPrune(value,{removeEmptyObjects=false,removeEmptyArrays=false}={}){\n  if (Array.isArray(value)){\n    const arr = value.map(v=>deepPrune(v,{removeEmptyObjects,removeEmptyArrays})).filter(v=>v!==undefined);\n    if (removeEmptyArrays && arr.length===0) return undefined;\n    return arr;\n  }\n  if (isPlainObject(value)){\n    const out = {};\n    for (const [k,v] of Object.entries(value)){\n      const pruned = deepPrune(v,{removeEmptyObjects,removeEmptyArrays});\n      if (pruned !== undefined) out[k]=pruned;\n    }\n    if (removeEmptyObjects && Object.keys(out).length===0) return undefined;\n    return out;\n  }\n  if (value===null || value===undefined || (typeof value===\"number\" && Number.isNaN(value))) return undefined;\n  return value;\n}\nfunction J(x){ try { return JSON.stringify(x ?? {}); } catch { return \"{}\"; } }\n\nconst items = $input.all();\nif (!items.length) err(\"Build_Sanitized_NDJSON: no input items.\");\n\nconst out = [];\n\nfor (const item of items){\n  const j = item.json || {};\n\n  const san = j.__san || {};\n  const snap = j._pipeline_snapshots || san._pipeline_snapshots || {};\n  const norm = j.normalization || san.normalization || {};\n\n  const pgDecision = j.decision || {};\n  const routing = j.routing || {};\n  const metrics = j.metrics || {};\n  const technical = j.technical || {};\n  const audit = j.audit || {};\n  const messages = j.messages || {};\n\n  const sanitizerDecision = j.sanitizer_decision || {};\n\n  const cfg = j.config || {};\n  const rules = j.rules || {};\n  const thr = j.thresholds || {};\n\n  const sessionId = firstDefined(\n    j.sessionId,\n    san.sessionId,\n    j.chat_payload?.sessionId\n  ) || \"unknown\";\n  \n  const action = firstDefined(\n    j.action,\n    san.action,\n    j.chat_payload?.action\n  ) || \"sendMessage\";\n\n  const originalInput = s(firstDefined(\n    j.chatInput,  // \u2705 NEW: Read from root level (preserved original by PII_Redactor)\n    snap.beforeSanitization,\n    norm?.original,\n    j.audit?.originalPrompt  // Removed san.chat_payload?.chatInput (contains redacted text)\n  )) || \"N/A\";\n\n  const normalizedInput = s(firstDefined(\n    snap.input_normalized,\n    norm?.canonical,\n    norm?.normalized,\n    originalInput\n  )) || originalInput;\n\n  const sanitizedText = s(firstDefined(\n    snap.afterSanitization,\n    san.chat_payload?.chatInput,\n    j.chat_payload?.chatInput\n  ));\n\n  const redactedText = s(firstDefined(\n    snap.afterPII,\n    sanitizedText\n  ));\n\n  const pgShouldBlock = !!(routing.shouldBlock || j._isBlocked);\n  const pgShouldWarn = !!(routing.shouldWarn || j._requiresSanitization);\n  const pgIsSafe = !!(routing.isSafe || j._shouldContinue);\n  \n  const sanitizerDecisionStr = sanitizerDecision.decision || 'ALLOW';\n  const sanitizerBlocked = (sanitizerDecisionStr === 'BLOCK');\n  \n  let finalStatus;\n  if (pgShouldBlock || sanitizerBlocked) {\n    finalStatus = \"BLOCKED\";\n  } else if (pgShouldWarn) {\n    finalStatus = \"SANITIZED\";\n  } else {\n    finalStatus = \"ALLOWED\";\n  }\n\n  const shouldBlock = (finalStatus === \"BLOCKED\");\n  const shouldWarn = (finalStatus === \"SANITIZED\");\n  const isSafe = (finalStatus === \"ALLOWED\");\n\n  // \u2713 UPDATED: Priorytet dla output_text z Final Decision\n  const finalOutput = s(j.output_text) || \n                      (shouldBlock \n                        ? (s(messages?.user) || s(cfg?.enforcement?.block_message) || \"Content blocked by security policy\")\n                        : (redactedText || sanitizedText || s(j.chat_payload?.chatInput) || \"N/A\"));\n\n  const pgHasDecision = !!(pgDecision && (pgDecision.action !== undefined || pgDecision.severity !== undefined || pgDecision.scoreRaw !== undefined));\n  const blockedByPG = shouldBlock && pgHasDecision;\n  const blockedBySan = shouldBlock && !pgHasDecision;\n\n  let source = \"sanitizer_pre_pg\";\n  let actionTaken = firstDefined(pgDecision.action, finalStatus);\n  \n  if (finalStatus === \"BLOCKED\"){\n    if (blockedBySan) { \n      source = \"sanitizer_only\"; \n      actionTaken = \"BLOCK_BY_SANITIZER\"; \n    }\n    if (blockedByPG) { \n      source = \"prompt_guard\"; \n      actionTaken = pgDecision.action || \"BLOCK_BY_PROMPT_GUARD\"; \n    }\n  } else {\n    source = pgHasDecision ? \"prompt_guard\" : \"sanitizer_pre_pg\";\n    if (finalStatus === \"ALLOWED\") actionTaken = \"ALLOW\";\n    if (finalStatus === \"SANITIZED\") actionTaken = actionTaken || \"SANITIZE\";\n  }\n\n  const nd = {\n    sessionId,\n    action,\n    chat_payload: {\n      sessionId,\n      action,\n      chatInput: finalOutput\n    },\n    sanitizer: {\n      decision: sanitizerDecisionStr,\n      removal_pct: san.enforcement?.removalPct ?? j.enforcement?.removalPct ?? 0,\n      mode: san.enforcement?.mode || j.enforcement?.mode,\n      score: j.score || sanitizerDecision.score || 0,\n      breakdown: j.scoreBreakdown || sanitizerDecision.scoreBreakdown || {},\n      pii: san.pii || j.pii || {}\n    },\n    prompt_guard: pgHasDecision ? {\n      score: pgDecision.scoreRaw || metrics.injectionScore,\n      score_percent: pgDecision.scorePercent || metrics.scorePercent,\n      risk_level: pgDecision.riskLevel,\n      severity: pgDecision.severity,\n      action: pgDecision.action,\n      should_block: pgShouldBlock,\n      should_warn: pgShouldWarn,\n      is_safe: pgIsSafe,\n      confidence: metrics.confidence,\n      thresholds_used: technical.thresholdsUsed,\n      policies_used: technical.policiesUsed,\n      timestamp: audit.timestamp\n    } : {},\n    final_decision: {\n      status: finalStatus,\n      blocked: shouldBlock,\n      sanitized: shouldWarn,\n      allowed: isSafe,\n      action_taken: actionTaken,\n      user_message: s(messages?.user) || \"\",\n      internal_note: s(messages?.internal) || \"\",\n      source\n    },\n    pipeline_flow: {\n      input_raw: originalInput,\n      input_normalized: normalizedInput,\n      after_sanitization: sanitizedText || finalOutput,\n      after_pii_redaction: redactedText || finalOutput,\n      output_final: finalOutput,\n      output_status: finalStatus\n    },\n    scoring: {\n      sanitizer_score: Number(j.score ?? sanitizerDecision.score ?? 0),\n      prompt_guard_score: pgDecision.scoreRaw || metrics.injectionScore,\n      prompt_guard_percent: pgDecision.scorePercent || metrics.scorePercent,\n      combined_severity: firstDefined(\n        pgDecision.severity,\n        (j.score ?? 0) >= 76 ? 5 :\n        (j.score ?? 0) >= 56 ? 4 :\n        (j.score ?? 0) >= 30 ? 3 :\n        (j.score ?? 0) >= 10 ? 2 : 1\n      ),\n      score_breakdown: j.scoreBreakdown || sanitizerDecision.scoreBreakdown || {},\n      match_details: j.matchDetails || []\n    },\n    config_metadata: {\n      config_hash: (cfg && rules && thr) ? simpleHash(JSON.stringify({ cfg, rules, thr })) : \"no-config\",\n      config_version: cfg?.version || \"unknown\",\n      has_full_config: !!(cfg && rules && thr),\n      has_prompt_guard: pgHasDecision,\n      config_ref: {\n        normalization_unicode: cfg.normalization?.unicode_form,\n        scoring_ranges: thr?.ranges,\n        prompt_guard_thresholds: technical.thresholdsUsed\n      },\n      loader_info: j._loader\n    },\n    _audit: {\n      processing_timestamp: new Date().toISOString(),\n      pipeline_version: \"v1.6.8\",\n      total_processing_time: metrics.processingTime,\n      final_action: actionTaken\n    },\n    normalization: norm || {},  // Include full normalization data (encoding, obfuscation, etc.)\n    validation: cfg._validation || j._validation || j.validation || {}  // Include validation results from Input_Validator (Phase 2.4)\n  };\n\n  const ndClean = deepPrune(nd);\n\n  const row = {\n    sessionId: ndClean.sessionId,\n    action: ndClean.action,\n    timestamp: ndClean._audit?.processing_timestamp,\n\n    original_input: originalInput,  // \u2705 FIXED: Use calculated originalInput variable (j.chatInput)\n    normalized_input: ndClean.pipeline_flow?.input_normalized,\n    after_sanitization: ndClean.pipeline_flow?.after_sanitization,\n    after_pii_redaction: ndClean.pipeline_flow?.after_pii_redaction,\n    chat_input: ndClean.chat_payload?.chatInput,\n    result: ndClean.pipeline_flow?.output_final,\n\n    threat_score: ndClean.scoring?.sanitizer_score ?? ndClean.scoring?.prompt_guard_score ?? 0,\n    threat_severity: ndClean.prompt_guard?.risk_level ?? \"UNDEFINED\",\n    pg_score: ndClean.prompt_guard?.score ?? 0,\n    pg_score_percent: ndClean.prompt_guard?.score_percent ?? 0,\n    final_status: ndClean.final_decision?.status ?? \"UNKNOWN\",\n    final_action: ndClean._audit?.final_action ?? \"\",\n    user_message: ndClean.final_decision?.user_message ?? \"\",\n\n    removal_pct: ndClean.sanitizer?.removal_pct ?? 0,\n    threat_labels: [],\n    threat_matches: [],\n\n    config_version: ndClean.config_metadata?.config_version,\n    config_hash: ndClean.config_metadata?.config_hash,\n    pipeline_version: ndClean._audit?.pipeline_version,\n    processing_time_ms: ndClean._audit?.total_processing_time ?? 0,\n\n    sanitizer_json: J(ndClean.sanitizer),\n    prompt_guard_json: J(ndClean.prompt_guard),\n    scoring_json: J(ndClean.scoring),\n    final_decision_json: J(ndClean.final_decision),\n    pipeline_flow_json: J(ndClean.pipeline_flow),\n    config_metadata_json: J(ndClean.config_metadata),\n    raw_event: J(ndClean)\n  };\n\n  out.push({ json: { ndjson: ndClean, row } });\n}\n\nreturn out;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        -96
      ],
      "id": "efa9c2ce-cf5c-4d8c-a126-5ad085a4952a",
      "name": "Build+Sanitize NDJSON"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=http://clickhouse:8123/?date_time_input_format=best_effort&input_format_skip_unknown_fields=1&query=INSERT%20INTO%20n8n_logs.events_processed%20FORMAT%20JSONEachRow",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/x-ndjson",
        "body": "={{$json.row}}",
        "options": {
          "response": {
            "response": {
              "fullResponse": true
            }
          },
          "timeout": 15000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        672,
        -96
      ],
      "id": "0eb35974-2756-4183-a9fd-7ec21a3578e4",
      "name": "Logging to Clikhouse",
      "retryOnFail": true,
      "alwaysOutputData": false,
      "credentials": {
        "httpBasicAuth": {
          "id": "04Fm7j9WPYuZOD2m",
          "name": "Clickhouse"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Load_Config - Production version with Bloom validation\n * FIXED: English messages, better error handling, bloom configuration validation\n */\n\nfunction safeParseJson(value, fieldName) {\n  if (value == null) {\n    return { ok: false, error: `${fieldName} is null/undefined` };\n  }\n  \n  if (typeof value === 'object') {\n    return { ok: true, data: value };\n  }\n  \n  if (typeof value === 'string') {\n    try {\n      return { ok: true, data: JSON.parse(value) };\n    } catch (e) {\n      return { ok: false, error: `${fieldName} JSON parse failed: ${e.message}` };\n    }\n  }\n  \n  return { ok: false, error: `${fieldName} has invalid type: ${typeof value}` };\n}\n\nfunction validateAllowlistSchema(obj) {\n  return obj && typeof obj === 'object' && \n    (obj.$schema || obj.title === 'Sanitizer Allowlist Schema');\n}\n\nfunction validateNormalizeConf(text) {\n  return typeof text === 'string' && \n    (/#\\s*normalize\\.conf/i.test(text) || \n     /\\\\u200B=|leet\\.char\\.|# Zero-width|# LEET map/.test(text));\n}\n\nfunction validatePiiConf(obj) {\n  return obj && typeof obj === 'object' && \n    Array.isArray(obj.rules) && \n    obj.rules.length > 0 &&\n    obj.rules.some(r => r && typeof r.pattern === 'string' && typeof r.name === 'string');\n}\n\nfunction validateThresholds(obj) {\n  return obj && typeof obj === 'object' && \n    obj.ranges && \n    obj.ranges.allow && \n    obj.ranges.block;\n}\n\nfunction validateUnifiedConfig(obj) {\n  return obj && typeof obj === 'object' && \n    obj.normalization && \n    obj.sanitization && \n    obj.scoring;\n}\n\nfunction validateRules(obj) {\n  return obj && typeof obj === 'object' && \n    obj.categories && \n    typeof obj.categories === 'object';\n}\n\nfunction validateBloomConfig(config) {\n  const warnings = [];\n  \n  if (!config.bloom || typeof config.bloom !== 'object') {\n    warnings.push('Missing or invalid bloom configuration, using defaults');\n  }\n  \n  if (!config.prefilter || typeof config.prefilter !== 'object') {\n    warnings.push('Missing or invalid prefilter configuration, using defaults');\n  }\n  \n  if (config.prefilter && !Array.isArray(config.prefilter.dangerous_patterns)) {\n    warnings.push('Missing dangerous_patterns in prefilter, will use defaults');\n  }\n  \n  if (!config.bloom_decisions || typeof config.bloom_decisions !== 'object') {\n    warnings.push('Missing bloom_decisions, using defaults');\n  }\n  \n  return warnings;\n}\n\nconst inputItems = $input.all();\nif (!inputItems || !inputItems.length) {\n  console.error('Load_Config: No input items');\n  return [{\n    json: {\n      error: 'No input items',\n      configError: true,\n      decision: { decision: 'ALLOW', reason: 'CONFIG_ERROR' }\n    }\n  }];\n}\n\nconst firstItem = inputItems[0];\nconst j = firstItem.json ? JSON.parse(JSON.stringify(firstItem.json)) : {};\n\nj._loader = {\n  sources: {},\n  missing: [],\n  errors: [],\n  warnings: []\n};\n\nconst data1Result = safeParseJson(j.data1, 'data1 (allowlist_schema)');\nif (data1Result.ok && validateAllowlistSchema(data1Result.data)) {\n  j.allowlist_schema = data1Result.data;\n  j._loader.sources.allowlist_schema = 'json.data1';\n} else {\n  j._loader.missing.push('allowlist_schema');\n  j._loader.errors.push(data1Result.error || 'data1: invalid allowlist_schema');\n}\n\nif (validateNormalizeConf(j.data2)) {\n  j.normalization_text = j.data2;\n  j._loader.sources.normalize_conf = 'json.data2';\n} else {\n  j._loader.missing.push('normalize_conf');\n  j._loader.errors.push('data2: invalid normalize.conf format');\n}\n\nconst data3Result = safeParseJson(j.data3, 'data3 (pii.conf)');\nif (data3Result.ok && validatePiiConf(data3Result.data)) {\n  j.pii_conf = data3Result.data;\n  j.pii_text = typeof j.data3 === 'string' ? j.data3 : JSON.stringify(data3Result.data);\n  j._loader.sources.pii_conf = 'json.data3';\n} else {\n  j._loader.missing.push('pii_conf');\n  j._loader.errors.push(data3Result.error || 'data3: invalid pii.conf format');\n}\n\nconst data4Result = safeParseJson(j.data4, 'data4 (thresholds)');\nif (data4Result.ok && validateThresholds(data4Result.data)) {\n  j.thresholds = data4Result.data;\n  j._loader.sources.thresholds = 'json.data4';\n} else {\n  j._loader.missing.push('thresholds');\n  j._loader.errors.push(data4Result.error || 'data4: invalid thresholds format');\n}\n\nconst data5Result = safeParseJson(j.data5, 'data5 (unified_config)');\nif (data5Result.ok && validateUnifiedConfig(data5Result.data)) {\n  j.config = data5Result.data;\n  j._loader.sources.unified_config = 'json.data5';\n  \n  // Validate bloom configuration and collect warnings\n  const bloomWarnings = validateBloomConfig(j.config);\n  if (bloomWarnings.length > 0) {\n    j._loader.warnings = j._loader.warnings.concat(bloomWarnings);\n    console.warn('Bloom config warnings:', bloomWarnings);\n  }\n  \n  // Ensure bloom configuration has required structure\n  if (!j.config.bloom) {\n    j.config.bloom = { m: 32768, k: 5, seed: 1337, match_mod: 97, min_matched_bits: 2 };\n  }\n  \n  if (!j.config.prefilter) {\n    j.config.prefilter = { \n      ngram: { min: 3, max: 6, prefix_window: 96 },\n      sample_limit: 800,\n      obf_signals: { min_count: 2 },\n      dangerous_patterns: []\n    };\n  } else if (!j.config.prefilter.dangerous_patterns) {\n    j.config.prefilter.dangerous_patterns = [];\n  }\n  \n  if (!j.config.bloom_decisions) {\n    j.config.bloom_decisions = {\n      route_to_ac_threshold: 15,\n      hard_block_threshold: 50,\n      require_zusatz_signals: true,\n      phrase_match_bonus: 20\n    };\n  }\n  \n  j.config.references = Object.assign({}, j.config.references || {}, {\n    rules_file: 'rules.config.json',\n    thresholds_file: 'thresholds.config.json',\n    normalize_conf: 'normalize.conf',\n    pii_conf: 'pii.conf'\n  });\n} else {\n  j._loader.missing.push('unified_config');\n  j._loader.errors.push(data5Result.error || 'data5: invalid unified_config format');\n}\n\nconst data6Result = safeParseJson(j.data6, 'data6 (rules)');\nif (data6Result.ok && validateRules(data6Result.data)) {\n  j.rules = data6Result.data;\n  j._loader.sources.rules = 'json.data6';\n} else {\n  j._loader.missing.push('rules');\n  j._loader.errors.push(data6Result.error || 'data6: invalid rules format');\n}\n\nif (j._loader.missing.length > 0) {\n  console.error('Load_Config: Missing required files:', j._loader.missing);\n  console.error('Error details:', j._loader.errors);\n  if (j._loader.warnings.length > 0) {\n    console.warn('Config warnings:', j._loader.warnings);\n  }\n  \n  return [{\n    json: {\n      ...j,\n      configError: true,\n      decision: { decision: 'ALLOW', reason: 'CONFIG_ERROR' },\n      error_message: `Missing required files: ${j._loader.missing.join(', ')}`\n    },\n    pairedItem: 0\n  }];\n}\n\nif (j._loader.warnings.length > 0) {\n  console.info('Config loaded with warnings:', j._loader.warnings);\n}\n\nreturn [{ json: j, pairedItem: 0 }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3600,
        -96
      ],
      "id": "ffa57fef-dc3e-4329-a7e3-fad988f39981",
      "name": "Config Loader"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "numberInputs": 7,
        "options": {
          "includeUnpaired": true
        }
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -3808,
        -112
      ],
      "id": "7e056d4c-5dba-4ee1-aaaf-3af7ac5e1a36",
      "name": "Merge"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b6fecd17-5c91-41b2-a235-85ac60cb4dc5",
              "name": "chat_payload",
              "value": "={{ {\n    chatInput: $json.body.chatInput || $json.chatInput || $json.text || \"\",\n    sessionId: $json.body.sessionId || $json.sessionId || $now.format('x'),\n    action: $json.body.action || $json.action || \"sendMessage\"\n  } }}",
              "type": "object"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -4832,
        -128
      ],
      "id": "c8041b34-5b47-492a-a3d0-9210a89c970c",
      "name": "Keep only set"
    },
    {
      "parameters": {
        "operation": "fromJson",
        "destinationKey": "data1",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        176
      ],
      "id": "34010237-93dd-476e-8e42-e261c7c1699d",
      "name": "Extract from File"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data2",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        368
      ],
      "id": "2fd2aac2-de3b-4076-afc1-340137a9d7f8",
      "name": "Extract from File1"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Normalize_Node - Production version with decodeNested()\n * FIXED: Added encoding bypass detection (base64, URL, hex)\n */\n\nfunction parseNormalizeConf(confText) {\n  const lines = (confText || \"\").split(/\\r?\\n/);\n  const map = new Map();\n  const leetChar = new Map();\n  const leetSingle = new Map();\n\n  for (const raw of lines) {\n    const line = raw.trim();\n    if (!line || line.startsWith(\"#\")) continue;\n    let m;\n    if ((m = line.match(/^leet\\.single\\.([^=]+)=(.*)$/))) {\n      leetSingle.set(m[1], m[2]);\n      continue;\n    }\n    if ((m = line.match(/^leet\\.char\\.([^=]+)=(.*)$/))) {\n      leetChar.set(m[1], m[2]);\n      continue;\n    }\n    const eq = line.indexOf(\"=\");\n    if (eq >= 0) {\n      const lhs = line.slice(0, eq);\n      const rhs = line.slice(eq + 1) || '';\n      const from = lhs.replace(/\\\\u\\{?([0-9A-Fa-f]{4,6})\\}?/g, (_, h) =>\n        String.fromCodePoint(parseInt(h, 16)),\n      );\n      const to = rhs.replace(/\\\\u\\{?([0-9A-Fa-f]{4,6})\\}?/g, (_, h) =>\n        String.fromCodePoint(parseInt(h, 16)),\n      );\n      map.set(from, to);\n    }\n  }\n  return { map, leetChar, leetSingle };\n}\n\n/**\n * decodeNested - Detects and decodes multiple encoding layers\n * Handles: URL encoding (double/triple), base64, hex\n */\nfunction decodeNested(input) {\n  let current = input;\n  let decoded = input;\n  const decodingSteps = [];\n  let changed = true;\n  let iterations = 0;\n  const MAX_ITERATIONS = 5; // Support multi-level encoding (was 3)\n\n  while (changed && iterations < MAX_ITERATIONS) {\n    changed = false;\n    iterations++;\n\n    // 1. URL Decode (multi-level)\n    try {\n      const urlDecoded = decodeURIComponent(current);\n      if (urlDecoded !== current) {\n        decodingSteps.push({ type: 'url', iteration: iterations });\n        current = urlDecoded;\n        decoded = urlDecoded;\n        changed = true;\n        continue;\n      }\n    } catch (e) {\n      // Invalid URL encoding - skip\n    }\n\n    // 2. Base64 Decode (with validation)\n    // FIXED: Match embedded base64 substrings (32+ chars) AND handle case-insensitive\n    const base64Pattern = /[A-Za-z0-9+/]{32,}={0,2}/;\n    const base64Match = current.match(base64Pattern);\n    if (base64Match) {\n      try {\n        const b64String = base64Match[0];\n        // Use Buffer for better compatibility than atob\n        const b64Decoded = (typeof Buffer !== 'undefined') ?\n          Buffer.from(b64String, 'base64').toString('utf-8') :\n          atob(b64String);\n\n        // Check if decoded result contains printable ASCII (likely malicious text)\n        if (b64Decoded && /[\\x20-\\x7E]{5,}/.test(b64Decoded)) {\n          decodingSteps.push({ type: 'base64', iteration: iterations, originalSubstr: b64String.substring(0, 30) });\n          // Replace base64 substring with decoded content\n          current = current.replace(b64String, b64Decoded);\n          decoded = current;\n          changed = true;\n          continue;\n        }\n      } catch (e) {\n        // Not valid base64 - skip\n      }\n    }\n\n    // 3. Hex Decode (0x prefix or pure hex)\n    const hexPattern = /^(?:0x)?([A-Fa-f0-9]{16,})$/;\n    const hexMatch = current.trim().match(hexPattern);\n    if (hexMatch) {\n      try {\n        const hexStr = hexMatch[1];\n        let hexDecoded = '';\n        for (let i = 0; i < hexStr.length; i += 2) {\n          hexDecoded += String.fromCharCode(parseInt(hexStr.substr(i, 2), 16));\n        }\n        // Check if decoded contains printable ASCII\n        if (hexDecoded && /[\\x20-\\x7E]{5,}/.test(hexDecoded)) {\n          decodingSteps.push({ type: 'hex', iteration: iterations });\n          current = hexDecoded;\n          decoded = hexDecoded;\n          changed = true;\n          continue;\n        }\n      } catch (e) {\n        // Invalid hex - skip\n      }\n    }\n  }\n\n  return {\n    decoded: decoded,\n    originalLength: input.length,\n    decodedLength: decoded.length,\n    steps: decodingSteps,\n    levelsDetected: decodingSteps.length\n  };\n}\n\nfunction stripZeroWidth(s) {\n  return s.replace(/[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\uFEFF]/g, \"\");\n}\n\nfunction collapseWhitespace(s) {\n  return s.replace(/\\s+/g, \" \").trim();\n}\n\nfunction hasMathAlnumSymbols(s) {\n  for (const ch of s) {\n    const cp = ch.codePointAt(0);\n    if (cp >= 0x1D400 && cp <= 0x1D7FF) return true;\n  }\n  return false;\n}\n\n/**\n * detectMixedScripts - Enhanced polyglot attack detection\n * Detects mixing of multiple writing systems (11 scripts total)\n * Returns: { detected: boolean, scripts: string[], count: number, suspicionBonus: number, signal: string }\n */\nfunction detectMixedScripts(text) {\n  const scriptRanges = {\n    latin: [\n      [0x0041, 0x007A],  // Basic Latin (A-Z, a-z)\n      [0x00C0, 0x024F]   // Latin Extended-A/B\n    ],\n    cyrillic: [\n      [0x0400, 0x04FF],  // Cyrillic\n      [0x0500, 0x052F]   // Cyrillic Supplement\n    ],\n    greek: [\n      [0x0370, 0x03FF],  // Greek and Coptic\n      [0x1F00, 0x1FFF]   // Greek Extended\n    ],\n    arabic: [\n      [0x0600, 0x06FF],  // Arabic\n      [0x0750, 0x077F],  // Arabic Supplement\n      [0xFB50, 0xFDFF],  // Arabic Presentation Forms-A\n      [0xFE70, 0xFEFF]   // Arabic Presentation Forms-B\n    ],\n    hebrew: [\n      [0x0590, 0x05FF]   // Hebrew\n    ],\n    thai: [\n      [0x0E00, 0x0E7F]   // Thai\n    ],\n    hangul: [\n      [0xAC00, 0xD7AF],  // Hangul Syllables\n      [0x1100, 0x11FF]   // Hangul Jamo\n    ],\n    hiragana: [\n      [0x3040, 0x309F]   // Hiragana\n    ],\n    katakana: [\n      [0x30A0, 0x30FF]   // Katakana\n    ],\n    cjk: [\n      [0x4E00, 0x9FFF],  // CJK Unified Ideographs\n      [0x3400, 0x4DBF]   // CJK Extension A\n    ],\n    emoji: [\n      [0x1F300, 0x1F9FF], // Emoticons, Symbols, Pictographs\n      [0x2600, 0x26FF],   // Miscellaneous Symbols\n      [0x2700, 0x27BF]    // Dingbats\n    ]\n  };\n\n  const detectedScripts = new Set();\n\n  // Scan text for scripts\n  for (const ch of text) {\n    const cp = ch.codePointAt(0);\n    \n    for (const [scriptName, ranges] of Object.entries(scriptRanges)) {\n      for (const [start, end] of ranges) {\n        if (cp >= start && cp <= end) {\n          detectedScripts.add(scriptName);\n          break;\n        }\n      }\n    }\n  }\n\n  const scriptsArray = Array.from(detectedScripts).sort();\n  const scriptCount = scriptsArray.length;\n\n  // Calculate suspicion bonus\n  let suspicionBonus = 0;\n  let signal = '';\n\n  if (scriptCount >= 3) {\n    suspicionBonus = 30;  // 3+ scripts = high suspicion\n    const first3 = scriptsArray.slice(0, 3);\n    signal = 'mixed-scripts-' + first3.join('-') + '+';\n  } else if (scriptCount === 2) {\n    // FIXED (Faza 2.3): Don't flag emoji+Latin as suspicious (normal use case)\n    // Only flag emoji with non-Latin scripts OR 2 non-emoji scripts\n    const hasEmoji = scriptsArray.includes('emoji');\n    const hasLatin = scriptsArray.includes('latin');\n    \n    if (hasEmoji && hasLatin && scriptCount === 2) {\n      // Emoji + Latin only = benign (e.g., \"Hello \ud83d\udc4b\", \"Great job! \ud83c\udf89\")\n      suspicionBonus = 0;\n      signal = '';\n    } else {\n      // Emoji + other script OR 2 non-emoji scripts = suspicious\n      suspicionBonus = 15;\n      signal = 'mixed-scripts-' + scriptsArray[0] + '-' + scriptsArray[1];\n    }\n  }\n\n  return {\n    detected: scriptCount >= 2,\n    scripts: scriptsArray,\n    count: scriptCount,\n    suspicionBonus: suspicionBonus,\n    signal: signal\n  };\n}\n\nfunction htmlDecodeIfNeeded(s, decode) {\n  if (!decode) return s;\n  return s\n    .replace(/&nbsp;/g, \" \")\n    .replace(/&amp;/g, \"&\")\n    .replace(/&lt;/g, \"<\")\n    .replace(/&gt;/g, \">\")\n    .replace(/&#(\\d+);/g, (_, d) => String.fromCodePoint(parseInt(d, 10)))\n    .replace(/&#x([0-9A-Fa-f]+);/g, (_, h) => String.fromCodePoint(parseInt(h, 16)));\n}\n\nfunction applyMap(s, mp) {\n  if (!mp || mp.size === 0) return s;\n  const keys = [...mp.keys()].sort((a, b) => b.length - a.length);\n  for (const k of keys) {\n    if (!k) continue;\n    const v = mp.get(k);\n    const re = new RegExp(k.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\"), \"g\");\n    s = s.replace(re, v);\n  }\n  return s;\n}\n\nfunction casefold(s) {\n  return s.toLocaleLowerCase(\"en\");\n}\n\n/**\n * detectObfuscation - Detects whitespace obfuscation BEFORE normalization\n * Returns: { detected: boolean, score: number, flags: object, signals: string[] }\n */\nfunction detectObfuscation(text) {\n  let obfuscationScore = 0;\n  const flags = {\n    zeroWidth: false,\n    excessiveSpacing: false,\n    spacedOutLetters: false\n  };\n  const signals = [];\n\n  // 1. Zero-width character detection\n  const zeroWidthPattern = /[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\uFEFF]/;\n  if (zeroWidthPattern.test(text)) {\n    flags.zeroWidth = true;\n    obfuscationScore += 25;\n    signals.push('zero-width-chars');\n\n    // Count zero-width characters\n    const zwCount = (text.match(new RegExp(zeroWidthPattern, 'g')) || []).length;\n    if (zwCount > 5) {\n      obfuscationScore += 10;  // Heavy use of zero-width\n      signals.push('zero-width-heavy');\n    }\n  }\n\n  // 2. Excessive spacing detection (3+ consecutive spaces)\n  if (/\\s{3,}/.test(text)) {\n    flags.excessiveSpacing = true;\n    obfuscationScore += 15;\n    signals.push('excessive-spacing');\n  }\n\n  // 3. Spaced-out letters detection (e.g., \"i g n o r e\")\n  // Look for pattern: letter + space + letter + space + letter (at least 5 chars with spaces)\n  const spacedLetterPattern = /\\b[a-zA-Z]\\s+[a-zA-Z]\\s+[a-zA-Z]\\s+[a-zA-Z]\\s+[a-zA-Z]/;\n  if (spacedLetterPattern.test(text)) {\n    flags.spacedOutLetters = true;\n    obfuscationScore += 20;\n    signals.push('spaced-out-letters');\n  }\n\n  return {\n    detected: obfuscationScore > 0,\n    score: obfuscationScore,\n    flags: flags,\n    signals: signals\n  };\n}\n\nfunction buildSignals(original, beforeHomoglyphMap, afterLeet, final, decodingResult, mixedScriptsResult) {\n  const sigs = [];\n\n  // Existing signals\n  if (original.length !== stripZeroWidth(original).length) sigs.push(\"zero-width-removed\");\n  if (hasMathAlnumSymbols(original) || hasMathAlnumSymbols(afterLeet)) sigs.push(\"math-alnum/fraktur\");\n  if (mixedScriptsResult && mixedScriptsResult.detected) {\n    sigs.push(mixedScriptsResult.signal);\n  }\n  if (/[A-Za-z]/.test(original) && /[0-9]/.test(original) && /[@$%|]/.test(original)) sigs.push(\"leet-like-mix\");\n  \n  const separators = beforeHomoglyphMap.match(/(?:_{3,}|-{3,}|\\.{3,}|={3,}|\\*{3,}){1,}/g);\n  if (separators && separators.length >= 3) sigs.push(\"separator-abuse\");\n\n  if (/(?:<\\|\\/?(system|assistant|user|user_query)\\|>|\\{\\{\\s*system\\s*\\}\\}|\\[\\[\\s*system\\s*\\]\\])/.test(beforeHomoglyphMap)) {\n    sigs.push(\"template-markers\");\n  }\n\n  // NEW: Encoding detection signals\n  if (decodingResult && decodingResult.levelsDetected > 0) {\n    sigs.push(`encoding-detected-${decodingResult.levelsDetected}-levels`);\n    decodingResult.steps.forEach(step => {\n      sigs.push(`encoding-${step.type}`);\n    });\n  }\n  \n  return sigs;\n}\n\n// FIXED: Added items declaration\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Normalize_Node: No input items');\n  return [];\n}\n\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const cfg = (j.config ?? {});\n  const ncfg = cfg.normalization ?? {};\n  const confText = j.normalization_text || \"\";\n  const { map, leetChar, leetSingle } = parseNormalizeConf(confText);\n\n  const input =\n    j?.chat_payload?.chatInput ??\n    j?.chatInput ??\n    j?.input ??\n    \"\";\n\n  const steps = [];\n  let s = String(input);\n  const original = s;\n\n  // **NEW: Detect obfuscation BEFORE any normalization**\n  const obfuscationDetected = detectObfuscation(s);\n\n  // **NEW: Decode nested encodings FIRST**\n  const decodingResult = decodeNested(s);\n  if (decodingResult.levelsDetected > 0) {\n    s = decodingResult.decoded;\n    steps.push({ \n      step: \"decode_nested\", \n      levels: decodingResult.levelsDetected,\n      decodingSteps: decodingResult.steps,\n      originalLen: decodingResult.originalLength,\n      decodedLen: decodingResult.decodedLength\n    });\n  }\n\n  s = htmlDecodeIfNeeded(s, !!ncfg.decode_entities);\n  steps.push({ step: \"html_decode\", outLen: s.length });\n\n  try {\n    s = s.normalize(\"NFKC\");\n  } catch {}\n  steps.push({ step: \"nfkc\", outLen: s.length });\n\n  s = casefold(s);\n  steps.push({ step: \"casefold\", outLen: s.length });\n\n  if (ncfg.remove_zero_width !== false) {\n    const s0 = s;\n    s = stripZeroWidth(s);\n    if (s !== s0) steps.push({ step: \"strip_zwsp\", removed: s0.length - s.length });\n  }\n\n  const beforeHomoglyphMap = s;\n\n  s = applyMap(s, map);\n  steps.push({ step: \"homoglyph_map\", outLen: s.length });\n\n  const HEART_PLACEHOLDER = '\\uE000HEART\\uE001';\n  s = s.replace(/<3/g, HEART_PLACEHOLDER);\n  \n  if (leetChar.size) {\n    for (const [k, v] of leetChar.entries()) {\n      if (!k) continue;\n      const re = new RegExp(k.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\"), \"g\");\n      s = s.replace(re, v);\n    }\n    steps.push({ step: \"leet.char\", outLen: s.length });\n  }\n  \n  s = s.replace(new RegExp(HEART_PLACEHOLDER, 'g'), '<3');\n\n  const afterLeet = s;\n\n  if (leetSingle.size) {\n    const tokens = s.split(/(\\b)/);\n    for (let i = 0; i < tokens.length; i++) {\n      const t = tokens[i];\n      if (/^\\b$/.test(t)) continue;\n      const mapped = leetSingle.get(t);\n      if (mapped) tokens[i] = mapped;\n    }\n    s = tokens.join(\"\");\n    steps.push({ step: \"leet.single\", outLen: s.length });\n  }\n\n  if (ncfg.collapse_whitespace !== false) {\n    s = collapseWhitespace(s);\n    steps.push({ step: \"collapse_ws\", outLen: s.length });\n  }\n\n  const canonical = s;\n\n  // FIXED: Use decoded text for scoring IF encoding was detected\n  // This ensures Pattern_Matching_Engine analyzes the actual malicious content\n  let forScoring = canonical;\n  if (decodingResult.levelsDetected > 0) {\n    // Apply same normalization to decoded text before scoring\n    let decodedForScoring = decodingResult.decoded;\n\n    // Apply critical normalization steps\n    try {\n      decodedForScoring = decodedForScoring.normalize(\"NFKC\");\n    } catch {}\n\n    decodedForScoring = casefold(decodedForScoring);\n    decodedForScoring = stripZeroWidth(decodedForScoring);\n    decodedForScoring = applyMap(decodedForScoring, map);\n    decodedForScoring = collapseWhitespace(decodedForScoring);\n\n    forScoring = decodedForScoring;\n  }\n\n  // Polyglot attack detection (moved before buildSignals)\n  const mixedScriptsResult = detectMixedScripts(original);\n  \n  const signals = buildSignals(original, beforeHomoglyphMap, afterLeet, canonical, decodingResult, mixedScriptsResult);\n\n  j._pipeline_snapshots = j._pipeline_snapshots || {};\n  j._pipeline_snapshots.input_raw = original;\n  j._pipeline_snapshots.input_normalized = canonical;\n  if (decodingResult.levelsDetected > 0) {\n    j._pipeline_snapshots.input_decoded = decodingResult.decoded;\n  }\n\n  j.normalization = {\n    original: original,\n    normalized: canonical,\n    canonical: canonical,\n    forScoring: forScoring,\n    steps,\n    obfuscationSignals: signals,\n    mixedScripts: mixedScriptsResult,\n    decodingDetected: decodingResult.levelsDetected > 0 ? decodingResult : null,\n    obfuscationDetected: obfuscationDetected.detected ? obfuscationDetected : null\n  };\n\n  j.chat_payload = j.chat_payload || {};\n  j.chat_payload.chatInput = canonical;\n  j.input_raw = original;\n\n  item.json = j;\n  results.push(item);\n}\n\nreturn results;\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2944,
        -96
      ],
      "id": "eacddca1-42aa-48e6-9866-d70cc534d04b",
      "name": "Normalize_Node"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "583cd94d-198b-4b10-a901-b4feb6edc51a",
              "name": "sessionId",
              "value": "={{ $('Build+Sanitize NDJSON').item.json.ndjson.chat_payload.sessionId }}",
              "type": "string"
            },
            {
              "id": "998db0bf-ad74-49e7-bbad-7d720cedea60",
              "name": "chatInput",
              "value": "={{ $('Build+Sanitize NDJSON').item.json.row.chat_input }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        928,
        -96
      ],
      "id": "ee0aa68e-f36f-496f-a197-a04192cba16d",
      "name": "Clean output"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/normalize.conf",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        368
      ],
      "id": "516f2a75-bcc0-453d-aa9a-1b95bdb234b6",
      "name": "Loading config files *.conf"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/allowlist.schema.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        176
      ],
      "id": "37d75806-85bb-4ae3-a0ba-9c5a1bb81c31",
      "name": "Loading config files *.json"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Unified Decision Engine - FIXED: Added items declaration, score validation\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n  \n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n  \n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\n// FIXED: Added items declaration\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Unified Decision Engine: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json || {};\n  \n  // Skip processing if already blocked by validator\n  if (j.configError === true || j._isBlocked === true) {\n    out.push(item);\n    continue;\n  }\n  \n  // Validate score (handle NaN, Infinity, wrong types)\n  let score = 0;\n  const rawScore = j.score;\n  \n  if (typeof rawScore === 'number' && !isNaN(rawScore) && isFinite(rawScore)) {\n    score = Math.max(0, Math.min(100, rawScore));\n  } else if (typeof rawScore === 'string') {\n    const parsed = parseFloat(rawScore);\n    score = (!isNaN(parsed) && isFinite(parsed)) ? Math.max(0, Math.min(100, parsed)) : 0;\n  } else {\n    score = 0;\n  }\n  \n  if (score !== rawScore) {\n    console.warn(`Invalid score detected: ${rawScore}, normalized to ${score}`);\n  }\n  \n  const scoreBreakdown = j.scoreBreakdown ?? {};\n  const thresholds = j.thresholds || {};\n  \n  const ranges = (thresholds && thresholds.ranges) || {\n    allow: { min: 0, max: 29 },\n    sanitize_light: { min: 30, max: 55 },\n    sanitize_heavy: { min: 56, max: 75 },\n    block: { min: 76, max: 100 },\n  };\n\n  let decision = 'ALLOW';\n  if (score >= ranges.block.min) decision = 'BLOCK';\n  else if (score >= ranges.sanitize_heavy.min) decision = 'SANITIZE_HEAVY';\n  else if (score >= ranges.sanitize_light.min) decision = 'SANITIZE_LIGHT';\n\n  mergeDecision(j, decision, 'unified_decision_engine', {\n    score: score,\n    scoreBreakdown: scoreBreakdown,\n    reason: decision === 'ALLOW' ? 'OK' : 'POLICY'\n  });\n\n  // FIX 2.5.1: Set unified_decision.threat_score for sliding window gating\n  j.unified_decision = {\n    threat_score: score,\n    decision: decision,\n    ranges_used: ranges\n  };\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1968,
        -96
      ],
      "id": "4798a040-1048-476f-ade7-18d2f9dcf96f",
      "name": "Unified Decision Engine"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Allowlist_Validator - FIXED: Better error handling, English messages\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n  \n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n  \n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\nfunction validateJsonSchema(data, schema) {\n  if (!schema || !schema.required) return { valid: true, errors: [] };\n  \n  const errors = [];\n  for (const field of schema.required || []) {\n    if (!(field in data)) {\n      errors.push(`Missing required field: ${field}`);\n    }\n  }\n  \n  if (schema.properties) {\n    for (const [key, propSchema] of Object.entries(schema.properties)) {\n      if (key in data) {\n        const value = data[key];\n        const expectedType = Array.isArray(propSchema.type) ? propSchema.type : [propSchema.type];\n        const actualType = value === null ? 'null' : typeof value === 'object' && Array.isArray(value) ? 'array' : typeof value;\n        \n        if (!expectedType.includes(actualType) && !(expectedType.includes('null') && value === null)) {\n          errors.push(`Field ${key}: expected ${expectedType.join('|')}, got ${actualType}`);\n        }\n      }\n    }\n  }\n  \n  return { valid: errors.length === 0, errors };\n}\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Allowlist_Validator: No input items');\n  return [];\n}\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const schema = j.allowlist_schema || null;\n  \n  const hasInput = !!(j.chat_payload && typeof j.chat_payload.chatInput === \"string\" && j.chat_payload.chatInput.length >= 0);\n  \n  let schemaValid = true;\n  let schemaErrors = [];\n  \n  if (schema && hasInput) {\n    const validation = validateJsonSchema(j, schema);\n    schemaValid = validation.valid;\n    schemaErrors = validation.errors;\n  }\n  \n  const ok = hasInput && schemaValid;\n  \n  j.validation = {\n    ok,\n    errors: ok ? [] : [\n      ...(!hasInput ? [\"chat_payload_missing_or_invalid\"] : []),\n      ...schemaErrors\n    ],\n    enforced: true,\n    schemaVersion: schema ? (schema.$schema || \"unknown\") : \"none\",\n  };\n  \n  if (!ok) {\n    j.configError = true;\n    \n    mergeDecision(j, 'BLOCK', 'allowlist_validator', {\n      validation_failed: true,\n      validation_errors: j.validation.errors,\n      processingMs: 0\n    });\n    \n    if (j.config?.enforcement?.block_message) {\n      j.chat_payload = j.chat_payload || {};\n      j.chat_payload.chatInput = j.config.enforcement.block_message;\n    }\n  }\n  \n  item.json = j;\n}\n\nreturn items;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2464,
        -96
      ],
      "id": "d6274143-a3f1-4448-bffa-79e7127bb6e7",
      "name": "Allowlist_Validator"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Sanitization_Enforcement - VERSION 2.0\n *\n * FIXED: Now uses ACTUAL detected patterns from Pattern_Matching_Engine\n * instead of hardcoded patterns in unified_config.json\n *\n * Strategy:\n * - SANITIZE_LIGHT: Remove patterns from LOW/MEDIUM severity categories\n * - SANITIZE_HEAVY: Remove patterns from ALL detected categories\n * - Uses matchDetails from Pattern_Matching_Engine to get actual regex patterns\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n\n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n\n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\n/**\n * Category severity mapping for LIGHT sanitization\n * LOW/MEDIUM categories will be removed in LIGHT mode\n * HIGH/CRITICAL categories will be removed in HEAVY mode\n */\nconst LOW_MEDIUM_CATEGORIES = [\n  \"MILD_SUSPICIOUS\",\n  \"ENCODING_SUSPICIOUS\",\n  \"FORMAT_COERCION\",\n  \"HYPOTHETICAL_ESCAPE\",\n  \"UNFILTERED_REQUEST\",\n  \"REBEL_RESPONSE\",\n  \"ENCODING_INDICATORS\",\n  \"JAILBREAK_ATTEMPT\",\n  \"GODMODE_JAILBREAK\",\n  \"EXPLICIT_JAILBREAK\"\n];\n\nconst HIGH_CRITICAL_CATEGORIES = [\n  \"CRITICAL_INJECTION\",\n  \"CONTROL_OVERRIDE\",\n  \"PROMPT_LEAK_ATTEMPT\",\n  \"HEAVY_OBFUSCATION\",\n  \"DANGEROUS_CONTENT\",\n  \"PROMPT_TEMPLATING_MARKERS\",\n  \"SEPARATOR_ABUSE\",\n  \"TEMPLATE_TOKEN\",\n  \"HEADER_ESCAPE\",\n  \"DIVIDER_ABUSE\",\n  \"SQL_XSS_ATTACKS\",\n  \"PRIVILEGE_ESCALATION\",\n  \"COMMAND_INJECTION\",\n  \"PATH_TRAVERSAL\",\n  \"XXE_INJECTION\",\n  \"LDAP_INJECTION\",\n  \"SSRF_ATTEMPT\",\n  \"CRLF_INJECTION\",\n  \"NOSQL_INJECTION\",\n  \"TEMPLATE_INJECTION\"\n];\n\n/**\n * Extract all unique regex patterns from matchDetails\n * @param {Array} matchDetails - Array from Pattern_Matching_Engine\n * @param {Array} categoryFilter - List of category names to include (null = all)\n * @returns {Array} Array of regex pattern strings\n */\nfunction extractPatternsFromMatches(matchDetails, categoryFilter = null) {\n  const patterns = [];\n\n  if (!matchDetails || !Array.isArray(matchDetails)) {\n    return patterns;\n  }\n\n  for (const detail of matchDetails) {\n    // Skip if category filter specified and this category not in filter\n    if (categoryFilter && !categoryFilter.includes(detail.category)) {\n      continue;\n    }\n\n    // Skip non-pattern categories (Mixed Scripts, Encoding Detection, Obfuscation Detection)\n    if (!detail.matches || !Array.isArray(detail.matches)) {\n      continue;\n    }\n\n    // Extract patterns from matches\n    for (const match of detail.matches) {\n      if (match.pattern) {\n        patterns.push(match.pattern);\n      }\n    }\n  }\n\n  return patterns;\n}\n\n/**\n * Apply sanitization using detected patterns\n * @param {string} text - Original text\n * @param {Array} patterns - Array of regex pattern strings\n * @param {string} redact - Replacement token\n * @returns {Object} {out: sanitized text, removedPct: percentage removed, removedChars: count}\n */\nfunction applySanitizeFromMatches(text, patterns, redact) {\n  if (!patterns || !patterns.length) {\n    return { out: text, removedPct: 0, removedChars: 0 };\n  }\n\n  let out = text;\n  let removed = 0;\n  const uniquePatterns = [...new Set(patterns)]; // Remove duplicates\n\n  for (const pattern of uniquePatterns) {\n    try {\n      const re = new RegExp(pattern, \"giu\");\n      out = out.replace(re, (m) => {\n        removed += m.length;\n        return redact || \"\";\n      });\n    } catch (e) {\n      console.warn(`Invalid sanitization regex: ${pattern}`, e);\n    }\n  }\n\n  const removedPct = text.length ? Math.round((removed / text.length) * 100) : 0;\n  return { out, removedPct, removedChars: removed };\n}\n\n// ============================================================================\n// MAIN LOGIC\n// ============================================================================\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Sanitization_Enforcement: No input items');\n  return [];\n}\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const decision = j.decision?.decision || \"ALLOW\";\n\n  // Skip if config error or validation failed\n  if (j.configError === true) {\n    console.error(\"Sanitization_Enforcement: Config error detected\");\n    item.json = j;\n    continue;\n  }\n\n  if (!j.config || !j.config.enforcement) {\n    console.error(\"Sanitization_Enforcement: Missing config.enforcement\");\n    j.error = \"Missing enforcement config\";\n    j.decision = { decision: \"ALLOW\", reason: \"CONFIG_ERROR\" };\n    item.json = j;\n    continue;\n  }\n\n  const inText = j.chat_payload?.chatInput ?? j.chatInput ?? \"\";\n  const sessionId = j.sessionId ?? j.chat_payload?.sessionId ?? \"unknown\";\n  const action = j.action ?? j.chat_payload?.action ?? \"sendMessage\";\n  const matchDetails = j.matchDetails || [];\n\n  let finalText = inText;\n  let mode = \"none\";\n  let removalPct = 0;\n  let patternsUsed = [];\n\n  j._pipeline_snapshots = j._pipeline_snapshots || {};\n  j._pipeline_snapshots.beforeSanitization = inText;\n\n  if (decision === \"SANITIZE_LIGHT\") {\n    // LIGHT: Remove only LOW/MEDIUM severity patterns\n    patternsUsed = extractPatternsFromMatches(matchDetails, LOW_MEDIUM_CATEGORIES);\n\n    if (patternsUsed.length === 0) {\n      console.warn(\"Sanitization_Enforcement: SANITIZE_LIGHT but no LOW/MEDIUM patterns detected\");\n      finalText = inText;\n      mode = \"light_nopatterns\";\n    } else {\n      const res = applySanitizeFromMatches(inText, patternsUsed, \"[removed]\");\n      finalText = res.out;\n      removalPct = res.removedPct;\n      mode = \"light\";\n\n      console.log(`Sanitization_Enforcement LIGHT: Removed ${res.removedChars} chars (${removalPct}%) using ${patternsUsed.length} patterns`);\n    }\n  }\n  else if (decision === \"SANITIZE_HEAVY\") {\n    // HEAVY: Remove ALL detected patterns\n    patternsUsed = extractPatternsFromMatches(matchDetails, null);\n\n    if (patternsUsed.length === 0) {\n      console.warn(\"Sanitization_Enforcement: SANITIZE_HEAVY but no patterns detected\");\n      finalText = inText;\n      mode = \"heavy_nopatterns\";\n    } else {\n      const res = applySanitizeFromMatches(inText, patternsUsed, \"[REDACTED]\");\n      removalPct = res.removedPct;\n\n      // Check if removal exceeds threshold (default: 60%)\n      const threshold = j.config.sanitization?.heavy?.max_removal_percent || 60;\n      const policy = j.config.sanitization?.heavy?.policy || \"sanitize_if_exceeds\";\n\n      if (policy === \"block_if_exceeds\" && removalPct > threshold) {\n        // TOO MUCH removed - escalate to BLOCK\n        mergeDecision(j, 'BLOCK', 'sanitization_enforcement', {\n          removal_pct: removalPct,\n          sanitizer_decision: 'SANITIZE_HEAVY',\n          blocked_by_sanitizer: true,\n          threshold_exceeded: threshold,\n          patterns_attempted: patternsUsed.length\n        });\n\n        finalText = j.config.enforcement.block_message || \"Content blocked by security policy\";\n        mode = \"blocked_excessive_removal\";\n\n        console.log(`Sanitization_Enforcement: BLOCKED due to excessive removal (${removalPct}% > ${threshold}%)`);\n      } else {\n        // Acceptable removal - proceed with sanitization\n        finalText = res.out;\n        mode = \"heavy\";\n\n        console.log(`Sanitization_Enforcement HEAVY: Removed ${res.removedChars} chars (${removalPct}%) using ${patternsUsed.length} patterns`);\n      }\n    }\n  }\n  else if (decision === \"BLOCK\") {\n    j._isBlocked = true;\n    finalText = j.config.enforcement?.block_message || \"Content blocked by security policy\";\n    mode = \"blocked\";\n  }\n  else {\n    // ALLOW - no sanitization\n    mode = \"allow\";\n  }\n\n  // Update chat_payload with sanitized text\n  j.chat_payload = j.chat_payload || {};\n  j.chat_payload.sessionId = sessionId;\n  j.chat_payload.action = action;\n  j.chat_payload.chatInput = finalText;\n\n  j._pipeline_snapshots.afterSanitization = finalText;\n\n  j.enforcement = Object.assign({}, j.enforcement, {\n    mode,\n    removalPct,\n    patternsUsed: patternsUsed.length,\n    patternsPreview: patternsUsed.slice(0, 5).map(p => p.substring(0, 30))\n  });\n\n  j.__san = {\n    sessionId,\n    action,\n    chat_payload: { sessionId, action, chatInput: finalText },\n    _pipeline_snapshots: {\n      beforeSanitization: j._pipeline_snapshots.beforeSanitization,\n      afterSanitization: j._pipeline_snapshots.afterSanitization\n    },\n    normalization: j.normalization,\n    enforcement: {\n      mode,\n      removalPct,\n      patternsUsed: patternsUsed.length,\n      heavy_policy: j.config.sanitization?.heavy?.policy || \"sanitize_if_exceeds\",\n      heavy_threshold_pct: j.config.sanitization?.heavy?.max_removal_percent || 60\n    },\n    pii: j.pii || {}\n  };\n\n  j.__metadata = j.__metadata || {};\n  const finalStatus = j.decision?.decision || \"ALLOW\";\n  j.__metadata.should_run_prompt_guard = (finalStatus !== \"BLOCK\");\n\n  item.json = j;\n}\n\nreturn items;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1456,
        -96
      ],
      "id": "06663d4a-36f0-47bc-bc8e-4a7e91e2bffe",
      "name": "Sanitization_Enforcement"
    },
    {
      "parameters": {
        "jsCode": "/**\n * PII_Redactor_v2 - Language-Aware Presidio Integration\n * Version: 1.6.11 - Language Auto-Detection + Fixed Sync\n * Date: 2025-02-01\n *\n * Features:\n * - LANGUAGE AUTO-DETECTION: Prevents cross-language false positives\n * - Smart entity routing: PERSON only in native language\n * - Fixed context_enhancement synchronization\n * - Parallel API calls for cross-language PII (CREDIT_CARD, EMAIL, etc.)\n *\n * Revision History:\n * - Rev 9 (v1.6.11): Language detection, fixed sync, eliminated \"jest\" \u2192 [PERSON] FP\n */\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('PII_Redactor_v2: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n\n  if (j.configError === true || j._isBlocked === true) {\n    out.push(item);\n    continue;\n  }\n\n  const originalChatInput = j.chat_payload?.chatInput ?? j.chatInput ?? \"\";\n\n  if (!j._original_input) {\n    j._original_input = originalChatInput;\n  }\n\n  let text = originalChatInput;\n\n  if (!text) {\n    j.pii_error = \"PII_Redactor_v2: no text to redact\";\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n\n  const piiConfig = j.config?.pii_detection || {};\n  const enablePresidio = piiConfig.enabled !== false;\n  const fallbackToRegex = piiConfig.fallback_to_regex !== false;\n\n  let results = {\n    entities: [],\n    redacted_text: text,\n    detection_method: 'none',\n    processing_time_ms: 0,\n    error: null,\n    language_stats: {}\n  };\n\n  // LANGUAGE-AWARE DETECTION\n  if (enablePresidio) {\n    try {\n      const startTime = Date.now();\n      const axios = require('axios');\n      const apiUrl = piiConfig.api_url || 'http://vigil-presidio-pii:5001/analyze';\n      const scoreThreshold = piiConfig.confidence_threshold || 0.7;\n      const apiTimeout = piiConfig.api_timeout_ms || 3000;\n\n      // SYNC DETECTION MODE WITH PRESIDIO (FIXED - compares mode AND context)\n      const detectionMode = piiConfig.detection_mode || 'balanced';\n      const contextEnhancement = piiConfig.context_enhancement !== false;\n\n      try {\n        const configUrl = apiUrl.replace('/analyze', '/config');\n\n        // Check current mode AND context (with cache to avoid redundant calls)\n        const currentModeKey = `presidio_mode_${detectionMode}_${contextEnhancement}`;\n        if (!global.__presidio_mode_cache || global.__presidio_mode_cache !== currentModeKey) {\n          const currentConfig = await axios.get(configUrl, { timeout: 1000 }).catch(() => ({\n            data: { current_mode: null, context_enhancement: null }\n          }));\n\n          // FIX: Compare BOTH mode AND context - update if either changed\n          const modeChanged = currentConfig.data.current_mode !== detectionMode;\n          const contextChanged = currentConfig.data.context_enhancement !== contextEnhancement;\n\n          if (modeChanged || contextChanged) {\n            await axios.post(configUrl, {\n              mode: detectionMode,\n              enable_context_enhancement: contextEnhancement\n            }, {\n              headers: { 'Content-Type': 'application/json' },\n              timeout: 2000\n            });\n\n            const changes = [];\n            if (modeChanged) changes.push(`mode: ${currentConfig.data.current_mode} \u2192 ${detectionMode}`);\n            if (contextChanged) changes.push(`context: ${currentConfig.data.context_enhancement} \u2192 ${contextEnhancement}`);\n            console.log(`\u2705 Presidio updated: ${changes.join(', ')}`);\n          }\n\n          // Update cache\n          global.__presidio_mode_cache = currentModeKey;\n        }\n      } catch (error) {\n        console.warn(`\u26a0\ufe0f Failed to sync Presidio mode: ${error.message} - continuing with current mode`);\n      }\n\n      // LANGUAGE AUTO-DETECTION (FIX: Eliminates cross-language false positives)\n      const polishKeywords = ['jest', 'nie', 'czy', 'dla', 'kt\u00f3ry', 'kt\u00f3ra', 'kt\u00f3re', 'oraz', 'przez', 'przy', 'jak', 'te\u017c', 'ju\u017c'];\n      const words = text.toLowerCase().split(/\\s+/).slice(0, 20); // Check first 20 words\n      const polishWordCount = words.filter(w => polishKeywords.includes(w)).length;\n      const isProbablyPolish = polishWordCount >= 2; // 2+ Polish keywords = Polish text\n\n      console.log(`Language detection: ${isProbablyPolish ? 'Polish' : 'English'} (polish_words: ${polishWordCount})`);\n\n      // ENTITIES BY LANGUAGE\n      const polishOnlyEntities = ['PL_PESEL', 'PL_NIP', 'PL_REGON', 'PL_ID_CARD'];\n      const crossLanguagePII = ['CREDIT_CARD', 'EMAIL_ADDRESS', 'IBAN_CODE', 'IP_ADDRESS', 'URL'];\n      // PERSON removed from cross-language - only detected in native language to avoid FP\n\n      let plEntities = [];\n      let enEntities = [];\n\n      if (isProbablyPolish) {\n        // Polish text: Full PL detection + cross-language PII from EN\n        const [plResponse, enResponse] = await Promise.all([\n          axios.post(apiUrl, {\n            text: text,\n            language: 'pl',\n            entities: [...polishOnlyEntities, 'PERSON', 'PHONE_NUMBER'],  // PERSON in native lang\n            score_threshold: scoreThreshold,\n            return_decision_process: false\n          }, {\n            headers: { 'Content-Type': 'application/json' },\n            timeout: apiTimeout\n          }).catch(err => {\n            console.warn(`Polish API call failed: ${err.message}`);\n            return { data: { entities: [] } };\n          }),\n\n          axios.post(apiUrl, {\n            text: text,\n            language: 'en',\n            entities: crossLanguagePII,  // Only cross-language PII, NO PERSON\n            score_threshold: scoreThreshold,\n            return_decision_process: false\n          }, {\n            headers: { 'Content-Type': 'application/json' },\n            timeout: apiTimeout\n          }).catch(err => {\n            console.warn(`International API call failed: ${err.message}`);\n            return { data: { entities: [] } };\n          })\n        ]);\n\n        plEntities = plResponse.data.entities || [];\n        enEntities = enResponse.data.entities || [];\n\n      } else {\n        // English text: Full EN detection + Polish PII from PL\n        const [enResponse, plResponse] = await Promise.all([\n          axios.post(apiUrl, {\n            text: text,\n            language: 'en',\n            entities: [...crossLanguagePII, 'PERSON', 'PHONE_NUMBER'],  // PERSON in native lang\n            score_threshold: scoreThreshold,\n            return_decision_process: false\n          }, {\n            headers: { 'Content-Type': 'application/json' },\n            timeout: apiTimeout\n          }).catch(err => {\n            console.warn(`English API call failed: ${err.message}`);\n            return { data: { entities: [] } };\n          }),\n\n          axios.post(apiUrl, {\n            text: text,\n            language: 'pl',\n            entities: polishOnlyEntities,  // Only Polish PII, NO PERSON\n            score_threshold: scoreThreshold,\n            return_decision_process: false\n          }, {\n            headers: { 'Content-Type': 'application/json' },\n            timeout: apiTimeout\n          }).catch(err => {\n            console.warn(`Polish PII check failed: ${err.message}`);\n            return { data: { entities: [] } };\n          })\n        ]);\n\n        enEntities = enResponse.data.entities || [];\n        plEntities = plResponse.data.entities || [];\n      }\n\n      const allEntities = [...plEntities, ...enEntities];\n      results.entities = deduplicateEntities(allEntities);\n      results.detection_method = 'presidio_language_aware';\n      results.processing_time_ms = Date.now() - startTime;\n      results.language_stats = {\n        detected_language: isProbablyPolish ? 'pl' : 'en',\n        polish_entities: plEntities.length,\n        international_entities: enEntities.length,\n        total_after_dedup: results.entities.length\n      };\n\n      console.log(\n        `Language-aware: ${results.entities.length} entities ` +\n        `(pl:${plEntities.length}, en:${enEntities.length}) in ${results.processing_time_ms}ms`\n      );\n\n    } catch (error) {\n      console.warn(`Presidio language-aware error: ${error.message}`);\n      results.error = error.message;\n\n      if (fallbackToRegex) {\n        console.log('Falling back to regex rules');\n        results = applyLegacyPiiRules(text, j.pii_conf, piiConfig);\n      } else {\n        j.pii_error = `Presidio API failed: ${error.message}`;\n        item.json = j;\n        out.push(item);\n        continue;\n      }\n    }\n  } else if (fallbackToRegex) {\n    results = applyLegacyPiiRules(text, j.pii_conf, piiConfig);\n  }\n\n  // APPLY REDACTION\n  let redactedText = text;\n  let redactionCount = 0;\n\n  if (results.detection_method === 'presidio_language_aware' && results.entities.length > 0) {\n    const sortedEntities = results.entities.sort((a, b) => b.start - a.start);\n\n    for (const entity of sortedEntities) {\n      const originalText = text.substring(entity.start, entity.end);\n      const redactionToken = getRedactionToken(entity.type, originalText, piiConfig);\n\n      redactedText =\n        redactedText.substring(0, entity.start) +\n        redactionToken +\n        redactedText.substring(entity.end);\n\n      redactionCount++;\n    }\n  } else if (results.detection_method === 'regex_fallback') {\n    redactedText = results.redacted_text;\n    redactionCount = results.entities.length;\n  }\n\n  const hasPII = (redactedText !== text);\n\n  if (hasPII) {\n    j.chat_payload = j.chat_payload || {};\n    j.chat_payload.chatInput = redactedText;\n    j.chatInput = originalChatInput;\n  } else {\n    j.chatInput = originalChatInput;\n  }\n\n  j._pipeline_snapshots = j._pipeline_snapshots || {};\n  j._pipeline_snapshots.afterPII = redactedText;\n\n  j.pii = {\n    redactedPreview: redactedText.substring(0, 200),\n    previewRedactionCount: redactionCount,\n    has: hasPII,\n    detection_method: results.detection_method,\n    processing_time_ms: results.processing_time_ms,\n    entities_detected: results.entities.length,\n    language_stats: results.language_stats || {},\n    entities: results.entities.map(e => ({\n      type: e.type,\n      start: e.start,\n      end: e.end,\n      score: e.score\n    }))\n  };\n\n  j.output_text_redacted = redactedText;\n  j.pii_error = null;\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;\n\nfunction deduplicateEntities(entities) {\n  if (entities.length <= 1) return entities;\n\n  const sorted = entities.sort((a, b) => {\n    if (a.start !== b.start) return a.start - b.start;\n    return b.score - a.score;\n  });\n\n  const unique = [];\n  for (const entity of sorted) {\n    const overlaps = unique.some(existing => {\n      return (\n        (entity.start >= existing.start && entity.start < existing.end) ||\n        (entity.end > existing.start && entity.end <= existing.end) ||\n        (entity.start <= existing.start && entity.end >= existing.end)\n      );\n    });\n\n    if (!overlaps) {\n      unique.push(entity);\n    }\n  }\n\n  return unique;\n}\n\nfunction getRedactionToken(entityType, originalText, piiConfig) {\n  const redactionMode = piiConfig.redaction_mode || 'replace';\n  const tokens = piiConfig.redaction_tokens || {};\n\n  switch (redactionMode) {\n    case 'replace':\n      return tokens[entityType] || `[${entityType}]`;\n\n    case 'mask':\n      if (originalText.length <= 4) {\n        return '*'.repeat(originalText.length);\n      }\n      const first = originalText.substring(0, 2);\n      const last = originalText.substring(originalText.length - 2);\n      const masked = '*'.repeat(originalText.length - 4);\n      return `${first}${masked}${last}`;\n\n    default:\n      return tokens[entityType] || `[${entityType}]`;\n  }\n}\n\nfunction applyLegacyPiiRules(text, piiConf, piiConfig) {\n  const startTime = Date.now();\n\n  if (!piiConf || !piiConf.rules) {\n    console.warn('No pii_conf available for fallback');\n    return {\n      entities: [],\n      redacted_text: text,\n      detection_method: 'regex_fallback_failed',\n      processing_time_ms: 0,\n      error: 'No pii.conf rules available'\n    };\n  }\n\n  const entities = [];\n  let redactedText = text;\n  const order = piiConf.order || piiConf.rules.map(r => r.name);\n\n  for (const ruleName of order) {\n    const rule = piiConf.rules.find(r => r.name === ruleName);\n    if (!rule) continue;\n\n    try {\n      const re = new RegExp(rule.pattern, rule.flags || 'giu');\n      let match;\n      const matches = [];\n\n      while ((match = re.exec(redactedText)) !== null) {\n        matches.push({\n          index: match.index,\n          length: match[0].length,\n          text: match[0]\n        });\n      }\n\n      matches.sort((a, b) => b.index - a.index);\n\n      for (const m of matches) {\n        const redactionToken = getRedactionToken(rule.name, m.text, piiConfig);\n\n        redactedText =\n          redactedText.substring(0, m.index) +\n          redactionToken +\n          redactedText.substring(m.index + m.length);\n\n        entities.push({\n          type: rule.name,\n          start: m.index,\n          end: m.index + m.length,\n          text: m.text,\n          score: 1.0,\n          source: 'regex'\n        });\n      }\n    } catch (e) {\n      console.warn(`PII regex failed for ${ruleName}:`, e.message);\n    }\n  }\n\n  return {\n    entities: entities,\n    redacted_text: redactedText,\n    detection_method: 'regex_fallback',\n    processing_time_ms: Date.now() - startTime,\n    error: null\n  };\n}\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3168,
        -96
      ],
      "id": "1d678bfb-3552-46ea-9cfc-e34f7f53f77d",
      "name": "PII_Redactor_v2"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Correlation_Engine - FIXED: Added items validation\n */\n\nfunction nowIsoMs() { return new Date().toISOString(); }\n\nfunction mergeDecision(j, decision, source, extraMeta = {}) {\n  j.decision = j.decision || {};\n  Object.assign(j.decision, {\n    decision: decision,\n    source: source,\n    updated_at: nowIsoMs()\n  });\n  \n  j.__metadata = Object.assign({}, j.__metadata || {}, {\n    final_decision: decision,\n    decision_source: source,\n    ...extraMeta\n  });\n  \n  if (decision === 'BLOCK') {\n    j._isBlocked = true;\n  }\n}\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Correlation_Engine: No input items');\n  return [];\n}\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  \n  // Skip correlation if validation failed\n  if (j.configError === true) {\n    item.json = j;\n    continue;\n  }\n  \n  const sigs = j.normalization?.obfuscationSignals || [];\n  const dec = j.decision?.decision || \"ALLOW\";\n\n  let escalated = dec;\n  \n  if (sigs.includes(\"template-markers\")) {\n    escalated = \"BLOCK\";\n  }\n  else if (sigs.includes(\"math-alnum/fraktur\")) {\n    // Math/Fraktur obfuscation - single escalation level\n    if (dec === \"ALLOW\") escalated = \"SANITIZE_LIGHT\";\n    else if (dec === \"SANITIZE_LIGHT\") escalated = \"SANITIZE_HEAVY\";\n    else if (dec === \"SANITIZE_HEAVY\") escalated = \"BLOCK\";\n  }\n  else {\n    // Mixed scripts detection (Phase 2.1) - 4-level escalation based on script count\n    const mixedScriptsSig = sigs.find(s => s.startsWith(\"mixed-scripts-\"));\n    if (mixedScriptsSig) {\n      const is3PlusScripts = mixedScriptsSig.endsWith('+');\n      \n      if (is3PlusScripts) {\n        // 3+ scripts = CRITICAL threat (30 pts bonus) - double escalation\n        if (dec === \"ALLOW\") escalated = \"SANITIZE_HEAVY\";  // Skip LIGHT\n        else if (dec === \"SANITIZE_LIGHT\") escalated = \"BLOCK\";  // Skip HEAVY\n        else if (dec === \"SANITIZE_HEAVY\") escalated = \"BLOCK\";\n      } else {\n        // 2 scripts = HIGH threat (15 pts bonus) - single escalation\n        if (dec === \"ALLOW\") escalated = \"SANITIZE_LIGHT\";\n        else if (dec === \"SANITIZE_LIGHT\") escalated = \"SANITIZE_HEAVY\";\n        else if (dec === \"SANITIZE_HEAVY\") escalated = \"BLOCK\";\n      }\n    }\n  }\n\n  const correlationReason = escalated !== dec \n    ? `ESCALATED_FROM_${dec}_BY_SIGNALS_${sigs.join(',')}` \n    : (j.decision?.reason || 'POLICY');\n\n  j.correlation = { \n    signals: sigs, \n    before: dec, \n    after: escalated,\n    escalated: escalated !== dec\n  };\n  \n  mergeDecision(j, escalated, 'correlation_engine', {\n    correlation_applied: escalated !== dec,\n    correlation_signals: sigs,\n    previous_decision: dec,\n    reason: correlationReason,\n    escalated_by_correlation: escalated !== dec\n  });\n  \n  item.json = j;\n}\n\nreturn items;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1728,
        -96
      ],
      "id": "2281e6dc-c048-45ca-9879-2d19cee0778c",
      "name": "Correlation_Engine"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Pattern_Matching_Engine - OPTIMIZED VERSION (Faza 2.2)\n *\n * OPTIMIZATIONS:\n * 1. Pre-compilation: Regex patterns compiled once and cached\n * 2. Early exit: Loop breaks when totalScore >= 100\n * 3. Category sorting: Process high-weight categories first for faster exit\n *\n * Target: 20% latency reduction on P95\n */\n\n// ============================================================================\n// GLOBAL REGEX CACHE - Persists across workflow executions\n// ============================================================================\n// Note: In n8n Code nodes, global variables persist during the workflow run\n// but are cleared when workflow is restarted. This is acceptable for caching.\nif (typeof globalThis.COMPILED_PATTERNS_CACHE === 'undefined') {\n  globalThis.COMPILED_PATTERNS_CACHE = new Map();\n  globalThis.CACHE_STATS = { hits: 0, misses: 0, compilations: 0 };\n}\n\n/**\n * Safe regex compilation with caching\n * @param {string} pattern - Regex pattern string\n * @param {string} flags - Regex flags (default: 'giu')\n * @returns {RegExp|null} Compiled regex or null if invalid\n */\nfunction safeRegexCached(pattern, flags = 'giu') {\n  const cacheKey = `${pattern}|||${flags}`;\n\n  // Check cache first\n  if (globalThis.COMPILED_PATTERNS_CACHE.has(cacheKey)) {\n    globalThis.CACHE_STATS.hits++;\n    return globalThis.COMPILED_PATTERNS_CACHE.get(cacheKey);\n  }\n\n  // Cache miss - compile new regex\n  globalThis.CACHE_STATS.misses++;\n  try {\n    const regex = new RegExp(pattern, flags);\n    globalThis.COMPILED_PATTERNS_CACHE.set(cacheKey, regex);\n    globalThis.CACHE_STATS.compilations++;\n    return regex;\n  } catch (e) {\n    console.warn(`Invalid regex pattern: ${pattern}`, e);\n    // Cache the null result to avoid recompiling invalid patterns\n    globalThis.COMPILED_PATTERNS_CACHE.set(cacheKey, null);\n    return null;\n  }\n}\n\n/**\n * Calculate category score based on match count\n */\nfunction calculateCategoryScore(baseWeight, multiplier, matchCount) {\n  if (matchCount === 0) return 0;\n  return Math.round(baseWeight * Math.pow(multiplier, matchCount - 1));\n}\n\n// ============================================================================\n// MAIN PROCESSING LOGIC\n// ============================================================================\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Pattern_Matching_Engine: No input items');\n  return [];\n}\n\nconst out = [];\nconst startTime = Date.now(); // Track overall execution time\n\nfor (const item of items) {\n  const itemStartTime = Date.now();\n  const j = item.json ?? {};\n\n  // Skip only if config error (not if already blocked - we still want to add detection metadata)\n  if (j.configError === true) {\n    out.push(item);\n    continue;\n  }\n\n  // Check if already blocked (will skip pattern matching but still add detection bonuses)\n  const alreadyBlocked = (j._isBlocked === true);\n\n  const text = j.normalization?.forScoring ?? j.chat_payload?.chatInput ?? \"\";\n  const rules = j.rules?.categories ?? {};\n\n  if (!text) {\n    j.scoreBreakdown = {};\n    j.score = 0;\n    j._performance = { patternMatchingMs: 0, earlyExitTriggered: false };\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n\n  const scoreBreakdown = {};\n  let totalScore = 0;\n  const matchDetails = [];\n  let earlyExitTriggered = false;\n  let categoriesProcessed = 0;\n\n  // Only run expensive pattern matching if NOT already blocked\n  if (!alreadyBlocked) {\n    // OPTIMIZATION: Sort categories by base_weight DESC for faster early exit\n    const sortedCategories = Object.entries(rules).sort((a, b) => {\n      const weightA = a[1].base_weight || 0;\n      const weightB = b[1].base_weight || 0;\n      return weightB - weightA; // Descending order\n    });\n\n    // Iterate through categories (highest weight first)\n    for (const [categoryName, categoryData] of sortedCategories) {\n      const { base_weight, multiplier, patterns } = categoryData;\n\n      if (!patterns || !Array.isArray(patterns)) continue;\n\n      categoriesProcessed++;\n      let categoryMatchCount = 0;\n      const categoryMatches = [];\n\n      // Iterate through patterns in category\n      for (const pattern of patterns) {\n        const re = safeRegexCached(pattern, 'giu');\n        if (!re) continue;\n\n        // Reset lastIndex for global regex (important!)\n        re.lastIndex = 0;\n        const matches = text.match(re);\n\n        if (matches && matches.length > 0) {\n          categoryMatchCount += matches.length;\n          categoryMatches.push({\n            pattern: pattern.substring(0, 50),\n            count: matches.length,\n            samples: matches.slice(0, 3).map(m => m.substring(0, 50) + (m.length > 50 ? '...' : ''))\n          });\n        }\n      }\n\n      // Add category score if matches found\n      if (categoryMatchCount > 0) {\n        const categoryScore = calculateCategoryScore(base_weight, multiplier, categoryMatchCount);\n        scoreBreakdown[categoryName] = categoryScore;\n        totalScore += categoryScore;\n\n        matchDetails.push({\n          category: categoryName,\n          matchCount: categoryMatchCount,\n          score: categoryScore,\n          matches: categoryMatches\n        });\n      }\n\n      // OPTIMIZATION: Early exit if score already at maximum\n      if (totalScore >= 100) {\n        earlyExitTriggered = true;\n        break;\n      }\n    }\n  }\n\n  // Add suspicion bonus from mixed scripts detection\n  const mixedScripts = j.normalization?.mixedScripts || {};\n  if (mixedScripts.suspicionBonus > 0) {\n    totalScore += mixedScripts.suspicionBonus;\n    matchDetails.push({\n      category: \"Mixed Scripts\",\n      score: mixedScripts.suspicionBonus,\n      matches: [mixedScripts.signal]\n    });\n  }\n\n  // Add encoding detection bonus (ENHANCED: Higher scores for suspicious encoding)\n  const decodingDetected = j.normalization?.decodingDetected || {};\n  if (decodingDetected.levelsDetected > 0) {\n    // Calculate bonus based on encoding types (base64 is VERY suspicious in prompts)\n    let encodingBonus = 0;\n    const encodingTypes = [];\n\n    for (const step of decodingDetected.steps) {\n      encodingTypes.push(step.type);\n      if (step.type === 'base64') {\n        encodingBonus += 45;  // Base64 in prompts is HIGHLY suspicious\n      } else if (step.type === 'url') {\n        encodingBonus += 30;  // URL encoding in prompts is very suspicious\n      } else if (step.type === 'hex') {\n        encodingBonus += 35;  // Hex encoding is quite suspicious\n      }\n    }\n\n    totalScore += encodingBonus;\n    matchDetails.push({\n      category: \"Encoding Detection\",\n      score: encodingBonus,\n      matches: [`${decodingDetected.levelsDetected} layer(s): ${encodingTypes.join(', ')}`]\n    });\n    scoreBreakdown[\"ENCODING_DETECTED\"] = encodingBonus;\n  }\n\n  // Add obfuscation detection bonus (whitespace, zero-width chars)\n  const obfuscationDetected = j.normalization?.obfuscationDetected || {};\n  if (obfuscationDetected.detected && obfuscationDetected.score > 0) {\n    totalScore += obfuscationDetected.score;\n    matchDetails.push({\n      category: \"Obfuscation Detection\",\n      score: obfuscationDetected.score,\n      matches: obfuscationDetected.signals\n    });\n    scoreBreakdown[\"OBFUSCATION_DETECTED\"] = obfuscationDetected.score;\n  }\n\n  // Cap score at 100\n  if (totalScore > 100) totalScore = 100;\n\n  // Calculate item processing time\n  const itemProcessingMs = Date.now() - itemStartTime;\n\n  // Store results\n  j.scoreBreakdown = scoreBreakdown;\n  j.score = totalScore;\n  j.matchDetails = matchDetails;\n  j._performance = {\n    patternMatchingMs: itemProcessingMs,\n    earlyExitTriggered: earlyExitTriggered,\n    categoriesProcessed: categoriesProcessed,\n    totalCategories: Object.keys(rules).length,\n    cacheStats: {\n      hits: globalThis.CACHE_STATS.hits,\n      misses: globalThis.CACHE_STATS.misses,\n      compilations: globalThis.CACHE_STATS.compilations,\n      cacheSize: globalThis.COMPILED_PATTERNS_CACHE.size\n    }\n  };\n\n  item.json = j;\n  out.push(item);\n}\n\n// Log overall execution stats\nconst totalExecutionMs = Date.now() - startTime;\nconsole.log(`Pattern_Matching_Engine OPTIMIZED: Processed ${items.length} items in ${totalExecutionMs}ms (avg: ${(totalExecutionMs / items.length).toFixed(2)}ms/item)`);\nconsole.log(`Cache stats: ${globalThis.CACHE_STATS.hits} hits, ${globalThis.CACHE_STATS.misses} misses, ${globalThis.CACHE_STATS.compilations} compilations, ${globalThis.COMPILED_PATTERNS_CACHE.size} cached patterns`);\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2224,
        -96
      ],
      "id": "f4f43063-6353-4bca-b58d-20865dcdce93",
      "name": "Pattern_Matching_Engine"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data3",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        576
      ],
      "id": "cd2a6cd0-f502-4a51-a2bb-9998981a9cd2",
      "name": "Extract from File2"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/pii.conf",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        576
      ],
      "id": "b47545b4-bc2e-42a8-8f2b-dbf0f59335fb",
      "name": "Loading config files *.conf1"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data4",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        784
      ],
      "id": "31452111-df45-4897-81ce-5e9b412aa2e2",
      "name": "Extract from File3"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/thresholds.config.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        784
      ],
      "id": "d017fced-6b25-4508-b8d6-4d9818c79a6b",
      "name": "Loading config files *.conf2"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data5",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        1008
      ],
      "id": "4dbcbe64-8069-440e-909e-180774df4e91",
      "name": "Extract from File4"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/unified_config.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        1008
      ],
      "id": "4e0bf0d8-7cce-42e2-8e46-6adcd8242e23",
      "name": "Loading config files *.conf3"
    },
    {
      "parameters": {
        "operation": "text",
        "destinationKey": "data6",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -4208,
        1232
      ],
      "id": "7dd747d7-c96d-4fa1-bfd6-d8571ba8b291",
      "name": "Extract from File5"
    },
    {
      "parameters": {
        "fileSelector": "=/home/node/config/rules.config.json",
        "options": {
          "mimeType": "application/json",
          "dataPropertyName": "data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -4384,
        1232
      ],
      "id": "6eb6c5b0-f92d-4c44-9e7c-7d0227d63563",
      "name": "Loading config files *.conf4"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Final Decision Node - BINARY CLASSIFICATION MODE\n * Updated for Llama Prompt Guard 2 (CRITICAL / MINIMAL only)\n * ADDED: output_text field for unified output logic\n * FIXED: shouldWarn and shouldSanitize detection for SANITIZED status\n */\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  throw new Error('Final Decision: No input items available');\n}\n\n// ========================================\n// HELPER FUNCTIONS\n// ========================================\n\nconst in01Regex = /(?:^|[^\\d])(1(?:\\.0+)?|0?\\.?\\d+|0)(?!\\d)/;\n\nfunction tryParse01(val) {\n  if (val === null || val === undefined) return null;\n  if (typeof val === 'number' && val >= 0 && val <= 100) return val;  // Accept 0-100 range\n  const str = String(val);\n  const m = str.match(in01Regex);\n  if (!m) return null;\n  const v = parseFloat(m[1]);\n  return (v >= 0 && v <= 100) ? v : null;  // Accept 0-100 range\n}\n\nfunction pickCtxItem(all) {\n  const fullConfigItem = all.find(it => {\n    const j = it?.json;\n    return j && j.config && j.rules && j.thresholds && j.chat_payload;\n  });\n  if (fullConfigItem) return fullConfigItem;\n\n  const configItem = all.find(it => {\n    const j = it?.json;\n    return j && (j.config || j.data5);\n  });\n  if (configItem) return configItem;\n\n  const restoredItem = all.find(it => {\n    const j = it?.json;\n    return j && j._llm_context_restored === true;\n  });\n  if (restoredItem) return restoredItem;\n\n  return all[0];\n}\n\nfunction findPgScore(all) {\n  let score = null, src = null, raw = null;\n\n  for (const it of all) {\n    const j = it?.json;\n\n    // Check for risk_score from Prompt Guard API\n    if (j && typeof j.risk_score === 'number') {\n      score = j.risk_score;\n      src = 'json.risk_score (Prompt Guard API)';\n      raw = j;\n      break;\n    }\n\n    if (j && j.llm_result && typeof j.llm_result.score === 'number') {\n      score = j.llm_result.score;\n      src = 'llm_result.score (restored context)';\n      raw = j.llm_result.raw_output;\n      break;\n    }\n\n    if (typeof j === 'string') {\n      const v = tryParse01(j);\n      if (v !== null) { score = v; src = 'json:string'; raw = j; break; }\n    }\n\n    if (Array.isArray(j) && j.length) {\n      const first = j[0];\n      if (first && typeof first === 'object' && 'text' in first) {\n        const v = tryParse01(first.text);\n        if (v !== null) { score = v; src = 'array[0].text'; raw = first; break; }\n      } else {\n        const v = tryParse01(first);\n        if (v !== null) { score = v; src = 'array[0]'; raw = first; break; }\n      }\n    }\n\n    if (j && typeof j === 'object' && 'text' in j) {\n      const v = tryParse01(j.text);\n      if (v !== null) { score = v; src = 'json.text'; raw = j.text; break; }\n    }\n\n    if (j && j.data && Array.isArray(j.data) && j.data[0] && 'text' in j.data[0]) {\n      const v = tryParse01(j.data[0].text);\n      if (v !== null) { score = v; src = 'json.data[0].text'; raw = j.data[0].text; break; }\n    }\n\n    if (j && j.metrics && j.metrics.injectionScore !== undefined) {\n      const v = tryParse01(j.metrics.injectionScore);\n      if (v !== null) { score = v; src = 'json.metrics.injectionScore'; raw = j.metrics.injectionScore; break; }\n    }\n  }\n\n  if (score === null) { score = 0; src = 'default:0'; raw = null; }\n\n  return { score, src, raw };\n}\n\n// ========================================\n// MAIN LOGIC\n// ========================================\n\nconst ctxItem = pickCtxItem(items);\nconst { score: injectionScoreRaw, src: extractedFrom, raw: pgRaw } = findPgScore(items);\n\nlet config = ctxItem?.json?.config || ctxItem?.json?.data5;\n\nif (!config) {\n  const configFromOtherItem = items.find(it => it?.json?.config || it?.json?.data5);\n\n  if (!configFromOtherItem) {\n    throw new Error(\n      'Final Decision: Missing config in all items. ' +\n      'Ensure Config Loader output is properly merged. ' +\n      'Available item keys: ' +\n      items.map((it, i) => `[${i}]: ${Object.keys(it?.json || {}).join(', ')}`).join(' | ')\n    );\n  }\n\n  config = configFromOtherItem.json.config || configFromOtherItem.json.data5;\n\n  if (!ctxItem.json.rules && configFromOtherItem.json.rules) {\n    ctxItem.json.rules = configFromOtherItem.json.rules;\n  }\n  if (!ctxItem.json.thresholds && configFromOtherItem.json.thresholds) {\n    ctxItem.json.thresholds = configFromOtherItem.json.thresholds;\n  }\n}\n\nconst promptGuardConfig = config.prompt_guard_policy;\nif (!promptGuardConfig) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy');\n}\n\nconst configEnabled = promptGuardConfig.enabled !== false;\nconst riskLevelsConfig = promptGuardConfig.risk_levels;\n\nif (!riskLevelsConfig) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy.risk_levels');\n}\n\n// Binary classification: only CRITICAL and MINIMAL required\nif (!riskLevelsConfig.CRITICAL) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy.risk_levels.CRITICAL');\n}\nif (!riskLevelsConfig.MINIMAL) {\n  throw new Error('Final Decision: Missing config.prompt_guard_policy.risk_levels.MINIMAL');\n}\n\nif (typeof riskLevelsConfig.CRITICAL.threshold_min !== 'number') {\n  throw new Error('Final Decision: Missing threshold_min for CRITICAL risk level');\n}\nif (typeof riskLevelsConfig.MINIMAL.threshold_min !== 'number') {\n  throw new Error('Final Decision: Missing threshold_min for MINIMAL risk level');\n}\nif (!riskLevelsConfig.CRITICAL.policy) {\n  throw new Error('Final Decision: Missing policy for CRITICAL risk level');\n}\nif (!riskLevelsConfig.MINIMAL.policy) {\n  throw new Error('Final Decision: Missing policy for MINIMAL risk level');\n}\n\nconst thresholds = {\n  critical: riskLevelsConfig.CRITICAL.threshold_min,\n  minimal: riskLevelsConfig.MINIMAL.threshold_min\n};\n\nconst policies = {\n  CRITICAL: riskLevelsConfig.CRITICAL.policy,\n  MINIMAL: riskLevelsConfig.MINIMAL.policy\n};\n\nif (!config.enforcement || !config.enforcement.block_message) {\n  throw new Error('Final Decision: Missing config.enforcement.block_message');\n}\nconst blockMessage = config.enforcement.block_message;\n\nlet injectionScore = Math.max(0, Math.min(100, injectionScoreRaw));  // Accept 0-100 range\nlet riskLevel, severity;\n\n// Binary classification: CRITICAL (>=0.9) or MINIMAL (<0.9)\nif (injectionScore >= thresholds.critical * 100) {  // Compare in 0-100 scale\n  riskLevel = 'CRITICAL';\n  severity = 5;\n} else {\n  riskLevel = 'MINIMAL';\n  severity = 1;\n}\n\nconst configPolicy = policies[riskLevel];\nconst shouldBlockByPolicy = configPolicy === 'block';\n\nlet action, route, userMessage = null, internalNote;\n\nif (riskLevel === 'CRITICAL') {\n  if (shouldBlockByPolicy) {\n    action = 'BLOCK_IMMEDIATE';\n    route = 'blocked';\n    userMessage = blockMessage;\n    internalNote = `Critical injection attempt detected by Prompt Guard (risk_score: ${injectionScore.toFixed(4)}) - blocked by policy=${configPolicy}`;\n  } else {\n    action = 'ALLOW_WITH_LOGGING';\n    route = 'safe';\n    userMessage = null;\n    internalNote = `Critical risk detected (risk_score: ${injectionScore.toFixed(4)}) - allowed by policy=${configPolicy} (unusual config)`;\n  }\n} else {\n  // MINIMAL risk level\n  if (shouldBlockByPolicy) {\n    action = 'BLOCK_WITH_WARNING';\n    route = 'blocked';\n    userMessage = blockMessage;\n    internalNote = `Minimal risk (risk_score: ${injectionScore < 0.01 ? injectionScore.toExponential(2) : injectionScore.toFixed(4)}) - blocked by policy=${configPolicy} (unusual config)`;\n  } else {\n    action = 'ALLOW';\n    route = 'safe';\n    userMessage = null;\n    internalNote = `Safe request confirmed by Prompt Guard (risk_score: ${injectionScore < 0.01 ? injectionScore.toExponential(2) : injectionScore.toFixed(4)}) - allowed`;\n  }\n}\n\n// Check for sanitizer override\nconst previousDecision =\n  ctxItem?.json?.decision?.decision ||\n  ctxItem?.json?.__metadata?.final_decision ||\n  ctxItem?.json?.correlation?.after;\n\nif (previousDecision === 'BLOCK' || previousDecision === 'blocked' || ctxItem?.json?._isBlocked === true) {\n  route = 'blocked';\n  action = 'BLOCK_BY_SANITIZER';\n  userMessage = userMessage || blockMessage;\n  internalNote += ' | Forced block by sanitizer (previousDecision=' + previousDecision + ', _isBlocked=' + ctxItem?.json?._isBlocked + ')';\n}\n\n// ========================================\n// DETECT SANITIZATION\n// ========================================\n\n// Check if content was sanitized by Sanitization_Enforcement node\nconst enforcementMode = ctxItem?.json?.enforcement?.mode;\nconst wasSanitized = (enforcementMode === 'light' || enforcementMode === 'heavy');\n\n// Alternative check: previous decision was SANITIZE_LIGHT or SANITIZE_HEAVY\nconst sanitizeDecision = (\n  previousDecision === 'SANITIZE_LIGHT' ||\n  previousDecision === 'SANITIZE_HEAVY'\n);\n\n// Final sanitization flag\nconst isSanitized = wasSanitized || sanitizeDecision;\n\n// ========================================\n// DETERMINE OUTPUT_TEXT\n// ========================================\n\nlet outputText;\n\nif (route === 'blocked') {\n  // BLOCKED: use block message\n  outputText = userMessage || blockMessage;\n} else {\n  // ALLOWED or SANITIZED: use text after PII redaction or sanitization\n  outputText = ctxItem?.json?._pipeline_snapshots?.afterSanitization ||\n               ctxItem?.json?._pipeline_snapshots?.afterPII ||\n               ctxItem?.json?.output_text_redacted ||\n               ctxItem?.json?.chat_payload?.chatInput ||\n               ctxItem?.json?.normalization?.canonical ||\n               'N/A';\n}\n\n// ========================================\n// BUILD RESULT\n// ========================================\n\nconst result = {\n  decision: {\n    action,\n    route,\n    severity,\n    riskLevel,\n    scoreRaw: injectionScore,\n    scorePercent: Math.round(injectionScore * 100),\n    scoreFormatted: injectionScore < 0.01 ? injectionScore.toExponential(2) : injectionScore.toFixed(4),\n    appliedPolicy: configPolicy,\n    model: 'Llama-Prompt-Guard-2-86M'\n  },\n  messages: {\n    user: userMessage,\n    internal: internalNote\n  },\n  routing: {\n    shouldBlock: route === 'blocked',\n    shouldWarn: isSanitized && route !== 'blocked',  // \u2713 FIXED: detect sanitization\n    shouldLog: severity >= 2,\n    shouldSanitize: isSanitized,  // \u2713 FIXED: detect sanitization\n    isSafe: route === 'safe' && !isSanitized  // Safe only if NOT sanitized\n  },\n  metrics: {\n    injectionScore,\n    scorePercent: Math.round(injectionScore * 100),\n    severity,\n    confidence: injectionScore > 0.9 || injectionScore < 0.1 ? 'high' : 'medium',\n    processingTime: Date.now()\n  },\n  technical: {\n    thresholdsUsed: thresholds,\n    policiesUsed: policies,\n    configEnabled: configEnabled,\n    pgRaw,\n    extractedFrom,\n    binaryClassification: true,\n    enforcementMode: enforcementMode || 'none',  // \u2713 ADDED: debugging info\n    wasSanitized: isSanitized  // \u2713 ADDED: debugging info\n  },\n  audit: {\n    timestamp: new Date().toISOString(),\n    node: 'final_decision',\n    originalPrompt:\n      ctxItem?.json?.output_text_redacted ||\n      ctxItem?.json?.chatInput ||\n      ctxItem?.json?.input ||\n      ctxItem?.json?.chat_payload?.chatInput ||\n      'N/A',\n    llmScore: injectionScore,\n    finalDecision: action,\n    appliedPolicy: configPolicy,\n    configSource: 'unified_config.json',\n    previousDecision: previousDecision || 'none',\n    blockFlagSet: ctxItem?.json?._isBlocked === true,\n    promptGuardModel: 'Llama-Prompt-Guard-2-86M',\n    sanitizationApplied: isSanitized  // \u2713 ADDED: audit trail\n  },\n\n  __san: ctxItem?.json?.__san || {},\n  _pipeline_snapshots: ctxItem?.json?._pipeline_snapshots || {},\n  normalization: ctxItem?.json?.normalization || {},\n  chat_payload: ctxItem?.json?.chat_payload || {},\n  sessionId: ctxItem?.json?.sessionId || ctxItem?.json?.chat_payload?.sessionId || 'unknown',\n  action: ctxItem?.json?.action || ctxItem?.json?.chat_payload?.action || 'sendMessage',\n  config: config,\n  rules: ctxItem?.json?.rules || {},\n  thresholds: ctxItem?.json?.thresholds || {},\n  enforcement: ctxItem?.json?.enforcement || {},\n  _loader: ctxItem?.json?._loader || {},\n  score: ctxItem?.json?.score || 0,\n  scoreBreakdown: ctxItem?.json?.scoreBreakdown || {},\n  matchDetails: ctxItem?.json?.matchDetails || [],\n  sanitizer_decision: ctxItem?.json?.decision || {},\n\n  // \u2713 UNIFIED OUTPUT FIELD\n  output_text: outputText,\n\n  _route: route,\n  _shouldContinue: route === 'safe',\n  _requiresSanitization: isSanitized,  // \u2713 FIXED: proper sanitization flag\n  _isBlocked: route === 'blocked'\n};\n\nreturn [{\n  json: result,\n  binary: ctxItem?.binary || {}\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        208,
        -96
      ],
      "id": "aaafca70-47bc-4833-a130-078ca29fa42d",
      "name": "Finale Decision"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {
          "includeUnpaired": true
        }
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -32,
        -96
      ],
      "id": "bcced283-8088-4d2b-9332-dd3db4ceec3d",
      "name": "Merge1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "36e14137-f077-4f9b-8bb7-0596338fa273",
              "leftValue": "={{ $json.decision?.decision }}",
              "rightValue": "BLOCK",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -1200,
        -96
      ],
      "id": "e34c0777-3231-45f7-ad97-7bfee46ec2da",
      "name": "If"
    },
    {
      "parameters": {
        "jsCode": "// NEW VERSION: LLM Context Restore with Multi-Chunk Aggregation\n\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json;\n  const responses = j.pg_responses || [];\n\n  // Helper function: Determine risk level from score\n  function determineRiskLevel(score) {\n    if (score >= 80) return 'CRITICAL';\n    if (score >= 60) return 'HIGH';\n    if (score >= 40) return 'MEDIUM';\n    if (score >= 20) return 'LOW';\n    return 'SAFE';\n  }\n\n  let riskScore = 0;\n  let llmRawOutput = null;\n  let llmVerdict = null;\n  let llmIsAttack = false;\n  let confidence = 0;\n\n  // CASE 1: Multi-chunk analysis (sliding window used)\n  if (responses.length > 1) {\n    const scores = responses.map(r => r.risk_score || 0);\n    const maxScore = Math.max(...scores);\n    const avgScore = scores.reduce((a, b) => a + b, 0) / scores.length;\n    const attackDetected = responses.some(r => r.is_attack);\n\n    // Use MAX score (most conservative approach)\n    riskScore = maxScore;\n    confidence = maxScore / 100;  // Convert to 0-1 range\n    llmIsAttack = attackDetected;\n    llmVerdict = attackDetected ? '\ud83d\udea8 ATTACK DETECTED (multi-chunk)!' : '\u2705 Safe (multi-chunk)';\n\n    // Create summary output\n    llmRawOutput = JSON.stringify({\n      analysis_type: 'sliding_window',\n      chunks_analyzed: responses.length,\n      max_score: maxScore,\n      avg_score: avgScore.toFixed(2),\n      attack_detected: attackDetected,\n      chunks_with_attacks: responses.filter(r => r.is_attack).length,\n      chunks_details: responses.map(r => ({\n        index: r.chunk_index,\n        score: r.risk_score,\n        is_attack: r.is_attack,\n        verdict: r.verdict\n      }))\n    });\n\n    // Store detailed aggregation in j\n    j.llm_guard_score = maxScore;\n    j.llm_guard_score_avg = avgScore;\n    j.llm_guard_score_max = maxScore;\n    j.llm_guard_attack_detected = attackDetected;\n    j.risk_level = determineRiskLevel(maxScore);\n\n    // Audit trail\n    j.audit = j.audit || {};\n    j.audit.chunks_analyzed = responses.length;\n    j.audit.chunks_with_attacks = responses.filter(r => r.is_attack).length;\n    j.audit.sliding_window_used = j.sliding_window_enabled || false;\n  }\n  // CASE 2: Single chunk analysis (original behavior) or fallback\n  else if (responses.length === 1) {\n    const apiData = responses[0];\n\n    riskScore = apiData.risk_score || 0;\n    confidence = apiData.confidence || 0;\n    llmIsAttack = apiData.is_attack || false;\n    llmVerdict = apiData.verdict || 'unknown';\n\n    llmRawOutput = JSON.stringify({\n      analysis_type: 'single_chunk',\n      text: apiData.text_analyzed,\n      is_attack: apiData.is_attack,\n      risk_score: apiData.risk_score,\n      confidence: apiData.confidence,\n      verdict: apiData.verdict\n    });\n\n    j.llm_guard_score = riskScore;\n    j.llm_guard_attack_detected = llmIsAttack;\n    j.risk_level = determineRiskLevel(riskScore);\n\n    // Audit trail\n    j.audit = j.audit || {};\n    j.audit.chunks_analyzed = 1;\n    j.audit.chunks_with_attacks = llmIsAttack ? 1 : 0;\n    j.audit.sliding_window_used = false;\n  }\n  // CASE 3: No responses (error fallback)\n  else {\n    riskScore = 0;\n    confidence = 0;\n    llmIsAttack = false;\n    llmVerdict = 'no_analysis';\n    llmRawOutput = JSON.stringify({ error: 'No Prompt Guard responses available' });\n\n    j.llm_guard_score = 0;\n    j.llm_guard_attack_detected = false;\n    j.risk_level = 'SAFE';\n\n    j.audit = j.audit || {};\n    j.audit.chunks_analyzed = 0;\n    j.audit.chunks_with_attacks = 0;\n    j.audit.sliding_window_used = false;\n    j.audit.error = 'no_pg_responses';\n  }\n\n  // Ensure score is valid (0-100 range for compatibility)\n  if (isNaN(riskScore)) riskScore = 0;\n  riskScore = Math.max(0, Math.min(100, riskScore));\n\n  // Normalize to 0-1 range for risk_score (backwards compatible)\n  j.risk_score = riskScore;  // Already in 0-100 range from Prompt Guard API node\n\n  // Store full result object\n  j.llm_result = {\n    score: riskScore,  // 0-100 range (already scaled)\n    score_raw: riskScore,    // 0-100 range\n    raw_output: llmRawOutput,\n    is_attack: llmIsAttack,\n    verdict: llmVerdict,\n    confidence: confidence,\n    source: 'meta-llama/llama-prompt-guard-2-86m',\n    timestamp: new Date().toISOString()\n  };\n\n  j._llm_context_restored = true;\n\n  // Clean up temporary fields\n  delete j.chunks_array;\n  delete j.pg_responses;\n\n  results.push({\n    json: j,\n    pairedItem: item.pairedItem\n  });\n}\n\nreturn results;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -304,
        80
      ],
      "id": "65c6b974-d8be-4097-a21b-d146b1901c9a",
      "name": "LLM Context Restore"
    },
    {
      "parameters": {
        "jsCode": "// NEW VERSION: Prepare LLM Request with Sliding Window Analysis\n\n/**\n * Analyzes text using sliding window approach for long inputs\n * @param {string} text - Input text to analyze\n * @param {number} windowSize - Size of each chunk (default: 500)\n * @param {number} stride - Step size between chunks (default: 250)\n * @param {number} maxChunks - Maximum number of chunks (default: 5)\n * @returns {Array} Array of chunk objects\n */\nfunction analyzeWithSlidingWindow(text, windowSize = 500, stride = 250, maxChunks = 5) {\n  // If text shorter than window \u2192 return single chunk\n  if (text.length <= windowSize) {\n    return [{\n      chunk: text,\n      start: 0,\n      end: text.length,\n      index: 0,\n      isLast: true\n    }];\n  }\n\n  const chunks = [];\n  let position = 0;\n  let chunkIndex = 0;\n\n  while (position < text.length && chunkIndex < maxChunks) {\n    const end = Math.min(position + windowSize, text.length);\n    const chunk = text.substring(position, end);\n\n    chunks.push({\n      chunk: chunk,\n      start: position,\n      end: end,\n      index: chunkIndex,\n      isLast: (end === text.length)\n    });\n\n    position += stride;\n    chunkIndex++;\n\n    // Break if we reached end\n    if (end === text.length) break;\n  }\n\n  return chunks;\n}\n\n// Main n8n node logic\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json;\n\n  const content = j._pipeline_snapshots?.afterSanitization ||\n                  j.chat_payload?.chatInput ||\n                  \"test\";\n\n  // Determine if sliding window should be used\n  const preliminaryScore = j.unified_decision?.threat_score || 0;\n  const shouldUseSlidingWindow = (\n    content.length > 500 &&                    // Text longer than window\n    preliminaryScore >= 30                     // Suspicious enough (SANITIZE_LIGHT or higher)\n  );\n\n  let chunksArray;\n  let slidingWindowEnabled;\n\n  if (shouldUseSlidingWindow) {\n    chunksArray = analyzeWithSlidingWindow(content);\n    slidingWindowEnabled = true;\n  } else {\n    // Single chunk mode (original behavior)\n    chunksArray = [{\n      chunk: content,\n      start: 0,\n      end: content.length,\n      index: 0,\n      isLast: true\n    }];\n    slidingWindowEnabled = false;\n  }\n\n  results.push({\n    json: {\n      ...j,\n      chunks_array: chunksArray,\n      sliding_window_enabled: slidingWindowEnabled,\n      sliding_window_config: {\n        window_size: 500,\n        stride: 250,\n        max_chunks: 5,\n        text_length: content.length,\n        chunks_generated: chunksArray.length\n      }\n    },\n    pairedItem: item.pairedItem\n  });\n}\n\nreturn results;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -912,
        64
      ],
      "id": "8a799090-8564-48f3-901e-bb434d8887dc",
      "name": "Prepare LLM Request"
    },
    {
      "parameters": {
        "jsCode": "// NEW VERSION v1.3.4: Prompt Guard API with axios\n// Using axios (enabled via NODE_FUNCTION_ALLOW_EXTERNAL=axios)\n\nconst axios = require('axios');\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const j = item.json;\n  const chunksArray = j.chunks_array || [];\n  const responses = [];\n\n  // Loop through all chunks and call Prompt Guard API\n  for (const chunkData of chunksArray) {\n    try {\n      // Call Prompt Guard API using axios\n      const response = await axios.post('http://prompt-guard-api:8000/detect', {\n        text: chunkData.chunk\n      }, {\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        timeout: 10000  // 10 second timeout\n      });\n\n      const result = response.data;\n\n      // Store response with chunk metadata\n      responses.push({\n        chunk_index: chunkData.index,\n        chunk_start: chunkData.start,\n        chunk_end: chunkData.end,\n        is_attack: result.is_attack || false,\n        confidence: result.confidence || 0,\n        risk_score: (result.risk_score || 0) * 100,  // Convert 0-1 to 0-100\n        verdict: result.verdict || 'unknown',\n        text_analyzed: chunkData.chunk.substring(0, 100) + (chunkData.chunk.length > 100 ? '...' : '')\n      });\n\n    } catch (error) {\n      console.error(`\u26a0\ufe0f Prompt Guard CRITICAL ERROR - chunk ${chunkData.index}:`, error.message);\n\n      // FIX 2.5.2: FAIL-CLOSED - Treat errors as attacks (prevent bypass)\n      responses.push({\n        chunk_index: chunkData.index,\n        chunk_start: chunkData.start,\n        chunk_end: chunkData.end,\n        error: error.message,\n        risk_score: 95,  // \u2705 CRITICAL threat level\n        is_attack: true,  // \u2705 Fail-closed: treat errors as attacks\n        confidence: 0.95,\n        verdict: '\u26a0\ufe0f PG_ERROR - BLOCKED (fail-closed)',\n        _pg_error: true  // Audit flag for monitoring\n      });\n    }\n  }\n\n  // Attach all responses to item\n  results.push({\n    json: {\n      ...j,\n      pg_responses: responses,\n      chunks_analyzed: responses.length,\n      pg_api_timestamp: new Date().toISOString()\n    },\n    pairedItem: item.pairedItem\n  });\n}\n\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -720,
        208
      ],
      "id": "174f03d2-5a41-4a7c-86fe-0063595ebaf3",
      "name": "Prompt Guard API"
    },
    {
      "parameters": {
        "mode": "combineByPosition"
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -528,
        80
      ],
      "id": "96c2fc25-ec06-4205-a28c-4ac91b4e4d59",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Bloom_Prefilter - FIXED VERSION\n *\n * PROBLEM: Poprzednia implementacja dodawa\u0142a pe\u0142ne frazy do Bloom Filter,\n * ale testowa\u0142a kr\u00f3tkie n-gramy (3-6 znak\u00f3w). To nigdy nie mog\u0142o zadzia\u0142a\u0107,\n * bo Bloom Filter operuje na pe\u0142nych stringach, nie substringach.\n *\n * ROZWI\u0104ZANIE: Opcja A (Performance-Optimized)\n * - Indeksuj wszystkie n-gramy z dangerous patterns\n * - Testuj n-gramy z input text\n * - To zapewnia sp\u00f3jno\u015b\u0107: te same typy string\u00f3w w obu operacjach\n *\n * ROZWI\u0104ZANIE ALTERNATYWNE: Opcja B (Higher Accuracy)\n * - Indeksuj pe\u0142ne frazy\n * - Testuj sliding windows r\u00f3\u017cnych d\u0142ugo\u015bci\n * - Wolniejsze, ale wykryje exact phrase matches\n */\n\nclass SimpleBloomFilter {\n  constructor(size = 32768, k = 5, seed = 1337) {\n    this.bits = new Uint8Array(size);\n    this.size = size;\n    this.k = k;\n    this.seed = seed;\n    this.itemCount = 0;\n  }\n\n  hash(str, seed) {\n    let h = seed;\n    for (let i = 0; i < str.length; i++) {\n      h ^= str.charCodeAt(i);\n      h = Math.imul(h ^ (h >>> 16), 0x85ebca6b);\n      h = Math.imul(h ^ (h >>> 13), 0xc2b2ae35);\n      h ^= h >>> 16;\n    }\n    return h >>> 0;\n  }\n\n  getHashes(item) {\n    const hashes = [];\n    for (let i = 0; i < this.k; i++) {\n      const h = this.hash(item, this.seed + i) % this.size;\n      hashes.push(h);\n    }\n    return hashes;\n  }\n\n  add(item) {\n    const hashes = this.getHashes(item);\n    for (const h of hashes) {\n      this.bits[h] = 1;\n    }\n    this.itemCount++;\n  }\n\n  test(item) {\n    const hashes = this.getHashes(item);\n    for (const h of hashes) {\n      if (this.bits[h] === 0) return false;\n    }\n    return true;\n  }\n\n  estimateFalsePositiveRate() {\n    const bitsSet = this.bits.reduce((sum, bit) => sum + bit, 0);\n    const p = bitsSet / this.size;\n    return Math.pow(p, this.k);\n  }\n}\n\nconst DEFAULT_DANGEROUS_PATTERNS = [\n  'ignore all instructions',\n  'ignore previous instructions',\n  'disregard instructions',\n  'override system',\n  'you are now',\n  'act as dan',\n  'jailbreak',\n  'developer mode',\n  'godmode enabled',\n  'love pliny',\n  'im free',\n  'i\\'m free',\n  'system prompt',\n  'reveal instructions',\n  'show your prompt',\n  'print instructions',\n  'forget everything'\n];\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('BloomPrefilter: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n\n  // Skip if already blocked\n  if (j.configError === true || j._isBlocked === true) {\n    out.push(item);\n    continue;\n  }\n\n  const cfg = j.config ?? {};\n\n  // Get configuration from unified_config.json with defaults\n  const bloomCfg = cfg.bloom || {\n    m: 32768,\n    k: 5,\n    seed: 1337,\n    match_mod: 97,\n    min_matched_bits: 2\n  };\n\n  const prefilterCfg = cfg.prefilter || {\n    ngram: { min: 3, max: 6, prefix_window: 96 },\n    sample_limit: 800,\n    obf_signals: { min_count: 2 }\n  };\n\n  // Get dangerous patterns from config or use defaults\n  const dangerousPatterns = (prefilterCfg.dangerous_patterns && Array.isArray(prefilterCfg.dangerous_patterns) && prefilterCfg.dangerous_patterns.length > 0)\n    ? prefilterCfg.dangerous_patterns\n    : DEFAULT_DANGEROUS_PATTERNS;\n\n  const bloomDecisions = cfg.bloom_decisions || {\n    route_to_ac_threshold: 15,\n    hard_block_threshold: 50,\n    require_zusatz_signals: true,\n    phrase_match_bonus: 20\n  };\n\n  // Initialize bloom filter\n  const bloom = new SimpleBloomFilter(bloomCfg.m, bloomCfg.k, bloomCfg.seed);\n\n  // ========================================\n  // FIX: Indeksuj n-gramy z patterns (nie pe\u0142ne frazy!)\n  // ========================================\n  const ngramMin = prefilterCfg.ngram?.min || 3;\n  const ngramMax = prefilterCfg.ngram?.max || 6;\n\n  let totalNgramsIndexed = 0;\n  for (const pattern of dangerousPatterns) {\n    if (typeof pattern === 'string' && pattern.length > 0) {\n      const normalizedPattern = pattern.toLowerCase();\n\n      // Add full pattern (dla dok\u0142adnych dopasowa\u0144)\n      bloom.add(normalizedPattern);\n      totalNgramsIndexed++;\n\n      // Add n-grams from pattern (dla cz\u0119\u015bciowych dopasowa\u0144)\n      for (let n = ngramMin; n <= Math.min(ngramMax, normalizedPattern.length); n++) {\n        for (let i = 0; i <= normalizedPattern.length - n; i++) {\n          const ngram = normalizedPattern.substring(i, i + n);\n          // Skipuj n-gramy sk\u0142adaj\u0105ce si\u0119 tylko ze spacji\n          if (ngram.trim().length > 0) {\n            bloom.add(ngram);\n            totalNgramsIndexed++;\n          }\n        }\n      }\n    }\n  }\n\n  const text = j.normalization?.forScoring ?? j.chat_payload?.chatInput ?? \"\";\n  const original = j.normalization?.original ?? \"\";\n\n  // Skip if no text to analyze\n  if (!text) {\n    j.prefilter = {\n      bloom: {\n        matchedBitsCount: 0,\n        totalHashes: 0,\n        matchRatio: 0,\n        suspiciousScore: 0,\n        falsePositiveRate: bloom.estimateFalsePositiveRate(),\n        patternsLoaded: dangerousPatterns.length,\n        ngramsIndexed: totalNgramsIndexed,\n        skipped: true,\n        skipReason: 'no_text',\n        version: 'FIXED_v1.0'\n      },\n      ngram: { sampledCount: 0 },\n      routeToAC: false,\n      hardBlock: false,\n      signals: {}\n    };\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n\n  // ========================================\n  // FIX: Testuj zar\u00f3wno n-gramy jak i sliding windows\n  // ========================================\n  const sampleLimit = prefilterCfg.sample_limit || 800;\n  const testText = text.substring(0, sampleLimit).toLowerCase();\n\n  let matchedNgrams = 0;\n  let totalNgramTests = 0;\n  let matchedPhrases = [];\n\n  // Test 1: N-gram matching (fast, general detection)\n  for (let n = ngramMin; n <= ngramMax; n++) {\n    for (let i = 0; i <= testText.length - n; i++) {\n      const ngram = testText.substring(i, i + n);\n      totalNgramTests++;\n      if (bloom.test(ngram)) {\n        matchedNgrams++;\n      }\n    }\n  }\n\n  // Test 2: Phrase matching (slower, but catches exact phrases)\n  // Testuj sliding windows od 10 do 50 znak\u00f3w\n  for (let windowSize = 10; windowSize <= Math.min(50, testText.length); windowSize += 5) {\n    for (let i = 0; i <= testText.length - windowSize; i++) {\n      const window = testText.substring(i, i + windowSize).trim();\n      if (bloom.test(window)) {\n        // Znale\u017ali\u015bmy potencjaln\u0105 fraz\u0119!\n        // Sprawd\u017a czy to jedna z known patterns\n        for (const pattern of dangerousPatterns) {\n          if (window.includes(pattern.toLowerCase())) {\n            if (!matchedPhrases.includes(pattern)) {\n              matchedPhrases.push(pattern);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  const ngramMatchRatio = totalNgramTests > 0 ? matchedNgrams / totalNgramTests : 0;\n\n  // Additional cheap signals\n  const hasZWSP = /[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\uFEFF]/.test(original);\n  const longBase64 = /\\b[A-Za-z0-9+/]{100,}={0,2}\\b/.test(text);\n  const hasTemplateMarkers = j.normalization?.obfuscationSignals?.includes(\"template-markers\") || false;\n  const hasSeparatorAbuse = j.normalization?.obfuscationSignals?.includes(\"separator-abuse\") || false;\n\n  // ========================================\n  // FIX: Scoring z uwzgl\u0119dnieniem phrase matches\n  // ========================================\n  // Base score z n-gram\u00f3w\n  let suspiciousScore = ngramMatchRatio * 100;\n\n  // Boost score je\u015bli znaleziono exact phrases\n  if (matchedPhrases.length > 0) {\n    // Ka\u017cda znaleziona fraza dodaje konfigurowalne punkty\n    const phraseBonus = bloomDecisions.phrase_match_bonus || 20;\n    suspiciousScore += matchedPhrases.length * phraseBonus;\n    // Cap at 100\n    suspiciousScore = Math.min(100, suspiciousScore);\n  }\n\n  // Decision based on config thresholds\n  // n-gram overlap is natural in normal language - need strong signal\n  const routeToAC = (suspiciousScore > bloomDecisions.route_to_ac_threshold) ||\n                    hasTemplateMarkers || hasSeparatorAbuse ||\n                    matchedPhrases.length > 0;  // Route if any phrase matched\n\n  const hardBlock = (suspiciousScore > bloomDecisions.hard_block_threshold) &&\n                    (!bloomDecisions.require_zusatz_signals ||\n                     (hasZWSP || longBase64 || matchedPhrases.length >= 2));\n\n  j.prefilter = {\n    bloom: {\n      matchedBitsCount: matchedNgrams,\n      totalHashes: totalNgramTests,\n      matchRatio: ngramMatchRatio,\n      suspiciousScore: Math.round(suspiciousScore),\n      falsePositiveRate: bloom.estimateFalsePositiveRate(),\n      patternsLoaded: dangerousPatterns.length,\n      ngramsIndexed: totalNgramsIndexed,\n      configSource: (prefilterCfg.dangerous_patterns && prefilterCfg.dangerous_patterns.length > 0) ? 'config' : 'defaults',\n      version: 'FIXED_v1.0'\n    },\n    ngram: {\n      sampledCount: Math.min(text.length, sampleLimit),\n      ngramMin,\n      ngramMax\n    },\n    phrases: {\n      matchedCount: matchedPhrases.length,\n      matched: matchedPhrases.slice(0, 5)  // Limit to first 5 for logging\n    },\n    routeToAC,\n    hardBlock,\n    signals: { hasZWSP, longBase64, hasTemplateMarkers, hasSeparatorAbuse },\n    thresholdsUsed: {\n      route_threshold: bloomDecisions.route_to_ac_threshold,\n      block_threshold: bloomDecisions.hard_block_threshold,\n      zusatz_required: bloomDecisions.require_zusatz_signals\n    }\n  };\n\n  // If hard block detected, set decision early\n  if (hardBlock) {\n    j.decision = j.decision || {};\n    j.decision.decision = 'BLOCK';\n    j.decision.source = 'bloom_prefilter';\n    j.decision.reason = 'HIGH_RISK_PATTERN_DETECTED';\n    j.decision.details = {\n      suspiciousScore: Math.round(suspiciousScore),\n      matchedPhrases: matchedPhrases,\n      signals: Object.keys(j.prefilter.signals).filter(k => j.prefilter.signals[k]),\n      ngramMatchRatio: ngramMatchRatio,\n      threshold: bloomDecisions.hard_block_threshold\n    };\n    j._isBlocked = true;\n  }\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2704,
        -96
      ],
      "id": "8c483ae6-c308-4fb8-abb1-0de2a927ba20",
      "name": "Bloom_Prefilter"
    },
    {
      "parameters": {
        "content": "## Standard chat input",
        "height": 320,
        "width": 560,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5456,
        -224
      ],
      "typeVersion": 1,
      "id": "72f8e86d-e38f-48ca-a624-5334657cb7f4",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "42f773e2-7ebf-42f7-a993-8be016d218e1",
        "responseMode": "lastNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        -5296,
        496
      ],
      "id": "6cd78d1e-60ba-4bf2-bca8-5fe624544bba",
      "name": "Webhook",
      "webhookId": "42f773e2-7ebf-42f7-a993-8be016d218e1"
    },
    {
      "parameters": {
        "content": "## Webhook",
        "height": 320,
        "width": 560,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5472,
        368
      ],
      "typeVersion": 1,
      "id": "8b9c1611-3f26-48d6-9a9a-7165e6ed04de",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Input_Validator - Pre-filtering DoS Protection (Phase 2.4)\n * Validates input before main pipeline to prevent resource exhaustion\n */\n\nconst items = $input.all();\nif (!items || items.length === 0) {\n  console.warn('Input_Validator: No input items');\n  return [];\n}\n\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n\n  // Skip if config error already present\n  if (j.configError === true) {\n    j.validation = { passed: false, reason: 'CONFIG_ERROR' };\n    item.json = j;\n    out.push(item);\n    continue;\n  }\n\n  // Get input text\n  const text = j.chat_payload?.chatInput ?? j.chatInput ?? \"\";\n\n  // Initialize validation result\n  const validation = {\n    passed: true,\n    reason: null,\n    checks: {},\n    input_length: text.length\n  };\n\n  // CHECK 1: Minimum length (empty input)\n  if (text.length < 1) {\n    validation.passed = false;\n    validation.reason = 'EMPTY_INPUT';\n    validation.checks.min_length = false;\n\n    j._isBlocked = true;\n    j.decision = {\n      decision: 'BLOCK',\n      source: 'input_validator',\n      reason: 'EMPTY_INPUT',\n      updated_at: new Date().toISOString()\n    };\n    j.score = 100;\n    j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n  }\n  // CHECK 2: Maximum length (DoS protection)\n  else if (text.length > 10000) {\n    validation.passed = false;\n    validation.reason = 'EXCESSIVE_LENGTH';\n    validation.checks.max_length = false;\n\n    j._isBlocked = true;\n    j.decision = {\n      decision: 'BLOCK',\n      source: 'input_validator',\n      reason: 'EXCESSIVE_LENGTH',\n      updated_at: new Date().toISOString()\n    };\n    j.score = 100;\n    j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n  }\n  // CHECK 3: Excessive control characters (>30%)\n  else {\n    const controlChars = (text.match(/[\\x00-\\x1F\\x7F-\\x9F]/g) || []).length;\n    const controlRatio = text.length > 0 ? controlChars / text.length : 0;\n\n    if (controlRatio > 0.30) {\n      validation.passed = false;\n      validation.reason = 'EXCESSIVE_CONTROL_CHARS';\n      validation.checks.control_chars = false;\n      validation.checks.control_ratio = controlRatio;\n\n      j._isBlocked = true;\n      j.decision = {\n        decision: 'BLOCK',\n        source: 'input_validator',\n        reason: 'EXCESSIVE_CONTROL_CHARS',\n        updated_at: new Date().toISOString()\n      };\n      j.score = 100;\n      j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n    }\n    // CHECK 4: Excessive repetition (uniqueChars < 5 for >100 char inputs)\n    else if (text.length > 100) {\n      const uniqueChars = new Set(text).size;\n\n      if (uniqueChars < 5) {\n        validation.passed = false;\n        validation.reason = 'EXCESSIVE_REPETITION';\n        validation.checks.unique_chars = uniqueChars;\n        validation.checks.repetition_detected = true;\n\n        j._isBlocked = true;\n        j.decision = {\n          decision: 'BLOCK',\n          source: 'input_validator',\n          reason: 'EXCESSIVE_REPETITION',\n          updated_at: new Date().toISOString()\n        };\n        j.score = 100;\n        j.scoreBreakdown = { INPUT_VALIDATION: 100 };\n      } else {\n        validation.checks.unique_chars = uniqueChars;\n        validation.checks.repetition_detected = false;\n      }\n    }\n\n    // Mark all checks passed if no failures\n    if (validation.passed) {\n      validation.checks.min_length = true;\n      validation.checks.max_length = true;\n      validation.checks.control_chars = true;\n      validation.checks.repetition_detected = false;\n    }\n  }\n\n  // Store validation result\n  j.validation = validation;\n  j._validation = validation;  // Protected field for pipeline persistence\n  j._input_validated = true;\n  \n  // CRITICAL: Store in config for pipeline persistence (Phase 2.4)\n  if (!j.config) j.config = {};\n  j.config._validation = validation;\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3424,
        -96
      ],
      "id": "5f13e8d0-8d14-4b8f-b1d3-3fe213fc1aff",
      "name": "Input_Validator"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "1db9e612-fab9-48c2-83ec-16bd5b821126",
              "leftValue": "={{ $json.validation?.passed }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "true"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3296,
        304
      ],
      "id": "e82d91d5-f6c7-4ce3-8690-4c9b460261f4",
      "name": "Validation Check"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Early Block Response - Validation failure handler (SIMPLIFIED)\n */\n\nconst items = $input.all();\nconst out = [];\n\nfor (const item of items) {\n  const j = item.json ?? {};\n  const validation = j.validation || {};\n\n  // Get original input\n  const originalInput = j.chat_payload?.chatInput || \"\";\n\n  // Create block message\n  let blockMessage = \"Content blocked by security policy\";\n  switch (validation.reason) {\n    case 'EMPTY_INPUT':\n      blockMessage = \"Invalid request: Empty input\";\n      break;\n    case 'EXCESSIVE_LENGTH':\n      blockMessage = \"Invalid request: Input exceeds maximum length (10000 characters)\";\n      break;\n    case 'EXCESSIVE_CONTROL_CHARS':\n      blockMessage = \"Invalid request: Excessive control characters detected\";\n      break;\n    case 'EXCESSIVE_REPETITION':\n      blockMessage = \"Invalid request: Excessive character repetition detected\";\n      break;\n  }\n\n  // Set output\n  j.output_text = blockMessage;\n  j.chat_payload = j.chat_payload || {};\n  j.chat_payload.chatInput = blockMessage;\n\n  // Preserve original for logging\n  j.audit = j.audit || {};\n  j.audit.originalPrompt = originalInput;\n  j.audit.validationFailure = true;\n  j.audit.validationReason = validation.reason;\n\n  item.json = j;\n  out.push(item);\n}\n\nreturn out;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        192,
        320
      ],
      "id": "cf1403da-83b8-4367-b2ac-7ec71bd9eaed",
      "name": "Early Block Response"
    },
    {
      "parameters": {
        "jsCode": "/**\n * output to plugin - Format response for browser extension\n * Reads from Build+Sanitize NDJSON node\n */\n\n// Get data from Build+Sanitize NDJSON (not from $input!)\nconst buildOutput = $('Build+Sanitize NDJSON').item.json;\n\nconsole.log('Build output keys:', Object.keys(buildOutput || {}));\n\nconst ndjson = buildOutput?.ndjson;\n\nif (!ndjson) {\n  console.log('\u274c No ndjson data from Build+Sanitize NDJSON');\n  return [{\n    json: {\n      action: 'allow',\n      reason: 'no_ndjson_data',\n      error: 'Could not read data from Build+Sanitize NDJSON node'\n    }\n  }];\n}\n\n// Extract decision data\nconst finalStatus = ndjson.final_decision?.status || 'ALLOWED';\nconst threatScore = ndjson.scoring?.sanitizer_score || ndjson.scoring?.prompt_guard_score || 0;\nconst cleanedPrompt = ndjson.chat_payload?.chatInput || '';\nconst sessionId = ndjson.sessionId || 'unknown';\n\nconsole.log('Final status:', finalStatus);\nconsole.log('Threat score:', threatScore);\nconsole.log('Cleaned prompt:', cleanedPrompt);\n\n// Map status to action\nlet action = 'allow';\nif (finalStatus === 'BLOCKED' || threatScore >= 85) {\n  action = 'block';\n} else if (finalStatus === 'SANITIZED' || threatScore >= 30) {\n  action = 'sanitize';\n}\n\n// Build response for plugin\nconst response = {\n  action: action,\n  reason: finalStatus.toLowerCase(),\n  threat_score: threatScore,\n  sessionId: sessionId\n};\n\n// Try to get original request body from Webhook\ntry {\n  const webhookInput = $('Webhook').first().json;\n  const originalBody = webhookInput?._debug?.fullBody;\n  \n  // If sanitizing and we have original body, build sanitizedBody\n  if (action === 'sanitize' && originalBody && originalBody.messages) {\n    response.sanitizedBody = {\n      ...originalBody,\n      messages: [{\n        ...originalBody.messages[0],\n        content: {\n          content_type: \"text\",\n          parts: [cleanedPrompt]\n        }\n      }]\n    };\n    console.log('\u2705 Built sanitizedBody with cleaned prompt');\n  } else if (action !== 'allow') {\n    // Fallback - return cleaned prompt as simple field\n    response.chatInput = cleanedPrompt;\n  }\n} catch (e) {\n  console.log('\u26a0\ufe0f Could not access Webhook data:', e.message);\n  if (action !== 'allow') {\n    response.chatInput = cleanedPrompt;\n  }\n}\n\nconsole.log('Final response:', JSON.stringify(response, null, 2));\n\n// Return single object\nreturn [{\n  json: response\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        928,
        192
      ],
      "id": "cb17901f-36ae-4b11-958b-576557d23e88",
      "name": "output to plugin"
    }
  ],
  "pinData": {},
  "connections": {
    "Build+Sanitize NDJSON": {
      "main": [
        [
          {
            "node": "Logging to Clikhouse",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Logging to Clikhouse": {
      "main": [
        [
          {
            "node": "Clean output",
            "type": "main",
            "index": 0
          },
          {
            "node": "output to plugin",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Config Loader": {
      "main": [
        [
          {
            "node": "Input_Validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Config Loader",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Keep only set": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.json",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf3",
            "type": "main",
            "index": 0
          },
          {
            "node": "Loading config files *.conf4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Extract from File1": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Normalize_Node": {
      "main": [
        [
          {
            "node": "Bloom_Prefilter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loading config files *.conf": {
      "main": [
        [
          {
            "node": "Extract from File1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loading config files *.json": {
      "main": [
        [
          {
            "node": "Extract from File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Unified Decision Engine": {
      "main": [
        [
          {
            "node": "Correlation_Engine",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Allowlist_Validator": {
      "main": [
        [
          {
            "node": "Pattern_Matching_Engine",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Sanitization_Enforcement": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Correlation_Engine": {
      "main": [
        [
          {
            "node": "Sanitization_Enforcement",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pattern_Matching_Engine": {
      "main": [
        [
          {
            "node": "Unified Decision Engine",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File2": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Loading config files *.conf1": {
      "main": [
        [
          {
            "node": "Extract from File2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File3": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "Loading config files *.conf2": {
      "main": [
        [
          {
            "node": "Extract from File3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File4": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 5
          }
        ]
      ]
    },
    "Loading config files *.conf3": {
      "main": [
        [
          {
            "node": "Extract from File4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File5": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 6
          }
        ]
      ]
    },
    "Loading config files *.conf4": {
      "main": [
        [
          {
            "node": "Extract from File5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Finale Decision": {
      "main": [
        [
          {
            "node": "Build+Sanitize NDJSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "Finale Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare LLM Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Context Restore": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Prompt Guard API": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "LLM Context Restore",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Bloom_Prefilter": {
      "main": [
        [
          {
            "node": "Allowlist_Validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare LLM Request": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prompt Guard API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Keep only set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Keep only set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Input_Validator": {
      "main": [
        [
          {
            "node": "Validation Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validation Check": {
      "main": [
        [
          {
            "node": "PII_Redactor_v2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Early Block Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Early Block Response": {
      "main": [
        [
          {
            "node": "Build+Sanitize NDJSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PII_Redactor_v2": {
      "main": [
        [
          {
            "node": "Normalize_Node",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "97594a85-db80-4540-93d5-70161a31b5d7",
  "meta": {
    "instanceId": "004e3bbc45b3f040b9767a4451ef465967114bc5e89c4ddc8cd6c892432d1ed8"
  },
  "id": "Gft83R4H1FQRNQXy",
  "tags": []
}