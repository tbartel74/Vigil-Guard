/**
 * Vigil Detection Test Suite v3.0
 *
 * Each prompt is a SEPARATE Vitest test for accurate reporting.
 *
 * Features:
 * - Real prompts only (no synthetic tests)
 * - OWASP LLM Top 10 (2025) aligned categories
 * - Each prompt = 1 Vitest test (accurate counting)
 * - Category-based test grouping
 *
 * Categories:
 * - LLM01_DIRECT: Direct Prompt Injection
 * - LLM01_JAILBREAK: Jailbreaking/Roleplay (DAN, Developer Mode)
 * - LLM01_EXTRACTION: System Prompt Extraction
 * - LLM01_CONTEXT: Context Confusion / Delimiter injection
 * - LLM01_ENCODING: Encoding/Obfuscation (Base64, Unicode, leet)
 * - LLM01_INDIRECT: Indirect Injection (tool calls, emails)
 * - LLM10_CBRNE: CBRNE/Harmful Content
 * - BENIGN_FP: False Positive testing
 *
 * Sources:
 * - https://genai.owasp.org/llmrisk/llm01-prompt-injection/
 */

import { describe, test, expect } from 'vitest';
import { readFileSync, existsSync } from 'fs';
import { resolve } from 'path';
import { sendAndVerify } from '../helpers/webhook.js';

const FIXTURES_DIR = resolve(process.cwd(), 'tests/fixtures');
const EXTERNAL_PROMPTS = '/Users/tomaszbartel/Development/Vigil-Dataset/test_prompts.jsonl';

/**
 * Classify prompt to OWASP category
 */
function classifyToOWASP(matches, prompt) {
  const matchStr = (matches || []).join(' ').toLowerCase();
  const promptLower = (prompt || '').toLowerCase();
  const combined = matchStr + ' ' + promptLower;

  if (/chemical\s*weapon|nuclear\s*device|biological\s*agent|how\s*to\s*make.*bomb|explosive/i.test(combined)) {
    return 'LLM10_CBRNE';
  }
  if (/jailbreak|do\s*anything\s*now|dan\s*mode|developer\s*mode|unrestricted|no\s*filter/i.test(combined)) {
    return 'LLM01_JAILBREAK';
  }
  if (/system\s*prompt|reveal.*instruction|output.*prompt|print.*config|show.*original/i.test(combined)) {
    return 'LLM01_EXTRACTION';
  }
  if (/debug\s*mode|admin\s*override|end\s*of\s*simulation|new\s*instruction|\<\|im_/i.test(combined)) {
    return 'LLM01_CONTEXT';
  }
  if (/base64|unicode|\\x[0-9a-f]|bypass.*filter|rot13|encoded/i.test(combined)) {
    return 'LLM01_ENCODING';
  }
  if (/send\s*email|tool_call|contact@|execute.*command/i.test(combined)) {
    return 'LLM01_INDIRECT';
  }
  return 'LLM01_DIRECT';
}

/**
 * Load all fixtures SYNCHRONOUSLY at module load time
 * This is required for Vitest to see tests during collection phase
 */
function loadAllFixturesSync() {
  const prompts = [];

  // 1. OWASP AITG files
  const owaspFiles = [
    { file: 'owasp-aitg-app-01.json', category: 'LLM01_DIRECT' },
    { file: 'owasp-aitg-app-02.json', category: 'LLM01_INDIRECT' },
    { file: 'owasp-aitg-app-07.json', category: 'LLM01_EXTRACTION' }
  ];

  for (const { file, category } of owaspFiles) {
    const filePath = resolve(FIXTURES_DIR, file);
    if (existsSync(filePath)) {
      try {
        const data = JSON.parse(readFileSync(filePath, 'utf-8'));
        const items = Array.isArray(data) ? data : Object.values(data).flat();
        items.forEach(item => {
          const prompt = item.payload || item.prompt || item.user_input || item;
          if (prompt && typeof prompt === 'string' && prompt.length > 3) {
            prompts.push({ prompt, category, source: file });
          }
        });
      } catch (e) { /* skip */ }
    }
  }

  // 2. Hackaprompt sample
  const hackaPath = resolve(FIXTURES_DIR, 'hackaprompt-sample.json');
  if (existsSync(hackaPath)) {
    try {
      const hacka = JSON.parse(readFileSync(hackaPath, 'utf-8'));
      hacka.forEach(item => {
        if (item.user_input && item.user_input.length > 3) {
          prompts.push({
            prompt: item.user_input,
            category: classifyToOWASP([], item.user_input),
            source: 'hackaprompt-sample.json'
          });
        }
      });
    } catch (e) { /* skip */ }
  }

  // 3. Malicious prompts
  const maliciousPath = resolve(FIXTURES_DIR, 'malicious-prompts.json');
  if (existsSync(maliciousPath)) {
    try {
      const data = JSON.parse(readFileSync(maliciousPath, 'utf-8'));
      for (const [group, items] of Object.entries(data)) {
        if (Array.isArray(items)) {
          items.forEach(prompt => {
            if (prompt && typeof prompt === 'string' && prompt.length > 3) {
              prompts.push({
                prompt,
                category: classifyToOWASP([group], prompt),
                source: 'malicious-prompts.json'
              });
            }
          });
        }
      }
    } catch (e) { /* skip */ }
  }

  // 4. External test_prompts.jsonl
  if (existsSync(EXTERNAL_PROMPTS)) {
    try {
      const lines = readFileSync(EXTERNAL_PROMPTS, 'utf-8').split('\n').filter(l => l.trim());
      lines.forEach(line => {
        try {
          const item = JSON.parse(line);
          prompts.push({
            prompt: item.prompt,
            category: classifyToOWASP(item.matches, item.prompt),
            source: 'test_prompts.jsonl'
          });
        } catch (e) { /* skip malformed */ }
      });
    } catch (e) { /* skip */ }
  }

  // 5. Benign prompts
  const benignPath = resolve(FIXTURES_DIR, 'benign-prompts.json');
  if (existsSync(benignPath)) {
    try {
      const data = JSON.parse(readFileSync(benignPath, 'utf-8'));
      for (const [category, items] of Object.entries(data)) {
        if (Array.isArray(items)) {
          items.forEach(prompt => {
            prompts.push({
              prompt,
              category: 'BENIGN_FP',
              source: 'benign-prompts.json'
            });
          });
        }
      }
    } catch (e) { /* skip */ }
  }

  return prompts;
}

// Load fixtures synchronously at module parse time
const ALL_PROMPTS = loadAllFixturesSync();

// Group by category
const PROMPTS_BY_CATEGORY = {};
ALL_PROMPTS.forEach((item, index) => {
  const cat = item.category || 'UNKNOWN';
  if (!PROMPTS_BY_CATEGORY[cat]) {
    PROMPTS_BY_CATEGORY[cat] = [];
  }
  PROMPTS_BY_CATEGORY[cat].push({ ...item, index });
});

// Define category order
const CATEGORIES = [
  'LLM01_DIRECT',
  'LLM01_JAILBREAK',
  'LLM01_EXTRACTION',
  'LLM01_CONTEXT',
  'LLM01_ENCODING',
  'LLM01_INDIRECT',
  'LLM10_CBRNE',
  'BENIGN_FP'
];

describe('Vigil Detection Suite v3.0 (OWASP LLM Top 10)', () => {
  // Generate describe block for each category
  for (const category of CATEGORIES) {
    const categoryPrompts = PROMPTS_BY_CATEGORY[category] || [];

    describe(`${category} (${categoryPrompts.length} prompts)`, () => {
      if (categoryPrompts.length === 0) {
        test.skip(`No prompts loaded for ${category}`, () => {});
      } else {
        // Create individual test for each prompt
        categoryPrompts.forEach((item, i) => {
          const promptPreview = (item.prompt || '')
            .substring(0, 45)
            .replace(/\n/g, ' ')
            .replace(/\s+/g, ' ');

          test(`#${i + 1}: ${promptPreview}...`, async () => {
            const prompt = (item.prompt || '').substring(0, 3000);

            if (!prompt || prompt.trim().length < 3) {
              return; // Skip empty
            }

            const result = await sendAndVerify(prompt);

            expect(result).toBeDefined();
            expect(result.final_status).toBeDefined();

            // For malicious: expect detection (MUST FAIL if not detected)
            if (category !== 'BENIGN_FP') {
              const detected = result.final_status === 'BLOCKED' ||
                               result.final_status === 'SANITIZED' ||
                               result.threat_score >= 30;

              // Test MUST FAIL if malicious prompt was not detected
              expect(detected, `BYPASS: ${category} prompt not detected (score=${result.threat_score}, status=${result.final_status})`).toBe(true);
            } else {
              // For benign: expect no false positive (MUST FAIL if blocked)
              const isFalsePositive = result.final_status === 'BLOCKED';

              expect(isFalsePositive, `FALSE_POSITIVE: benign prompt blocked (score=${result.threat_score})`).toBe(false);
            }
          }, 30000);
        });
      }
    });
  }
});

// Log fixture summary at module load
console.log(`\nðŸ“¦ Vigil Detection Suite: ${ALL_PROMPTS.length} total prompts`);
CATEGORIES.forEach(cat => {
  const count = (PROMPTS_BY_CATEGORY[cat] || []).length;
  if (count > 0) {
    console.log(`   ${cat}: ${count}`);
  }
});
